{
  "version": 3,
  "sources": [
    "node_modules/browser-pack/_prelude.js",
    "node_modules/events/events.js",
    "node_modules/mux.js/lib/aac/index.js",
    "node_modules/mux.js/lib/aac/utils.js",
    "node_modules/mux.js/lib/codecs/adts.js",
    "node_modules/mux.js/lib/codecs/h264.js",
    "node_modules/mux.js/lib/codecs/index.js",
    "node_modules/mux.js/lib/constants/audio-properties.js",
    "node_modules/mux.js/lib/constants/video-properties.js",
    "node_modules/mux.js/lib/data/silence.js",
    "node_modules/mux.js/lib/flv/coalesce-stream.js",
    "node_modules/mux.js/lib/flv/flv-header.js",
    "node_modules/mux.js/lib/flv/flv-tag.js",
    "node_modules/mux.js/lib/flv/index.js",
    "node_modules/mux.js/lib/flv/tag-list.js",
    "node_modules/mux.js/lib/flv/transmuxer.js",
    "node_modules/mux.js/lib/index.js",
    "node_modules/mux.js/lib/m2ts/caption-stream.js",
    "node_modules/mux.js/lib/m2ts/index.js",
    "node_modules/mux.js/lib/m2ts/m2ts.js",
    "node_modules/mux.js/lib/m2ts/metadata-stream.js",
    "node_modules/mux.js/lib/m2ts/probe.js",
    "node_modules/mux.js/lib/m2ts/stream-types.js",
    "node_modules/mux.js/lib/m2ts/timestamp-rollover-stream.js",
    "node_modules/mux.js/lib/mp4/audio-frame-utils.js",
    "node_modules/mux.js/lib/mp4/caption-parser.js",
    "node_modules/mux.js/lib/mp4/find-box.js",
    "node_modules/mux.js/lib/mp4/frame-utils.js",
    "node_modules/mux.js/lib/mp4/index.js",
    "node_modules/mux.js/lib/mp4/mp4-generator.js",
    "node_modules/mux.js/lib/mp4/parse-type.js",
    "node_modules/mux.js/lib/mp4/probe.js",
    "node_modules/mux.js/lib/mp4/track-decode-info.js",
    "node_modules/mux.js/lib/mp4/transmuxer.js",
    "node_modules/mux.js/lib/partial/audio-segment-stream.js",
    "node_modules/mux.js/lib/partial/index.js",
    "node_modules/mux.js/lib/partial/transmuxer.js",
    "node_modules/mux.js/lib/partial/video-segment-stream.js",
    "node_modules/mux.js/lib/tools/caption-packet-parser.js",
    "node_modules/mux.js/lib/tools/flv-inspector.js",
    "node_modules/mux.js/lib/tools/mp4-inspector.js",
    "node_modules/mux.js/lib/tools/parse-sample-flags.js",
    "node_modules/mux.js/lib/tools/parse-sidx.js",
    "node_modules/mux.js/lib/tools/parse-tfdt.js",
    "node_modules/mux.js/lib/tools/parse-tfhd.js",
    "node_modules/mux.js/lib/tools/parse-trun.js",
    "node_modules/mux.js/lib/tools/ts-inspector.js",
    "node_modules/mux.js/lib/utils/bin.js",
    "node_modules/mux.js/lib/utils/clock.js",
    "node_modules/mux.js/lib/utils/exp-golomb.js",
    "node_modules/mux.js/lib/utils/stream.js",
    "src/controller/buffer-controller.js",
    "src/controller/flow-controller.js",
    "src/event-handler.js",
    "src/events.js",
    "src/index.js",
    "src/loader/websocket-loader.js",
    "src/player.css.js",
    "src/player.js",
    "src/utils/xhr-loader.js",
    "src/videojs/flow-mux.js",
    "src/videojs/flow.js",
    "src/wfs.js"
  ],
  "names": [],
  "mappings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nIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACreA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACz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rcA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACz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hBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7PA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/RA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACrGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACvcA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/TA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC/xBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7WA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC3GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChqCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1JA;AACA;AACA;AACA;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1XA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AChNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACpMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC5KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7qBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzgBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACzJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACzIA;;;;AACA;;;;AACA;;;;;;;;;;+eANA;;;;IAQM,gB;;;AAEJ,4BAAY,GAAZ,EAAiB;AAAA;;AAAA,oIACT,GADS,EAEb,iBAAM,eAFO,EAGb,iBAAM,gBAHO,EAIb,iBAAM,YAJO,EAKb,iBAAM,iBALO;;AAQf,UAAK,WAAL,GAAmB,IAAnB;AACA,UAAK,KAAL,GAAa,IAAb;AACA,UAAK,aAAL,GAAqB,EAArB;AACA,UAAK,YAAL,GAAoB,EAApB;AACA,UAAK,QAAL,GAAgB,EAAhB;;AAEA,UAAK,QAAL,GAAgB,CAAhB;AACA,UAAK,WAAL,GAAmB,IAAnB;;AAEA;AACA,UAAK,MAAL,GAAc,MAAK,aAAL,CAAmB,IAAnB,OAAd;;AAEA,UAAK,WAAL,GAAmB,CAAnB;AACA,QAAI,UAAU,SAAV,CAAoB,WAApB,GAAkC,OAAlC,CAA0C,SAA1C,MAAyD,CAAC,CAA9D,EAAgE;AAC9D,YAAK,WAAL,GAAmB,CAAnB;AACD;AACD,UAAK,SAAL,GAAiB,SAAjB;;AAEA,UAAK,aAAL,GAAqB,SAArB;AACA,UAAK,WAAL,GAAmB,SAAnB;AA3Be;AA4BhB;;;;8BAES;AACR,UAAG,KAAK,IAAR,EAAa,KAAK,IAAL,CAAU,OAAV;AACb,6BAAa,SAAb,CAAuB,OAAvB,CAA+B,IAA/B,CAAoC,IAApC;AACD;;;qCAEgB,I,EAAM;AACrB,UAAI,QAAQ,KAAK,KAAL,GAAa,KAAK,KAA9B;AACA,WAAK,SAAL,GAAiB,KAAK,SAAtB;AACA,WAAK,aAAL,GAAqB,KAAK,aAA1B;AACA,WAAK,WAAL,GAAmB,KAAK,WAAxB;AACA,UAAI,KAAJ,EAAW;AACT;AACA,YAAI,KAAK,KAAK,WAAL,GAAmB,IAAI,WAAJ,EAA5B;AACA;AACA,cAAM,GAAN,GAAY,IAAI,eAAJ,CAAoB,EAApB,CAAZ;;AAEA;AACA,aAAK,KAAL,GAAa,KAAK,iBAAL,CAAuB,IAAvB,CAA4B,IAA5B,CAAb;AACA,aAAK,KAAL,GAAa,KAAK,kBAAL,CAAwB,IAAxB,CAA6B,IAA7B,CAAb;AACA,aAAK,KAAL,GAAa,KAAK,kBAAL,CAAwB,IAAxB,CAA6B,IAA7B,CAAb;AACA,WAAG,gBAAH,CAAoB,YAApB,EAAkC,KAAK,KAAvC;AACA,WAAG,gBAAH,CAAoB,aAApB,EAAmC,KAAK,KAAxC;AACA,WAAG,gBAAH,CAAoB,aAApB,EAAmC,KAAK,KAAxC;AACD;AACF;;;uCAEkB,CAElB;;;sCAEiB,I,EAAM;AACtB,UAAI,CAAC,KAAK,QAAV,EAAoB;AAClB,aAAK,QAAL,GAAgB,CAAE,IAAF,CAAhB;AACD,OAFD,MAEO;AACL,aAAK,QAAL,CAAc,IAAd,CAAmB,IAAnB;AACD;AACD,WAAK,WAAL;AACD;;;yCAEoB;AACnB,cAAQ,GAAR,CAAY,qBAAZ;AACD;;;yCAEoB;AACnB,cAAQ,GAAR,CAAY,oBAAZ;AACD;;;kCAEa,K,EAAO;AACnB;AACA,UAAI,KAAK,WAAL,KAAqB,CAAzB,EAA2B;AACzB,aAAK,WAAL,CAAiB,WAAjB;AACA,aAAK,KAAL,CAAW,IAAX;AACD;;AAED,WAAK,SAAL,GAAiB,KAAjB;AACA,WAAK,WAAL;AACA,WAAK,0BAAL;AAED;;;iDAE4B,CAE5B;;;wCAEmB;AAClB,UAAI,cAAc,KAAK,WAAvB;AACA,UAAI,WAAJ,EAAiB;AACf;AACA,oBAAY,mBAAZ,CAAgC,YAAhC,EAA8C,KAAK,KAAnD;AACD;;AAED,UAAI,oBAAoB,YAAY,eAAZ,CAA4B,gCAA5B,CAAxB;AACA,WAAK,IAAL,GAAY,IAAI,cAAJ,EAAZ;AACA,WAAK,IAAL,CAAU,EAAV,CAAa,MAAb,EAAsB,UAAS,OAAT,EAAiB;AACrC,YAAG,QAAQ,IAAR,IAAgB,OAAnB,EAA2B;AACzB;AACD,SAFD,MAEK;AACH,4BAAkB,YAAlB,CAA+B,QAAQ,IAAR,CAAa,MAA5C;AACD;AACF,OAND;;AAQA,WAAK,GAAL,CAAS,OAAT,CAAiB,iBAAM,cAAvB,EAAuC,EAAC,OAAM,KAAK,KAAZ,EAAmB,aAAY,KAAK,WAApC,EAAiD,WAAW,KAAK,SAAjE,EAA4E,eAAc,KAAK,aAA/F,EAAvC;AACD;;;sCAEiB,K,EAAO;AAAA;;AACzB,UAAI,IAAI,MAAM,IAAd,CADyB,CACL;AAClB,UAAI,SAAS,IAAI,UAAJ,EAAb;AACA,aAAO,gBAAP,CAAwB,SAAxB,EAAmC,YAAI;AACnC,YAAI,QAAQ,IAAI,UAAJ,CAAe,OAAO,MAAtB,CAAZ;AACA,eAAK,IAAL,CAAU,QAAV,CAAmB,KAAnB;AACH,OAHD;AAIA,aAAO,iBAAP,CAAyB,CAAzB;AACF;;;;EA5H6B,sB;;kBA+HhB,gB;;;;;;;;;;;ACnIf;;;;AACA;;;;;;;;;;+eALA;;;;IAOM,c;;;AAEJ,0BAAY,GAAZ,EAAiB;AAAA;;AAAA,gIACT,GADS,EAEb,iBAAM,cAFO,EAGb,iBAAM,cAHO,EAIb,iBAAM,iBAJO,EAKb,iBAAM,gBALO,EAMb,iBAAM,gBANO,EAOb,iBAAM,kBAPO,EAQb,iBAAM,iBARO,EASb,iBAAM,yBATO;;AAWf,UAAK,SAAL,GAAiB,CAAjB;AACA,UAAK,OAAL,GAAe,CAAf;AACA,UAAK,gBAAL,GAAwB,CAAxB;AACA,UAAK,SAAL,GAAiB,SAAjB;AACA,iBAAY,MAAK,WAAL;AAfG;AAgBhB;;;;8BAES;AACP,6BAAa,SAAb,CAAuB,OAAvB,CAA+B,IAA/B,CAAoC,IAApC;AACF;;;oCAEe,I,EAAM;AACpB,UAAI,KAAK,aAAL,IAAsB,SAA1B,EAAoC;AAClC,YAAI,SAAS,IAAI,SAAJ,CAAe,UAAU,OAAO,QAAP,CAAgB,IAA1B,GAAiC,GAAjC,GAAwC,KAAK,aAA5D,CAAb;AACA,aAAK,GAAL,CAAS,eAAT,CAAyB,MAAzB,EAAgC,KAAK,WAArC;AACD,OAHD,MAGK;AACF,gBAAQ,GAAR,CAAY,wBAAZ;AACF;AAEF;;;oCAEe,I,EAAM;AACpB,WAAK,SAAL,GAAiB,KAAK,SAAtB;AACD;;;qCAEgB,I,EAAM,CACtB;;;qCAEgB,I,EAAM,CACtB;;;sCAEiB,I,EAAM,CACvB;;;wCAEmB,I,EAAM;AACxB,WAAK,GAAL,CAAS,OAAT,CAAiB,iBAAM,gBAAvB,EAAyC,EAAC,MAAM,OAAP,EAAgB,MAAM,KAAK,OAA3B,EAAoC,QAAS,MAA7C,EAAzC;AACD;;;6CAEwB,I,EAAM;AAC7B,UAAI,SAAS,KAAK,MAAlB;AAAA,UAA0B,SAA1B;AAAA,UAAqC,KAArC;;AAEE,cAAQ,OAAO,KAAf;AACA,UAAG,KAAH,EAAU;AACR,cAAM,EAAN,GAAW,KAAK,EAAhB;AACD;;AAED,WAAK,SAAL,IAAkB,MAAlB,EAA0B;AACxB,gBAAQ,OAAO,SAAP,CAAR;AACA,YAAI,cAAc,MAAM,WAAxB;AACA,YAAI,WAAJ,EAAiB;AACf,eAAK,gBAAL;AACA,eAAK,GAAL,CAAS,OAAT,CAAiB,iBAAM,gBAAvB,EAAyC,EAAC,MAAM,SAAP,EAAkB,MAAM,WAAxB,EAAqC,QAAS,MAA9C,EAAzC;AACD;AACF;AAEJ;;;sCAEiB,I,EAAM;AAAA;;AAEpB,UAAG,KAAK,IAAL,KAAc,OAAjB,EAA0B,CAEzB;;AAED,OAAC,KAAK,KAAN,EAAa,KAAK,KAAlB,EAAyB,OAAzB,CAAiC,kBAAU;AACzC,YAAI,MAAJ,EAAY;AACV,iBAAK,gBAAL;AACA,iBAAK,GAAL,CAAS,OAAT,CAAiB,iBAAM,gBAAvB,EAAyC,EAAC,MAAM,KAAK,IAAZ,EAAkB,MAAM,MAAxB,EAAgC,QAAS,MAAzC,EAAzC;AACD;AACF,OALD;AAOH;;;;EAnF0B,sB;;kBAsFd,c;;;;;;;;;;;qjBC7Ff;;;;;;;AAKA;;;;;;;;IAEM,Y;AAEJ,wBAAY,GAAZ,EAA4B;AAAA;;AAC1B,SAAK,GAAL,GAAW,GAAX;AACA,SAAK,OAAL,GAAe,KAAK,OAAL,CAAa,IAAb,CAAkB,IAAlB,CAAf;;AAF0B,sCAAR,MAAQ;AAAR,YAAQ;AAAA;;AAG1B,SAAK,aAAL,GAAqB,MAArB;AACA,SAAK,iBAAL,GAAyB,IAAzB;;AAEA,SAAK,iBAAL;AACD;;;;8BAES;AACR,WAAK,mBAAL;AACD;;;qCAEgB;AACf,aAAO,QAAO,KAAK,aAAZ,MAA8B,QAA9B,IAA0C,KAAK,aAAL,CAAmB,MAA7D,IAAuE,OAAO,KAAK,OAAZ,KAAwB,UAAtG;AACD;;;wCAEmB;AAClB,UAAI,KAAK,cAAL,EAAJ,EAA2B;AACzB,aAAK,aAAL,CAAmB,OAAnB,CAA2B,UAAS,KAAT,EAAgB;AACzC,cAAI,UAAU,iBAAd,EAAiC;AAC/B;AACD;AACD,eAAK,GAAL,CAAS,EAAT,CAAY,KAAZ,EAAmB,KAAK,OAAxB;AACD,SAL0B,CAKzB,IALyB,CAKpB,IALoB,CAA3B;AAMD;AACF;;;0CAEqB;AACpB,UAAI,KAAK,cAAL,EAAJ,EAA2B;AACzB,aAAK,aAAL,CAAmB,OAAnB,CAA2B,UAAS,KAAT,EAAgB;AACzC,eAAK,GAAL,CAAS,GAAT,CAAa,KAAb,EAAoB,KAAK,OAAzB;AACD,SAF0B,CAEzB,IAFyB,CAEpB,IAFoB,CAA3B;AAGD;AACF;;AAED;;;;;;4BAGQ,K,EAAO,I,EAAM;AACnB,WAAK,cAAL,CAAoB,KAApB,EAA2B,IAA3B;AACD;;;mCAEc,K,EAAO,I,EAAM;AAC1B,UAAI,kBAAkB,SAAlB,eAAkB,CAAS,KAAT,EAAgB,IAAhB,EAAsB;AAC1C,YAAI,WAAW,OAAO,MAAM,OAAN,CAAc,KAAd,EAAqB,EAArB,CAAtB;AACA,YAAI,OAAO,KAAK,QAAL,CAAP,KAA0B,UAA9B,EAA0C;AACxC;AACD;AACD,eAAO,KAAK,QAAL,EAAe,IAAf,CAAoB,IAApB,EAA0B,IAA1B,CAAP;AACD,OAND;AAOA,UAAI;AACF,wBAAgB,IAAhB,CAAqB,IAArB,EAA2B,KAA3B,EAAkC,IAAlC,EAAwC,IAAxC;AACD,OAFD,CAEE,OAAO,GAAP,EAAY;AACZ,gBAAQ,GAAR,+CAAwD,KAAxD,SAAiE,IAAI,OAArE;AACA;AACD;AACF;;;;;;kBAGY,Y;;;;;ACrEf,OAAO,OAAP,GAAiB;;AAEf,mBAAiB,mBAFF;;AAIf,kBAAgB,kBAJD;;AAMf,gBAAc,gBANC;;AAQf,kBAAgB,kBARD;;AAUf,oBAAkB,oBAVH;;AAYf,gBAAc,gBAZC;;AAcf,qBAAmB,oBAdJ;;AAgBf,6BAA2B,2BAhBZ;AAiBjB;AACE,qBAAmB,oBAlBJ;;AAoBf,oBAAkB,mBApBH;AAqBjB;AACE,sBAAoB,sBAtBL;;AAwBf,uBAAqB,uBAxBN;;AA0Bf,4BAA0B,2BA1BX;;AA4Bf,6BAA2B,4BA5BZ;;AA8Bf,uBAAqB,sBA9BN;;AAgCf,qBAAkB,qBAhCH;;AAkCf,0BAAuB,iBAlCR;AAmCjB;AACE,qBAAmB,oBApCJ;;AAsCf,oBAAkB,mBAtCH;;AAwCf,qBAAmB,oBAxCJ;;AA0Cf,oBAAkB,mBA1CH;;AA4Cf,qBAAmB;AACrB;;AA7CiB,CAAjB;;;;;ACAA;AACA;AACA;AACA,OAAO,OAAP,GAAiB,QAAQ,aAAR,EAAuB,OAAxC;;;;;;;;;;;;;ACCA;;;;AACA;;;;;;;;;;+eALA;;;;AAMA;;IAEM,e;;;AAEJ,2BAAY,GAAZ,EAAiB;AAAA;;AAAA,kIACT,GADS,EAEf,iBAAM,mBAFS,EAGf,iBAAM,wBAHS,EAIf,iBAAM,yBAJS;;AAKf,UAAK,GAAL,GAAW,IAAX;AACA;AACA,UAAK,SAAL,GAAiB,SAAjB;AACA,UAAK,WAAL,GAAmB,SAAnB;AARe;AAShB;;;;8BAES;AACX,OAAC,CAAC,KAAK,MAAP,IAAiB,KAAK,MAAL,CAAY,KAAZ,EAAjB;AACA;AACG,6BAAa,SAAb,CAAuB,OAAvB,CAA+B,IAA/B,CAAoC,IAApC;AACD;;;yCAEoB,I,EAAM;AAC1B,WAAK,SAAL,GAAiB,KAAK,SAAtB;AACA,WAAK,WAAL,GAAmB,KAAK,WAAxB;AACC,UAAI,KAAK,SAAL,YAA0B,SAA9B,EAA0C;AACxC,aAAK,MAAL,GAAc,KAAK,SAAnB;AACA,aAAK,MAAL,CAAY,MAAZ,GAAqB,KAAK,gBAAL,CAAsB,IAAtB,CAA2B,IAA3B,CAArB;AACA,aAAK,MAAL,CAAY,OAAZ,GAAsB,UAAS,CAAT,EAAY;AAC9B,kBAAQ,GAAR,CAAY,yBAAZ;AACH,SAFD;AAGD;AACF;;;qCAEgB,M,EAAO;AACtB;AACA,WAAK,MAAL,CAAY,SAAZ,GAAwB,KAAK,oBAAL,CAA0B,IAA1B,CAA+B,IAA/B,CAAxB;AACA,WAAK,GAAL,CAAS,OAAT,CAAiB,iBAAM,iBAAvB,EAA0C,EAA1C;AACA;AACA,cAAQ,GAAR,CAAY,iBAAZ;AACD;;;yCAEqB,K,EAAO;AAC3B,UAAG,SAAS,QAAT,CAAH,EAAuB;AACvB,UAAG,QAAQ,MAAM,IAAd,EAAoB,WAApB,OAAsC,QAAzC,EAAoD;AAClD,gBAAQ,GAAR,CAAY,sBAAZ;AACA,aAAK,GAAL,CAAS,OAAT,CAAiB,iBAAM,sBAAvB,EAA+C,MAAM,IAArD;AACA;AACD;AACD,WAAK,GAAL,CAAS,OAAT,CAAiB,iBAAM,mBAAvB,EAA4C,MAAM,IAAN,CAAW,IAAvD;;AAEA,WAAK,GAAL,CAAS,OAAT,CAAiB,iBAAM,iBAAvB,EAA0C,KAA1C;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACD;;;6CAEyB,K,EAAO;AAC/B,WAAK,MAAL,CAAY,IAAZ,CAAkB,MAAM,IAAxB;AACD;;;8CAE0B,K,EAAO;AAChC,WAAK,MAAL,CAAY,IAAZ,CAAkB,KAAK,SAAL,CAAe,EAAE,GAAG,MAAM,WAAX,EAAwB,GAAE,MAAM,WAAhC,EAA6C,GAAG,MAAM,YAAtD,EAAf,CAAlB;AACD;;;;EAnE2B,sB;;kBAuEf,e;;;AC/Ef;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;ACDA;;;;AACA;;;;AACA;;;;AACA;;;;;;;;;;+eARA;;;AAGA;;AAOA,IAAM,SAAS;AACb,UAAK,MADQ;AAEb,aAAS,SAFI;AAGb,WAAO,OAHM;AAIb,UAAM;AAJO,CAAf;;IAOM,U;;;AACF,wBAAY,GAAZ,EAAkB,MAAlB,EAA0B;AAAA;;AAAA,4HAChB,GADgB,EAElB,iBAAM,eAFY,EAIlB,iBAAM,cAJY,EAMlB,iBAAM,yBANY,EAOlB,iBAAM,mBAPY,EAQlB,iBAAM,sBARY,EASlB,iBAAM,iBATY;;AAWtB,cAAK,gBAAL,GAAwB,IAAI,IAAJ,EAAxB;;AAEA,cAAK,MAAL,GAAc,MAAd;;AAEA,cAAK,IAAL,GAAY,CAAZ;AACA,cAAK,MAAL,GAAc,YAAY,YAAM;AAC5B,gBAAG,MAAK,MAAL,CAAY,MAAZ,IAAsB,OAAO,OAAhC,EAAwC;AACpC,oBAAG,IAAI,IAAJ,GAAW,OAAX,KAAuB,MAAK,gBAAL,CAAsB,OAAtB,EAAvB,GAAyD,MAAK,MAAL,CAAY,MAAZ,CAAmB,OAAnB,GAA6B,IAAzF,EAA+F;AAC3F;AACA,0BAAK,MAAL,CAAY,IAAZ;AACA,0BAAK,MAAL,CAAY,OAAZ,CAAoB,eAApB;AACH;AACJ;AACD,kBAAK,MAAL,CAAY,kBAAZ,CAA+B,CAAC,MAAK,IAAL,GAAU,MAAX,EAAmB,OAAnB,CAA2B,CAA3B,CAA/B;AACA,kBAAK,IAAL,GAAY,CAAZ;AACH,SAVa,EAUX,IAVW,CAAd;AAhBsB;AA2BzB;;;;kCACS;AACN,iBAAK,MAAL,CAAY,kBAAZ,CAA+B,MAA/B;AACA,0BAAc,KAAK,MAAnB;AACA,mCAAa,SAAb,CAAuB,OAAvB,CAA+B,IAA/B,CAAoC,IAApC;AACH;;;2CAEiB;AACd,iBAAK,MAAL,CAAY,OAAZ,CAAoB,WAApB;AACA,oBAAQ,GAAR,CAAY,mBAAZ;AAEH;;;0CACgB;AACb;AACA,iBAAK,MAAL,CAAY,OAAZ,CAAoB,eAApB;AACA,oBAAQ,GAAR,CAAY,iBAAZ;AACH;;;mDACyB;AACtB;AACA,iBAAK,MAAL,CAAY,OAAZ;AACA,oBAAQ,GAAR,CAAY,0BAAZ;AACH;;;4CAEmB,I,EAAK;AACrB,iBAAK,IAAL,IAAa,IAAb;AACA,iBAAK,gBAAL,GAAwB,IAAI,IAAJ,EAAxB;AACH;;;uCACc,I,EAAK;AAChB,gBAAI;AACA,oBAAI,MAAM,KAAK,KAAL,CAAW,QAAQ,EAAnB,CAAV;AACA,oBAAG,OAAO,IAAI,UAAd,EAAyB;AACrB,yBAAK,MAAL,CAAY,IAAZ;AACA,yBAAK,MAAL,CAAY,OAAZ,CAAoB,IAAI,SAAJ,IAAe,EAAnC;AACH;AACJ,aAND,CAME,OAAO,CAAP,EAAU,CAEX;AACJ;;;6CAEmB;AAChB,gBAAI,CAAC,KAAK,MAAL,CAAY,MAAZ,CAAmB,MAApB,IAA8B,KAAK,MAAL,CAAY,MAAZ,CAAmB,UAArD,EAAgE;AAC5D,qBAAK,MAAL,CAAY,MAAZ,IAAsB,KAAK,MAAL,CAAY,MAAZ,CAAmB,IAAnB,CAAwB,KAAK,MAAL,CAAY,MAAZ,CAAmB,UAA3C,CAAtB;AACH;;AAED,gBAAG,KAAK,MAAL,CAAY,MAAf,EAAsB;AAClB,qBAAK,MAAL,CAAY,KAAZ;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACH;;;;EAlFoB,sB;;IAqFnB,S;;;4BAEyB;AACvB,gBAAI,CAAC,UAAU,aAAf,EAA8B;AAC1B,0BAAU,aAAV,GAA0B;AACtB,wBAAG,iBADmB;AAEtB,gCAAW,MAFW;AAGtB,6BAAS,CAHa;AAItB,yBAAI,+BAJkB;AAKtB,6BAAQ,2BALc;AAMtB,2BAAM,EANgB;AAOtB,8BAAS,EAPa;AAQtB,4BAAO,EARe;AAStB,6BAAS,EATa;AAUtB,4BAAO,IAVe,CAUV;AAVU,iBAA1B;AAYH;AACD,mBAAO,UAAU,aAAjB;AACH;;;AACD,yBAAyB;AAAA,YAAb,MAAa,uEAAJ,EAAI;;AAAA;;AACrB,YAAI,gBAAgB,UAAU,aAA9B;AACA,aAAK,IAAI,IAAT,IAAiB,aAAjB,EAAgC;AAC5B,gBAAI,QAAQ,MAAZ,EAAoB;AAAE;AAAW;AACjC,mBAAO,IAAP,IAAe,cAAc,IAAd,CAAf;AACH;AACD,aAAK,MAAL,GAAc,MAAd;;AAEA,aAAK,MAAL,GAAc,OAAO,IAArB;;AAEA,kBAAU,WAAV;AACA,aAAK,SAAL,GAAiB,SAAS,aAAT,CAAuB,MAAM,KAAK,MAAL,CAAY,EAAzC,CAAjB;AACA,aAAK,SAAL,CAAe,SAAf,GAA2B,KAAK,QAAL,EAA3B;AACA,aAAK,KAAL,GAAa,KAAK,SAAL,CAAe,aAAf,CAA6B,oBAA7B,CAAb;;AAEA,aAAK,SAAL;AACH;;;;6BACI,M,EAAQ;AACT,gBAAG,UAAU,OAAO,UAApB,EAA+B;AAC3B,qBAAK,MAAL,CAAY,UAAZ,GAAyB,OAAO,UAAhC;AACA,qBAAK,MAAL,CAAY,OAAZ,GAAsB,OAAO,OAA7B;AACA,qBAAK,MAAL,CAAY,GAAZ,GAAkB,OAAO,GAAzB;AACH;AACD,gBAAG,CAAC,KAAK,MAAL,CAAY,MAAb,IAAuB,CAAC,KAAK,MAAL,CAAY,UAAvC,EAAkD;AAC9C;AACA;AACH;;AAED,gBAAG,KAAK,MAAL,IAAe,OAAO,OAAzB,EAAiC;AAC7B,qBAAK,IAAL;AACH;AACD,iBAAK,MAAL,GAAc,OAAO,OAArB;;AAEA,gBAAI;AACA,qBAAK,SAAL,CAAe,aAAf,CAA6B,YAA7B,EAA2C,OAA3C,IAAoD,EAApD;AACA,qBAAK,SAAL,CAAe,aAAf,CAA6B,eAA7B,EAA8C,OAA9C,IAAuD,eAAvD;AACA,qBAAK,SAAL,CAAe,aAAf,CAA6B,cAA7B,EAA6C,OAA7C,IAAsD,eAAtD;AACH,aAJD,CAIE,OAAO,CAAP,EAAU,CAEX;;AAED,gBAAG,CAAC,KAAK,MAAN,IAAgB,KAAK,MAAL,CAAY,UAAZ,IAA0B,CAA7C,EAA+C;AAC3C,qBAAK,GAAL,GAAW,IAAI,aAAJ,EAAX;AACA,qBAAK,UAAL,GAAkB,IAAI,UAAJ,CAAe,KAAK,GAApB,EAA0B,IAA1B,CAAlB;AACA,qBAAK,GAAL,CAAS,WAAT,CAAqB,KAAK,KAA1B;AACA,qBAAK,MAAL,GAAc,IAAI,SAAJ,CAAc,KAAK,MAAL,CAAY,GAA1B,CAAd;AACA,oBAAI,OAAO,IAAX;AACA,qBAAK,MAAL,CAAY,OAAZ,GAAsB,UAAS,CAAT,EAAY;AAC9B,yBAAK,IAAL;AACA,yBAAK,OAAL,CAAa,gBAAb;AACH,iBAHD;AAIA,qBAAK,GAAL,CAAS,eAAT,CAAyB,KAAK,MAA9B;AACH;;AAGD;AACA;AACA;AACA;AACA;AACA;AACA;AAEH;;;+BAEK;AACF,iBAAK,MAAL,IAAe,cAAc,KAAK,MAAnB,CAAf;AACA,iBAAK,MAAL,GAAc,IAAd;;AAEA,iBAAK,MAAL,GAAc,OAAO,IAArB;AACA,iBAAK,KAAL,CAAW,GAAX,GAAe,GAAf;;AAEA,gBAAI;AACA,qBAAK,SAAL,CAAe,aAAf,CAA6B,YAA7B,EAA2C,OAA3C,IAAoD,eAApD;AACA,qBAAK,SAAL,CAAe,aAAf,CAA6B,eAA7B,EAA8C,OAA9C,IAAuD,EAAvD;AACA,qBAAK,SAAL,CAAe,aAAf,CAA6B,cAA7B,EAA6C,OAA7C,IAAsD,EAAtD;AACH,aAJD,CAIE,OAAO,CAAP,EAAU,CAEX;;AAED,iBAAK,OAAL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,iBAAK,UAAL,IAAmB,KAAK,UAAL,CAAgB,OAAhB,EAAnB;AACA,iBAAK,GAAL,IAAY,KAAK,GAAL,CAAS,OAAT,EAAZ;AACA,iBAAK,MAAL,GAAc,IAAd;AACH;;;gCACM;AAAA;;AACH,iBAAK,MAAL,GAAc,YAAY,YAAM;AAC5B,oBAAG,OAAK,MAAL,IAAe,OAAK,MAAL,CAAY,UAAZ,IAA0B,CAA5C,EAA8C;AAC1C;AACA,2BAAK,MAAL,CAAY,IAAZ,CAAiB,OAAjB;AACH;AACJ,aALa,EAKX,IALW,CAAd;AAMH;AACD;;;;qCACa;AACT,gBAAI,MAAM,KAAK,SAAf;AACA,gBAAI,IAAI,iBAAR,EAA2B;AACvB,oBAAI,iBAAJ;AACH,aAFD,MAEO,IAAI,IAAI,oBAAR,EAA8B;AACjC,oBAAI,oBAAJ;AACH,aAFM,MAEA,IAAI,IAAI,uBAAR,EAAiC;AACpC,oBAAI,uBAAJ;AACH;AACJ;;AAED;;;;yCACiB;AACb,gBAAI,KAAK,QAAT;AACA,gBAAI,GAAG,cAAP,EAAuB;AACnB,mBAAG,cAAH;AACH,aAFD,MAEO,IAAI,GAAG,mBAAP,EAA4B;AAC/B,mBAAG,mBAAH;AACH,aAFM,MAEA,IAAI,GAAG,sBAAP,EAA+B;AAClC,mBAAG,sBAAH;AACH;AACJ;;;oCAEU;AACP,gBAAI,OAAO,IAAX;AACA,iBAAK,KAAL,CAAW,gBAAX,CAA4B,SAA5B,EAAsC,YAAU;AAC5C,qBAAK,OAAL;AACH,aAFD,EAEE,KAFF;AAGA,iBAAK,KAAL,CAAW,gBAAX,CAA4B,SAA5B,EAAsC,YAAU;AAC5C,qBAAK,KAAL,CAAW,IAAX;AACH,aAFD,EAEE,KAFF;;AAIA,iBAAK,SAAL,CAAe,aAAf,CAA6B,aAA7B,EAA4C,gBAA5C,CAA6D,OAA7D,EAAsE,YAAY;AAC9E,qBAAK,KAAL,CAAW,IAAX;AACA,qBAAK,IAAL;AACH,aAHD;AAIA,iBAAK,SAAL,CAAe,aAAf,CAA6B,eAA7B,EAA8C,gBAA9C,CAA+D,OAA/D,EAAuE,YAAY;AAC/E,qBAAK,KAAL,CAAW,IAAX;AACA,qBAAK,IAAL;AACH,aAHD;AAIA,iBAAK,SAAL,CAAe,aAAf,CAA6B,YAA7B,EAA2C,OAA3C,GAAqD,YAAY;AAC7D,qBAAK,IAAL;AACH,aAFD;AAGA,iBAAK,SAAL,CAAe,aAAf,CAA6B,kBAA7B,EAAiD,OAAjD,GAA2D,YAAY;AACnE,oBAAI;AACA,yBAAK,SAAL,CAAe,aAAf,CAA6B,kBAA7B,EAAiD,OAAjD,IAA0D,gBAA1D;AACA,yBAAK,SAAL,CAAe,aAAf,CAA6B,gBAA7B,EAA+C,OAA/C,IAAwD,EAAxD;AACH,iBAHD,CAGE,OAAO,CAAP,EAAU,CAEX;;AAED,qBAAK,UAAL;AACH,aATD;AAUA,iBAAK,SAAL,CAAe,aAAf,CAA6B,gBAA7B,EAA+C,OAA/C,GAAyD,YAAY;AACjE,oBAAI;AACA,yBAAK,SAAL,CAAe,aAAf,CAA6B,gBAA7B,EAA+C,OAA/C,IAAwD,gBAAxD;AACA,yBAAK,SAAL,CAAe,aAAf,CAA6B,kBAA7B,EAAiD,OAAjD,IAA0D,EAA1D;AACH,iBAHD,CAGE,OAAO,CAAP,EAAU,CAEX;;AAED,qBAAK,cAAL;AACH,aATD;;AAWA,iBAAK,SAAL,CAAe,aAAf,CAA6B,cAA7B,EAA6C,WAA7C,GAA2D,YAAY;AACnE,oBAAI;AACA,yBAAK,SAAL,CAAe,aAAf,CAA6B,WAA7B,EAA0C,OAA1C,IAAqD,EAArD;AACH,iBAFD,CAEE,OAAO,CAAP,EAAU,CAEX;AACJ,aAND;AAOA,iBAAK,SAAL,CAAe,aAAf,CAA6B,cAA7B,EAA6C,UAA7C,GAA0D,YAAY;AAClE,oBAAI;AACA,yBAAK,SAAL,CAAe,aAAf,CAA6B,WAA7B,EAA0C,OAA1C,IAAqD,gBAArD;AACH,iBAFD,CAEE,OAAO,CAAP,EAAU,CAEX;AACJ,aAND;AAOH;;;gCAEO,G,EAAK;AACT,gBAAI;AACA,oBAAI,MAAM,KAAK,SAAL,CAAe,aAAf,CAA6B,WAA7B,CAAV;AACA,oBAAI,OAAJ,IAAe,iBAAf;AACA,oBAAI,SAAJ,GAAgB,GAAhB;AACH,aAJD,CAIE,OAAO,CAAP,EAAU,CAEX;AAEJ;;;kCAES;AACN,gBAAI;AACA,qBAAK,SAAL,CAAe,aAAf,CAA6B,WAA7B,EAA0C,OAA1C,IAAqD,gBAArD;AACH,aAFD,CAEE,OAAO,CAAP,EAAU,CAEX;AACJ;;;6CAEiC;AAAA,gBAAf,KAAe,uEAAP,MAAO;;AAC9B,gBAAI;AACA,oBAAI,KAAK,KAAK,SAAL,CAAe,aAAf,CAA6B,aAA7B,CAAT;AACA,mBAAG,SAAH,GAAkB,KAAlB,aAA+B,KAAK,MAAL,CAAY,UAA3C,eAA+D,KAAK,MAAL,CAAY,OAA3E;;AAEA,qBAAK,KAAK,SAAL,CAAe,aAAf,CAA6B,sBAA7B,CAAL;AACA,mBAAG,SAAH,GAAkB,KAAlB;AACH,aAND,CAME,OAAO,CAAP,EAAU,CAEX;AAEJ;;;iCAEQ,I,EAAM,M,EAAQ;AACnB,gBAAI,UAAU,KAAK,aAAL,CAAmB,CAAnB,EAAsB,IAAtB,EAA4B,MAA5B,CAAd;AACA,2GAA6F,OAA7F;AACH;;;sCAEa,K,EAAO;AACjB,qBAAS,aAAT,CAAuB,KAAvB;AACA,2CAA6B,KAA7B,iDAA8E,KAA9E,+CAC6B,KAD7B,0IAEiC,KAFjC,+TAQ2C,KAAK,MAAL,CAAY,UARvD,eAQ2E,KAAK,MAAL,CAAY,OARvF,2IAUsD,KAAK,MAAL,CAAY,UAVlE,eAUsF,KAAK,MAAL,CAAY,OAVlG;AA0BH;;;sCAEoB;AACjB,gBAAG,UAAU,cAAb,EAA4B;AAC5B,sBAAU,cAAV,GAA2B,IAA3B;AACA,gBAAI,QAAQ,SAAS,aAAT,CAAuB,OAAvB,CAAZ;AACA,kBAAM,IAAN,GAAa,UAAb;AACA,kBAAM,SAAN,GAAkB,mBAAlB;AACA,qBAAS,oBAAT,CAA8B,MAA9B,EAAsC,IAAtC,CAA2C,CAA3C,EAA8C,WAA9C,CAA0D,KAA1D;AACH;;;;;;kBAMU,S;;;;;;;;;;;;;AChYf;;;;IAKM,S;AAEJ,qBAAY,MAAZ,EAAoB;AAAA;;AAClB,QAAI,UAAU,OAAO,QAArB,EAA+B;AAC7B,WAAK,QAAL,GAAgB,OAAO,QAAvB;AACD;AACF;;;;8BAES;AACR,WAAK,KAAL;AACA,WAAK,MAAL,GAAc,IAAd;AACD;;;4BAEO;AACN,UAAI,SAAS,KAAK,MAAlB;AACA,UAAI,UAAU,OAAO,UAAP,KAAsB,CAApC,EAAuC;AACrC,aAAK,KAAL,CAAW,OAAX,GAAqB,IAArB;AACA,eAAO,KAAP;AACD;;AAED,aAAO,YAAP,CAAoB,KAAK,cAAzB;AACA,WAAK,cAAL,GAAsB,IAAtB;AACA,aAAO,YAAP,CAAoB,KAAK,YAAzB;AACA,WAAK,YAAL,GAAoB,IAApB;AACD;;;6BAEQ,O,EAAS,M,EAAQ,S,EAAW;AACnC,WAAK,OAAL,GAAe,OAAf;AACA,WAAK,MAAL,GAAc,MAAd;AACA,WAAK,SAAL,GAAiB,SAAjB;AACA,WAAK,KAAL,GAAa,EAAC,UAAU,YAAY,GAAZ,EAAX,EAA8B,OAAO,CAArC,EAAb;AACA,WAAK,UAAL,GAAkB,OAAO,UAAzB;AACA,UAAI,MAAM,IAAI,cAAJ,EAAV;AACA,UAAI,IAAJ,CAAS,MAAT,EAAiB,QAAQ,GAAzB;AACA,UAAI,MAAJ,GAAa,YAAY;AACnB,kBAAU,SAAV,CAAoB,IAAI,iBAAJ,CAAsB,gBAAtB,CAApB;AACL,OAFD;AAGA,UAAI,IAAJ;AACD;;;yBAEI,O,EAAS,M,EAAQ,S,EAAW;AAC/B,WAAK,OAAL,GAAe,OAAf;AACA,WAAK,MAAL,GAAc,MAAd;AACA,WAAK,SAAL,GAAiB,SAAjB;AACA,WAAK,KAAL,GAAa,EAAC,UAAU,YAAY,GAAZ,EAAX,EAA8B,OAAO,CAArC,EAAb;AACA,WAAK,UAAL,GAAkB,OAAO,UAAzB;AACA,WAAK,YAAL;AACD;;;mCAEc;AACb,UAAI,GAAJ;AAAA,UAAS,UAAU,KAAK,OAAxB;AACA,UAAI,OAAO,cAAP,KAA0B,WAA9B,EAA2C;AACxC,cAAM,KAAK,MAAL,GAAc,IAAI,cAAJ,EAApB;AACF,OAFD,MAEO;AACJ,cAAM,KAAK,MAAL,GAAc,IAAI,cAAJ,EAApB;AACF;AACD,UAAI,SAAJ,GAAgB,KAAK,OAAL,CAAa,IAAb,CAAkB,IAAlB,CAAhB;AACA,UAAI,UAAJ,GAAiB,KAAK,YAAL,CAAkB,IAAlB,CAAuB,IAAvB,CAAjB;AACA,UAAI,IAAJ,CAAS,KAAT,EAAgB,QAAQ,GAAxB,EAA6B,IAA7B;AACA,UAAI,QAAQ,QAAZ,EAAsB;AACpB,YAAI,gBAAJ,CAAqB,OAArB,EAA6B,WAAW,QAAQ,UAAnB,GAAgC,GAAhC,IAAuC,QAAQ,QAAR,GAAiB,CAAxD,CAA7B;AACD;AACD,UAAI,YAAJ,GAAmB,QAAQ,YAA3B;AACA,UAAI,QAAQ,KAAK,KAAjB;AACA,YAAM,MAAN,GAAe,CAAf;AACA,YAAM,MAAN,GAAe,CAAf;AACA,UAAI,KAAK,QAAT,EAAmB;AACjB,aAAK,QAAL,CAAc,GAAd,EAAmB,QAAQ,GAA3B;AACD;AACD;AACA,WAAK,cAAL,GAAsB,OAAO,UAAP,CAAkB,KAAK,WAAL,CAAiB,IAAjB,CAAsB,IAAtB,CAAlB,EAA+C,KAAK,MAAL,CAAY,OAA3D,CAAtB;AACA,UAAI,IAAJ;AACD;;;4BAEO,K,EAAO;AACb,UAAI,MAAM,MAAM,aAAhB;AAAA,UACI,SAAS,IAAI,MADjB;AAAA,UAEI,QAAQ,KAAK,KAFjB;AAAA,UAGI,UAAU,KAAK,OAHnB;AAAA,UAII,SAAS,KAAK,MAJlB;AAKA;AACA,UAAI,MAAM,OAAV,EAAmB;AACjB;AACD;AACD;AACA,aAAO,YAAP,CAAoB,KAAK,cAAzB;;AAEA;AACA,UAAI,UAAU,GAAV,IAAiB,SAAS,GAA9B,EAAoC;AAClC,cAAM,KAAN,GAAc,KAAK,GAAL,CAAS,MAAM,MAAf,EAAsB,YAAY,GAAZ,EAAtB,CAAd;AACA,YAAI,aAAJ;AAAA,YAAS,YAAT;AACA,YAAI,QAAQ,YAAR,KAAyB,aAA7B,EAA4C;AAC1C,iBAAO,IAAI,QAAX;AACA,gBAAM,KAAK,UAAX;AACD,SAHD,MAGO;AACL,iBAAO,IAAI,YAAX;AACA,gBAAM,KAAK,MAAX;AACD;AACD,cAAM,MAAN,GAAe,MAAM,KAAN,GAAc,GAA7B;AACA,YAAI,WAAW,EAAE,KAAM,IAAI,WAAZ,EAAyB,MAAO,IAAhC,EAAf;AACA,aAAK,SAAL,CAAe,SAAf,CAAyB,QAAzB,EAAmC,KAAnC,EAA0C,OAA1C;AACD,OAbD,MAaO;AACL;AACA,YAAI,MAAM,KAAN,IAAe,OAAO,QAAtB,IAAmC,UAAU,GAAV,IAAiB,SAAS,GAAjE,EAAuE;AACvE;AACE,eAAK,SAAL,CAAe,OAAf,CAAuB,EAAE,MAAO,MAAT,EAAiB,MAAO,IAAI,UAA5B,EAAvB,EAAgE,OAAhE;AACD,SAHD,MAGO;AACP;AACA;AACE;AACA,eAAK,OAAL;AACA;AACA,eAAK,YAAL,GAAoB,OAAO,UAAP,CAAkB,KAAK,YAAL,CAAkB,IAAlB,CAAuB,IAAvB,CAAlB,EAAgD,KAAK,UAArD,CAApB;AACA;AACA,eAAK,UAAL,GAAkB,KAAK,GAAL,CAAS,IAAI,KAAK,UAAlB,EAA8B,OAAO,aAArC,CAAlB;AACA,gBAAM,KAAN;AACD;AACF;AACF;;;kCAEa;AACd;AACE,WAAK,SAAL,CAAe,SAAf,CAAyB,KAAK,KAA9B,EAAqC,KAAK,OAA1C;AACD;;;iCAEY,K,EAAO;AAClB,UAAI,QAAQ,KAAK,KAAjB;AACA,UAAI,MAAM,MAAN,KAAiB,CAArB,EAAwB;AACtB,cAAM,MAAN,GAAe,KAAK,GAAL,CAAS,YAAY,GAAZ,EAAT,EAA4B,MAAM,QAAlC,CAAf;AACD;AACD,YAAM,MAAN,GAAe,MAAM,MAArB;AACA,UAAI,MAAM,gBAAV,EAA4B;AAC1B,cAAM,KAAN,GAAc,MAAM,KAApB;AACD;AACD,UAAI,aAAa,KAAK,SAAL,CAAe,UAAhC;AACA,UAAI,UAAJ,EAAgB;AACd;AACA,mBAAW,KAAX,EAAkB,KAAK,OAAvB,EAAgC,IAAhC;AACD;AACF;;;;;;kBAGY,S;;;;;ACnJf;;;;;;AAEA,SAAS,cAAT,CAAwB,MAAxB,EAAgC;AAC5B,WAAO,cAAM,GAAN,CAAU,SAAV,CAAoB,WAApB,CAAgC,MAAhC,CAAP;AACH;;AAED;;;;;;;;;AASA,IAAI,SAAS,SAAT,MAAS,GAAW;AACpB,SAAK,IAAL,GAAY,YAAW;AACnB,YAAI,YAAY,EAAhB;AACA;;;;;;AAMA,aAAK,EAAL,GAAU,UAAS,IAAT,EAAe,QAAf,EAAyB;AAC/B,gBAAI,CAAC,UAAU,IAAV,CAAL,EAAsB;AAClB,0BAAU,IAAV,IAAkB,EAAlB;AACH;AACD,sBAAU,IAAV,EAAgB,IAAhB,CAAqB,QAArB;AACH,SALD;AAMA;;;;;;AAMA,aAAK,GAAL,GAAW,UAAS,IAAT,EAAe,QAAf,EAAyB;AAChC,gBAAI,KAAJ;AACA,gBAAI,CAAC,UAAU,IAAV,CAAL,EAAsB;AAClB,uBAAO,KAAP;AACH;AACD,oBAAQ,UAAU,IAAV,EAAgB,OAAhB,CAAwB,QAAxB,CAAR;AACA,sBAAU,IAAV,EAAgB,MAAhB,CAAuB,KAAvB,EAA8B,CAA9B;AACA,mBAAO,QAAQ,CAAC,CAAhB;AACH,SARD;AASA;;;;;AAKA,aAAK,OAAL,GAAe,UAAS,IAAT,EAAe;AAC1B,gBAAI,SAAJ,EAAe,CAAf,EAAkB,MAAlB,EAA0B,IAA1B;AACA,wBAAY,UAAU,IAAV,CAAZ;AACA,gBAAI,CAAC,SAAL,EAAgB;AACZ;AACH;AACD;AACA;AACA;AACA;AACA,gBAAI,UAAU,MAAV,KAAqB,CAAzB,EAA4B;AACxB,yBAAS,UAAU,MAAnB;AACA,qBAAK,IAAI,CAAT,EAAY,IAAI,MAAhB,EAAwB,EAAE,CAA1B,EAA6B;AACzB,8BAAU,CAAV,EAAa,IAAb,CAAkB,IAAlB,EAAwB,UAAU,CAAV,CAAxB;AACH;AACJ,aALD,MAKO;AACH,uBAAO,EAAP;AACA,oBAAI,UAAU,MAAd;AACA,qBAAK,IAAI,CAAT,EAAY,IAAI,UAAU,MAA1B,EAAkC,EAAE,CAApC,EAAuC;AACnC,yBAAK,IAAL,CAAU,UAAU,CAAV,CAAV;AACH;AACD,yBAAS,UAAU,MAAnB;AACA,qBAAK,IAAI,CAAT,EAAY,IAAI,MAAhB,EAAwB,EAAE,CAA1B,EAA6B;AACzB,8BAAU,CAAV,EAAa,KAAb,CAAmB,IAAnB,EAAyB,IAAzB;AACH;AACJ;AACJ,SA1BD;AA2BA;;;AAGA,aAAK,OAAL,GAAe,YAAW;AACtB,wBAAY,EAAZ;AACH,SAFD;AAGH,KAnED;AAoEH,CArED;;AAuEA;;;;;;;;;AASA,OAAO,SAAP,CAAiB,IAAjB,GAAwB,UAAS,WAAT,EAAsB;AAC1C,SAAK,EAAL,CAAQ,MAAR,EAAgB,UAAS,IAAT,EAAe;AAC3B,oBAAY,IAAZ,CAAiB,IAAjB;AACH,KAFD;;AAIA,SAAK,EAAL,CAAQ,MAAR,EAAgB,UAAS,WAAT,EAAsB;AAClC,oBAAY,KAAZ,CAAkB,WAAlB;AACH,KAFD;;AAIA,WAAO,WAAP;AACH,CAVD;;AAYA;AACA;AACA;AACA;AACA,OAAO,SAAP,CAAiB,IAAjB,GAAwB,UAAS,IAAT,EAAe;AACnC,SAAK,OAAL,CAAa,MAAb,EAAqB,IAArB;AACH,CAFD;;AAIA,OAAO,SAAP,CAAiB,KAAjB,GAAyB,UAAS,WAAT,EAAsB;AAC3C,SAAK,OAAL,CAAa,MAAb,EAAqB,WAArB;AACH,CAFD;;AAIA;;;;;AAKA,IAAI,iBAAiB,SAAjB,cAAiB,CAAS,OAAT,EAAkB,cAAlB,EAAkC;AACnD;AACA;AACA;AACA,SAAK,cAAL,GAAsB,CAAtB;AACA,SAAK,cAAL,GAAsB,cAAtB;;AAEA,QAAI,OAAO,QAAQ,KAAf,KAAyB,WAA7B,EAA0C;AACtC,aAAK,WAAL,GAAmB,CAAC,CAAC,QAAQ,KAA7B;AACH,KAFD,MAEO;AACH,aAAK,WAAL,GAAmB,IAAnB;AACH;;AAED,SAAK,aAAL,GAAqB,EAArB;AACA,SAAK,UAAL,GAAkB,IAAlB;AACA,SAAK,YAAL,GAAoB,EAApB;AACA,SAAK,eAAL,GAAuB,EAAvB;AACA,SAAK,eAAL,GAAuB,EAAvB;AACA,SAAK,YAAL,GAAoB,CAApB;AACA,SAAK,aAAL,GAAqB,CAArB;;AAEA,mBAAe,SAAf,CAAyB,IAAzB,CAA8B,IAA9B,CAAmC,IAAnC;;AAEA;AACA,SAAK,IAAL,GAAY,UAAS,MAAT,EAAiB;AACzB;AACA;AACA,YAAI,OAAO,IAAX,EAAiB;AACb,mBAAO,KAAK,eAAL,CAAqB,IAArB,CAA0B,MAA1B,CAAP;AACH;AACD;AACA,YAAI,OAAO,MAAX,EAAmB;AACf,mBAAO,KAAK,eAAL,CAAqB,IAArB,CAA0B,MAA1B,CAAP;AACH;;AAED;AACA;AACA;AACA,aAAK,aAAL,CAAmB,IAAnB,CAAwB,OAAO,KAA/B;AACA,aAAK,YAAL,CAAkB,IAAlB,CAAuB,OAAO,KAA9B;AACA,aAAK,YAAL,IAAqB,OAAO,KAAP,CAAa,UAAlC;;AAEA,YAAI,OAAO,KAAP,CAAa,IAAb,KAAsB,OAA1B,EAAmC;AAC/B,iBAAK,UAAL,GAAkB,OAAO,KAAzB;AACH;AACD,YAAI,OAAO,KAAP,CAAa,IAAb,KAAsB,OAA1B,EAAmC;AAC/B,iBAAK,UAAL,GAAkB,OAAO,KAAzB;AACH;AACJ,KAxBD;AAyBH,CAjDD;;AAmDA;AACA,IAAI,mBAAmB,CACnB,iBADmB,EAEnB,cAFmB,EAGnB,YAHmB,EAInB,wBAJmB,EAKnB,YALmB,CAAvB;;AAQA,IAAI,mBAAmB,CACnB,OADmB,EAEnB,QAFmB,EAGnB,YAHmB,EAInB,UAJmB,EAKnB,sBALmB,CAAvB;;AAQA,eAAe,SAAf,GAA2B,IAAI,MAAJ,EAA3B;AACA,eAAe,SAAf,CAAyB,KAAzB,GAAiC,UAAS,WAAT,EAAsB;AACnD,QACI,SAAS,CADb;AAAA,QAEI,QAAQ;AACJ,kBAAU,EADN;AAEJ,kBAAU,EAFN;AAGJ,cAAM;AAHF,KAFZ;AAAA,QAOI,OAPJ;AAAA,QAQI,GARJ;AAAA,QASI,WATJ;AAAA,QAUI,mBAAmB,CAVvB;AAAA,QAWI,CAXJ;;AAaA,QAAI,KAAK,aAAL,CAAmB,MAAnB,GAA4B,KAAK,cAArC,EAAqD;AACjD,YAAI,gBAAgB,oBAAhB,IACA,gBAAgB,oBADpB,EAC0C;AACtC;AACA;AACA;AACA;AACH,SAND,MAMO,IAAI,KAAK,WAAT,EAAsB;AACzB;AACA;AACA;AACH,SAJM,MAIA,IAAI,KAAK,aAAL,CAAmB,MAAnB,KAA8B,CAAlC,EAAqC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA,iBAAK,aAAL;;AAEA,gBAAI,KAAK,aAAL,IAAsB,KAAK,cAA/B,EAA+C;AAC3C,qBAAK,OAAL,CAAa,MAAb;AACA,qBAAK,aAAL,GAAqB,CAArB;AACH;AACD;AACH;AACJ;;AAED,QAAI,KAAK,UAAT,EAAqB;AACjB,2BAAmB,KAAK,UAAL,CAAgB,iBAAhB,CAAkC,GAArD;AACA,yBAAiB,OAAjB,CAAyB,UAAS,IAAT,EAAe;AACpC,kBAAM,IAAN,CAAW,IAAX,IAAmB,KAAK,UAAL,CAAgB,IAAhB,CAAnB;AACH,SAFD,EAEG,IAFH;AAGH,KALD,MAKO,IAAI,KAAK,UAAT,EAAqB;AACxB,2BAAmB,KAAK,UAAL,CAAgB,iBAAhB,CAAkC,GAArD;AACA,yBAAiB,OAAjB,CAAyB,UAAS,IAAT,EAAe;AACpC,kBAAM,IAAN,CAAW,IAAX,IAAmB,KAAK,UAAL,CAAgB,IAAhB,CAAnB;AACH,SAFD,EAEG,IAFH;AAGH;;AAED,QAAI,KAAK,aAAL,CAAmB,MAAnB,KAA8B,CAAlC,EAAqC;AACjC,cAAM,IAAN,GAAa,KAAK,aAAL,CAAmB,CAAnB,EAAsB,IAAnC;AACH,KAFD,MAEO;AACH,cAAM,IAAN,GAAa,UAAb;AACH;;AAED,SAAK,aAAL,IAAsB,KAAK,aAAL,CAAmB,MAAzC;;AAEA,kBAAc,eAAe,KAAK,aAApB,CAAd;;AAEA;AACA;AACA,UAAM,IAAN,GAAa,IAAI,UAAJ,CAAe,YAAY,UAAZ,GACxB,KAAK,YADI,CAAb;;AAGA;AACA;AACA,UAAM,IAAN,CAAW,GAAX,CAAe,WAAf;AACA,cAAU,YAAY,UAAtB;;AAEA;AACA,SAAK,IAAI,CAAT,EAAY,IAAI,KAAK,YAAL,CAAkB,MAAlC,EAA0C,GAA1C,EAA+C;AAC3C,cAAM,IAAN,CAAW,GAAX,CAAe,KAAK,YAAL,CAAkB,CAAlB,CAAf,EAAqC,MAArC;AACA,kBAAU,KAAK,YAAL,CAAkB,CAAlB,EAAqB,UAA/B;AACH;;AAED;AACA;AACA,SAAK,IAAI,CAAT,EAAY,IAAI,KAAK,eAAL,CAAqB,MAArC,EAA6C,GAA7C,EAAkD;AAC9C,kBAAU,KAAK,eAAL,CAAqB,CAArB,CAAV;AACA,gBAAQ,SAAR,GAAqB,QAAQ,QAAR,GAAmB,gBAAxC;AACA,gBAAQ,SAAR,IAAqB,IAArB;AACA,gBAAQ,OAAR,GAAmB,QAAQ,MAAR,GAAiB,gBAApC;AACA,gBAAQ,OAAR,IAAmB,IAAnB;AACA,cAAM,QAAN,CAAe,IAAf,CAAoB,OAApB;AACH;;AAED;AACA;AACA,SAAK,IAAI,CAAT,EAAY,IAAI,KAAK,eAAL,CAAqB,MAArC,EAA6C,GAA7C,EAAkD;AAC9C,cAAM,KAAK,eAAL,CAAqB,CAArB,CAAN;AACA,YAAI,OAAJ,GAAe,IAAI,GAAJ,GAAU,gBAAzB;AACA,YAAI,OAAJ,IAAe,IAAf;AACA,cAAM,QAAN,CAAe,IAAf,CAAoB,GAApB;AACH;AACD;AACA;AACA,UAAM,QAAN,CAAe,YAAf,GAA8B,KAAK,cAAL,CAAoB,YAAlD;;AAEA;AACA,SAAK,aAAL,CAAmB,MAAnB,GAA4B,CAA5B;AACA,SAAK,UAAL,GAAkB,IAAlB;AACA,SAAK,YAAL,CAAkB,MAAlB,GAA2B,CAA3B;AACA,SAAK,eAAL,CAAqB,MAArB,GAA8B,CAA9B;AACA,SAAK,YAAL,GAAoB,CAApB;AACA,SAAK,eAAL,CAAqB,MAArB,GAA8B,CAA9B;;AAEA;AACA,SAAK,OAAL,CAAa,MAAb,EAAqB,KAArB;;AAEA;AACA,QAAI,KAAK,aAAL,IAAsB,KAAK,cAA/B,EAA+C;AAC3C,aAAK,OAAL,CAAa,MAAb;AACA,aAAK,aAAL,GAAqB,CAArB;AACH;AACJ,CAvHD;;AA0HA,OAAO,OAAP,GAAiB;AACb,kBADa;AAEb;AAFa,CAAjB;;;;;;;;;ACxTA;;;;AACA;;;;AAJA;AACA;AACA;AAOA,IAAI,UAAJ,EAAgB,OAAhB,EAAyB,SAAzB,EAAoC,OAApC,EAA6C,eAA7C;;AAEA;AACA,UAAU,mBAAW;AACjB,QAAI,OAAO,IAAX;AACA,SAAK,IAAL,GAAY,EAAZ;AACA,SAAK,WAAL,GAAmB,CAAnB;AACF,SAAK,SAAL,GAAiB,CAAjB;;AAEE,SAAK,IAAL,GAAY,UAAS,GAAT,EAAc;AACtB,YAAI,IAAI,UAAJ,EAAJ,EAAsB;AAClB,iBAAK,WAAL;AACA,oBAAQ,GAAR,CAAY,cAAc,KAAK,WAA/B;AACH;AACD,aAAK,IAAL,CAAU,IAAV,CAAe,GAAf;AACA,aAAK,SAAL;AACA;AACH,KARD;;AAUA,SAAK,GAAL,GAAW,YAAW;AAClB,YAAI,KAAK,WAAL,GAAmB,CAAvB,EAA0B;AACtB,mBAAO,IAAP;AACH;;AAED,YAAI,cAAc,CAAlB;AACA,YAAI,OAAO,EAAX;AACA,eAAO,KAAK,IAAL,CAAU,MAAV,GAAmB,CAA1B,EAA6B;AACzB,gBAAI,MAAM,KAAK,IAAL,CAAU,CAAV,CAAV;;AAEA,gBAAI,IAAI,UAAJ,EAAJ,EAAsB;AAClB;AACA,oBAAI,cAAc,CAAlB,EAAqB;AACjB;AACH;;AAED,qBAAK,WAAL;AACA;AACH;;AAED,iBAAK,IAAL,CAAU,KAAK,IAAL,CAAU,KAAV,EAAV;AACA,iBAAK,SAAL;AACH;;AAED,gBAAQ,GAAR,CAAY,iBAAiB,KAAK,SAAlC;AACA,eAAO,IAAP;AACH,KA1BD;AA2BH,CA3CD;;AA6CA;AACA,YAAY,qBAAW;AACnB;AACA,QAAI,gCAAgC,CAApC;AAAA,QACI,iCAAiC,CADrC;AAAA,QAEI,gCAAgC,CAFpC;AAAA,QAGI,kCAAiC,CAHrC;AAAA,QAII,4CAA4C,CAJhD;AAAA,QAKI,yCAAyC,CAL7C;AAAA,QAMI,sCAAsC,CAN1C;;AAQA;AACA;AACA,QAAI,2BAA2B,CAA/B;AAAA,QACI,0BAA0B,CAD9B;AAAA,QAEI,wBAAwB,CAF5B;AAAA,QAGI,yBAAyB,CAH7B;AAAA,QAII,wBAAwB,CAJ5B;AAAA,QAI+B;AAC3B,8BAA0B,EAL9B,CAZmB,CAiBe;;AAElC;;;;;AAKA,QAAI,2BAA2B,CAA/B;AAAA,QACI,4BAA4B,CADhC;AAAA,QAEI,0BAA0B,CAF9B;;AAIA;;;;AAIA,QAAI,yBAAyB,CAA7B;AAAA,QACI,uBAAuB,CAD3B;AAAA,QAEI,+BAA+B,CAFnC;AAAA,QAGI,+BAA+B,CAHnC;AAAA,QAII,+BAA+B,CAJnC;AAAA,QAKI,oBAAoB,CALxB;AAAA,QAMI,oBAAoB,CANxB;AAAA,QAOI,oBAAoB,CAPxB;AAAA,QAQI,oBAAoB,CARxB;AAAA,QASI,oCAAoC,CATxC;AAAA,QAUI,2BAA2B,EAV/B;AAAA,QAWI,yBAAyB,EAX7B;AAAA,QAYI,2BAA2B,EAZ/B;AAAA,QAaI,uBAAuB,EAb3B;AAAA,QAcI,2BAA2B,EAd/B;AAAA,QAeI,0BAA0B,EAf9B;AAAA,QAgBI,sCAAsC,EAhB1C;AAAA,QAiBI,8BAA8B,EAjBlC;;AAmBA;AACA,QAAI,oBAAoB,CAAxB;AAAA,QACI,kBAAkB,CADtB;AAAA,QAEI,mBAAmB,CAFvB;AAAA,QAGI,wBAAwB,CAH5B;;AAKA,QAAI,OAAO,IAAX;AACA,SAAK,GAAL,GAAW;AACP,YAAI,KADG;AAEP,gBAAQ,CAFD,EAEI;AACX,oBAAY,CAHL;AAIP,kBAAU;AAJH,KAAX;AAMA,SAAK,GAAL,GAAW;AACP,YAAI,KADG;AAEP,kBAAU,CAFH;AAGP,aAAK,IAHE;AAIP,aAAK,IAJE;AAKP,wBAAgB;AALT,KAAX;;AAQA;AACA,SAAK,WAAL,GAAmB,UAAS,WAAT,EAAsB;AACrC,gBAAQ,WAAR;AACI,iBAAK,uBAAL;AAA8B,uBAAO,iBAAP;AAC9B,iBAAK,qBAAL;AACA,iBAAK,uBAAL;AACA,iBAAK,qBAAL;AAA4B,uBAAO,eAAP;AAC5B,iBAAK,sBAAL;AAA6B,uBAAO,gBAAP;AAC7B;AAAS,uBAAO,qBAAP;AANb;AAQH,KATD;;AAWA;AACA;AACA;AACA;AACA,SAAK,MAAL,GAAc,UAAS,GAAT,EAAc;AACxB;AACA,YAAI,GAAJ,GAAU,IAAI,GAAd;;AAEA,YAAI,MAAM,IAAI,GAAd;AACA,YAAI,IAAI,UAAJ,GAAiB,CAArB,EAAwB;AACpB,kBAAM,IAAI,KAAJ,CAAU,6BAA6B,IAAI,UAA3C,CAAN;AACH;;AAED;AACA,YAAI,eAAe,IAAI,CAAJ,CAAnB;AACA;AACA;AACA;AACA;AACA,uBAAgB,gBAAgB,CAAjB,GAAsB,IAArC;AACA;AACA,YAAI,gBAAgB,EAApB,EAAwB;AACpB,kBAAM,IAAI,KAAJ,CAAU,8BAA8B,YAAxC,CAAN;AACH;;AAED,YAAI,kBAAkB,IAAI,CAAJ,CAAtB;AACA,cAAM,IAAI,QAAJ,CAAa,CAAb,CAAN;AACA,YAAI,mBAAmB,CAAvB,EAA0B;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAI,IAAI,UAAJ,GAAiB,CAArB,EAAwB;AACpB,sBAAM,IAAI,KAAJ,CAAU,uCAAuC,IAAI,UAArD,CAAN;AACH;;AAED,gBAAI,kBAAkB,IAAI,CAAJ,CAAtB;AACA,iBAAK,GAAL,CAAS,UAAT,GAAsB,IAAI,CAAJ,CAAtB;;AAEA,iBAAK,GAAL,CAAS,QAAT,GAAqB,KAAK,GAAL,CAAS,UAAT,IAAuB,CAAxB,GAA6B,IAAjD;AACA,iBAAK,GAAL,CAAS,UAAT,GAAwB,mBAAmB,CAApB,GAAyB,IAA1B,GAAoC,KAAK,GAAL,CAAS,UAAT,IAAuB,CAAxB,GAA6B,IAAtF;;AAEA,iBAAK,GAAL,CAAS,MAAT,GAAmB,mBAAmB,CAApB,GAAyB,IAA3C;AACA,iBAAK,GAAL,CAAS,EAAT,GAAc,IAAd;AACA,mBAAO,IAAP;AACH;;AAED,YAAI,CAAC,KAAK,GAAL,CAAS,EAAd,EAAkB;AACd,kBAAM,IAAI,KAAJ,CAAU,wBAAV,CAAN;AACH;;AAED;AACA,YAAI,iBAAiB,IAAI,UAAzB;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAI,mBAAmB,IAAI,UAAJ,CAAe,CAAf,CAAvB;AACA,YAAI,mBAAmB,iBAAiB,CAAxC;;AAEA;AACA,yBAAiB,CAAjB,IAAsB,IAAtB;AACA;AACA;AACA;AACA;AACA;AACA,yBAAiB,CAAjB,IAAsB,IAAtB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,YAAI,cAAc,KAAK,WAAL,CAAiB,KAAK,GAAL,CAAS,MAA1B,CAAlB;AACA,yBAAiB,CAAjB,IAAwB,eAAe,CAAhB,GAAqB,IAAtB,GAAgC,KAAK,GAAL,CAAS,UAAT,IAAuB,CAAxB,GAA6B,IAA5D,GAAsE,KAAK,GAAL,CAAS,QAAT,IAAqB,CAAtB,GAA2B,IAAtH;AACA;AACA;AACA;AACA;AACA,yBAAiB,CAAjB,IAAwB,KAAK,GAAL,CAAS,QAAT,IAAqB,CAAtB,GAA2B,IAA5B,GAAsC,oBAAoB,EAArB,GAA2B,IAAtF;;AAEA;AACA;AACA;AACA,yBAAiB,CAAjB,IAAsB,oBAAoB,CAA1C;AACA;AACA,yBAAiB,CAAjB,IAAuB,oBAAoB,CAArB,GAA0B,IAAhD;;AAEA;AACA,yBAAiB,CAAjB,IAAsB,IAAtB;;AAEA,YAAI,OAAO,IAAI,UAAJ,CAAe,gBAAf,CAAX;AACA,aAAK,GAAL,CAAS,gBAAT;AACA,aAAK,GAAL,CAAS,GAAT,EAAc,CAAd;AACA,eAAO,IAAP;AACH,KAhHD;;AAkHA;AACA;AACA,SAAK,QAAL,GAAgB,UAAS,GAAT,EAAc;AAC1B,YAAI,MAAM,IAAI,GAAd;;AAEA;AACA,YAAI,SAAS,EAAC,IAAG,KAAJ,EAAW,MAAK,IAAI,GAAJ,CAAQ,UAAxB;AACT,iBAAI,IAAI,GADC,EACI,KAAI,CADR,EACW,KAAI,CADf,EACkB,iBAAgB,CADlC,EACqC,OAAM,EAD3C,EAC+C,SAAQ,KADvD;AAET,qBAAS,iBAAS,IAAT,EAAe;AACpB,oBAAI,gBAAiB,KAAK,CAAL,IAAU,IAA/B;AACA,oBAAI,iBAAiB,iBAArB,EAAwC;AACpC,yBAAK,OAAL,GAAe,IAAf;AACH;AACD;AACA,qBAAK,KAAL,CAAW,IAAX,CAAgB,IAAhB;AACH;AATQ,SAAb;;AAYA;AACA,eAAO,GAAP,GAAa,CAAb;AACA,eAAO,GAAP,GAAa,OAAO,GAAP,GAAa,OAAO,GAAjC;AACA;AACA,YAAI,GAAJ,GAAU,OAAO,GAAjB;;AAEJ,aAAK,iBAAL,CAAuB,GAAvB;;AAGI,aAAK,gBAAL,CAAsB,GAAtB,EAA2B,MAA3B;AACA,YAAI,CAAC,OAAO,EAAZ,EAAgB;AACf,mBAAO,IAAP;AACA;;AAED,YAAI,QAAQ,KAAK,GAAL,CAAS,GAAjB,IAAwB,QAAQ,KAAK,GAAL,CAAS,GAA7C,EACA;AACC,iBAAK,IAAI,CAAT,IAAc,OAAO,KAArB,EAA4B;AACxB,oBAAI,OAAO,OAAO,KAAP,CAAa,CAAb,CAAX;;AAEA;AACA;AACA,oBAAI,gBAAgB,KAAK,CAAL,IAAQ,IAA5B;;AAEA;AACA,wBAAQ,aAAR;AACI,yBAAK,iBAAL;AACG,6BAAK,GAAL,CAAS,GAAT,GAAe,IAAf;AACE;AACL,yBAAK,iBAAL;AACK,6BAAK,GAAL,CAAS,GAAT,GAAe,IAAf;AACA;AACL;AACI;AARR;AAUH;AACD,gBAAG,KAAK,GAAL,CAAS,GAAT,IAAgB,KAAK,GAAL,CAAS,GAA5B,EACA;AACC,qBAAK,GAAL,CAAS,EAAT,GAAc,IAAd;AACA;AACD;;AAEH,YAAG,SAAS,KAAK,GAAL,CAAS,EAArB,EACA;AACC,mBAAO,IAAP;AACA;AACD,eAAO,KAAK,mBAAL,CAAyB,MAAzB,CAAP;AAED,KA/DD;AAgEA,SAAK,iBAAL,GAAyB,UAAS,GAAT,EAAc;;AAEnC;AACA,aAAK,GAAL,CAAS,QAAT,GAAoB,CAApB;AACA;AACA;AACA;AACH,KAPD;AAQA,SAAK,gBAAL,GAAwB,UAAS,GAAT,EAAc,MAAd,EAAsB;;AAE1C;AACA,YAAI,KAAK,GAAL,CAAS,cAAT,IAA2B,wBAA/B,EAAyD;AACrD;AACA;AACA,gBAAI,CAAC,KAAK,uBAAL,CAA6B,GAA7B,EAAkC,MAAlC,CAAL,EAAgD;AAC5C;AACA,oBAAI,CAAC,KAAK,qBAAL,CAA2B,GAA3B,EAAgC,MAAhC,CAAL,EAA8C;AAC1C,0BAAM,IAAI,KAAJ,CAAU,oCAAV,CAAN;AACH,iBAFD,MAEO;AACH,yBAAK,GAAL,CAAS,cAAT,GAA0B,uBAA1B;AACH;AACJ,aAPD,MAOO;AACH,qBAAK,GAAL,CAAS,cAAT,GAA0B,yBAA1B;AACH;AACJ,SAbD,MAaO,IAAI,KAAK,GAAL,CAAS,cAAT,IAA2B,uBAA/B,EAAwD;AAC3D;AACA,gBAAI,CAAC,KAAK,qBAAL,CAA2B,GAA3B,EAAgC,MAAhC,CAAL,EAA8C;AAC1C,sBAAM,IAAI,KAAJ,CAAU,sBAAV,CAAN;AACH;AACJ,SALM,MAKA;AACH;AACA;AACA,gBAAI,CAAC,KAAK,uBAAL,CAA6B,GAA7B,EAAkC,MAAlC,CAAL,EAAgD;AAC5C;AACA,oBAAI,CAAC,KAAK,qBAAL,CAA2B,GAA3B,EAAgC,MAAhC,CAAL,EAA8C;AAC1C,0BAAM,IAAI,KAAJ,CAAU,oCAAV,CAAN;AACH,iBAFD,MAEO;AACH,yBAAK,GAAL,CAAS,cAAT,GAA0B,uBAA1B;AACH;AACJ;AACJ;AACJ,KAjCD;AAkCA,SAAK,uBAAL,GAA+B,UAAS,GAAT,EAAc,MAAd,EAAsB;AACjD,YAAI,4BAA4B,SAA5B,yBAA4B,CAAS,GAAT,EAAc;AAC1C,gBAAI,IAAI,IAAI,QAAJ,CAAa,CAAb,CAAR;AACA,qBAAS;AACL,oBAAI,EAAE,UAAF,GAAe,CAAnB,EAAsB;AAClB,2BAAO,IAAP;AACH;;AAED;AACA,oBAAI,EAAE,CAAF,KAAQ,IAAR,IAAgB,EAAE,CAAF,KAAQ,IAA5B,EAAkC;AAChC,wBAAI,EAAE,QAAF,CAAW,CAAX,CAAJ;AACE;AACH;;AAED;AACA,oBAAI,EAAE,CAAF,KAAQ,IAAZ,EAAkB;AACd,2BAAO,CAAP;AACH;AACD,oBAAI,EAAE,QAAF,CAAW,CAAX,CAAJ;AACH;;AAED,mBAAO,IAAP;AACH,SArBD;;AAuBA,cAAM,0BAA0B,GAA1B,CAAN;AACA;AACA,YAAI,CAAC,GAAL,EAAU;AACN,mBAAO,KAAP;AACH;;AAED;AACA;AACA;AACA,eAAO,OAAO,IAAI,UAAJ,GAAiB,CAA/B,EAAkC;AAC9B,gBAAI,OAAO,0BAA0B,IAAI,QAAJ,CAAa,CAAb,CAA1B,CAAX;AACA,gBAAI,OAAO,IAAI,QAAJ,CAAa,CAAb,EAAgB,IAAI,UAAJ,IAAkB,OAAM,KAAK,UAAX,GAAsB,CAAxC,KAA8C,OAAM,CAAN,GAAQ,CAAtD,CAAhB,CAAX;AACA,mBAAO,OAAP,CAAe,IAAf;AACA,kBAAM,IAAN;AACH;;AAED,eAAO,EAAP,GAAY,IAAZ;AACA,eAAO,IAAP;AACH,KA1CD;AA2CA,SAAK,qBAAL,GAA6B,UAAS,GAAT,EAAc,MAAd,EAAsB;AAC/C,eAAO,OAAO,IAAI,UAAJ,GAAiB,CAA/B,EAAkC;AAC9B,gBAAI,IAAI,UAAJ,GAAkB,KAAK,GAAL,CAAS,QAAT,GAAoB,CAA1C,EAA8C;AAC1C,sBAAM,IAAI,KAAJ,CAAU,mCAAmC,KAAK,GAAL,CAAS,QAAT,GAAkB,CAArD,IAA0D,SAA1D,GAAsE,IAAI,UAApF,CAAN;AACH;AACD,gBAAI,gBAAgB,CAApB;AACA,gBAAI,KAAK,GAAL,CAAS,QAAT,IAAqB,CAAzB,EAA4B;AACxB,gCAAiB,IAAI,CAAJ,KAAQ,EAAT,GAAc,IAAI,CAAJ,KAAQ,EAAtB,GAA2B,IAAI,CAAJ,KAAQ,CAAnC,GAAuC,IAAI,CAAJ,CAAvD;AACH,aAFD,MAEO,IAAI,KAAK,GAAL,CAAS,QAAT,IAAqB,CAAzB,EAA4B;AAC/B,gCAAiB,IAAI,CAAJ,KAAQ,CAAT,GAAa,IAAI,CAAJ,CAA7B;AACH,aAFM,MAEA;AACH,gCAAgB,IAAI,CAAJ,CAAhB;AACH;AACD,kBAAM,IAAI,QAAJ,CAAa,KAAK,GAAL,CAAS,QAAT,GAAoB,CAAjC,CAAN;;AAEA;AACA;AACA,gBAAI,gBAAgB,CAApB,EAAuB;AACnB,uBAAO,KAAP;AACH;;AAED;AACA,gBAAI,IAAI,UAAJ,GAAiB,aAArB,EAAoC;AAChC,sBAAM,IAAI,KAAJ,CAAU,2BAA2B,aAA3B,GAA2C,SAA3C,GAAuD,IAAI,UAArE,CAAN;AACH;AACD;AACA,gBAAI,OAAO,IAAI,QAAJ,CAAa,CAAb,EAAgB,aAAhB,CAAX;AACA,mBAAO,OAAP,CAAe,IAAf;AACA,kBAAM,IAAI,QAAJ,CAAa,aAAb,CAAN;AACH;;AAED,eAAO,EAAP,GAAY,IAAZ;AACA,eAAO,IAAP;AACH,KAjCD;AAkCA,SAAK,mBAAL,GAA2B,UAAS,MAAT,EAAiB;AACxC;;;;;;AAMA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAwCA,YAAI,oBAAoB,IAAI,UAAJ,CAAe,CAAC,IAAD,EAAO,IAAP,EAAa,IAAb,EAAmB,IAAnB,CAAf,CAAxB;AACA,YAAI,mBAAmB,IAAI,UAAJ,CAAe,CAAC,IAAD,EAAO,IAAP,EAAa,IAAb,CAAf,CAAvB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAI,aAAa,IAAI,UAAJ,CAAe,CAAC,IAAD,EAAO,IAAP,CAAf,CAAjB;;AAEA;AACA,YAAI,YAAY,IAAE,CAAF,GAAK,CAAL,GAAO,KAAK,GAAL,CAAS,GAAT,CAAa,UAApB,GAAgC,CAAhC,GAAkC,KAAK,GAAL,CAAS,GAAT,CAAa,UAA/D;AACA,aAAK,IAAI,CAAT,IAAc,OAAO,KAArB,EAA4B;AACxB,gBAAI,OAAO,OAAO,KAAP,CAAa,CAAb,CAAX;AACA,yBAAa,IAAE,KAAK,UAApB;AACH;AACD,YAAI,QAAQ,IAAI,UAAJ,CAAe,SAAf,CAAZ;AACA,oBAAY,CAAZ;;AAEA;AACA,cAAM,GAAN,CAAU,iBAAV,EAA6B,SAA7B,EAAyC,aAAa,CAAb;AACzC,cAAM,GAAN,CAAU,UAAV,EAAsB,SAAtB,EAAkC,aAAa,CAAb;;AAElC;AACA,YAAI,OAAO,OAAX,EAAoB;AAChB;AACA,gBAAI,KAAK,GAAL,CAAS,GAAT,CAAa,UAAb,GAA0B,CAA9B,EAAiC;AAC7B;AACA,sBAAM,GAAN,CAAU,iBAAV,EAA6B,SAA7B,EAAyC,aAAa,CAAb;AACzC;AACA,sBAAM,GAAN,CAAU,KAAK,GAAL,CAAS,GAAnB,EAAwB,SAAxB,EAAoC,aAAa,KAAK,GAAL,CAAS,GAAT,CAAa,UAA1B;AACvC;AACD;AACA,gBAAI,KAAK,GAAL,CAAS,GAAT,CAAa,UAAb,GAA0B,CAA9B,EAAiC;AAC7B;AACA,sBAAM,GAAN,CAAU,gBAAV,EAA4B,SAA5B,EAAwC,aAAa,CAAb;AACxC;AACA,sBAAM,GAAN,CAAU,KAAK,GAAL,CAAS,GAAnB,EAAwB,SAAxB,EAAoC,aAAa,KAAK,GAAL,CAAS,GAAT,CAAa,UAA1B;AACvC;AACJ;;AAED;AACA,aAAK,IAAI,CAAT,IAAc,OAAO,KAArB,EAA4B;AACxB,gBAAI,OAAO,OAAO,KAAP,CAAa,CAAb,CAAX;;AAEA;AACA;AACA,gBAAI,gBAAgB,KAAK,CAAL,IAAQ,IAA5B;;AAEA;AACA,oBAAQ,aAAR;AACI,qBAAK,iBAAL;AACA,qBAAK,iBAAL;AACA,qBAAK,iCAAL;AACI;AACJ;AACI;AANR;;AASA;AACA,kBAAM,GAAN,CAAU,gBAAV,EAA4B,SAA5B,EAAwC,aAAa,CAAb;AACxC;AACA,kBAAM,GAAN,CAAU,IAAV,EAAgB,SAAhB,EAA4B,aAAa,KAAK,UAAlB;AAC/B;;AAED;AACA,YAAI,SAAS,MAAM,QAAN,CAAe,CAAf,EAAkB,SAAlB,CAAb;AACA,eAAO,MAAP;AACH,KA9ID;AA+IH,CAlhBD;;AAohBA;AACA,UAAU,mBAAW;AACjB,QAAI,OAAO,IAAX;AACA,SAAK,IAAL,GAAY,KAAK,GAAL,GAAW,KAAK,GAAL,GAAW,CAAlC,CAFiB,CAEoB;AACrC,SAAK,GAAL,GAAW,IAAX,CAHiB,CAGA;;AAEjB,SAAK,OAAL,GAAe,YAAW;AACtB,eAAO,KAAP;AACH,KAFD;AAGA,SAAK,OAAL,GAAe,YAAY;AACxB;AACC,eAAO,IAAP;AACH,KAHD;AAIA,SAAK,UAAL,GAAkB,YAAW;AACzB,YAAI,CAAC,KAAK,OAAL,EAAL,EAAqB;AACjB,mBAAO,KAAP;AACH;;AAED,YAAI,KAAK,GAAL,CAAS,UAAT,GAAsB,CAA1B,EAA6B;AACzB,kBAAM,IAAI,KAAJ,CAAU,4BAA4B,KAAK,GAAL,CAAS,UAA/C,CAAN;AACH;AACD;AACA,YAAI,OAAO,KAAX;AACA,YAAG,CAAC,KAAK,GAAL,CAAS,CAAT,IAAc,IAAf,KAAwB,CAAxB,IACD,CAAC,KAAK,GAAL,CAAS,CAAT,IAAc,IAAf,KAAwB,CADvB,IAED,CAAC,KAAK,GAAL,CAAS,CAAT,IAAc,IAAf,KAAwB,CAF1B,EAGA;AACC,mBAAO,IAAP;AACA;AACD,eAAO,IAAP;AACH,KAjBD;AAkBA,SAAK,KAAL,GAAa,YAAW;AACpB,eAAO,KAAP;AACH,KAFD;AAGA,SAAK,KAAL,GAAa,YAAW;AACpB,eAAO,IAAP;AACH,KAFD;AAGA,SAAK,gBAAL,GAAwB,YAAW;AAC/B,eAAO,KAAP;AACH,KAFD;AAGA,SAAK,YAAL,GAAoB,YAAW;AAC3B,eAAO,KAAP;AACH,KAFD;AAGA,SAAK,QAAL,GAAgB,YAAW;AACvB,YAAI,IAAI,KAAK,OAAL,KAAgB,OAAhB,GAAwB,KAAK,OAAL,KAAgB,OAAhB,GAAyB,KAAK,YAAL,KAAqB,MAArB,GAA4B,OAArF;AACA,eAAO,IAAI,IAAJ,GAAW,OAAO,OAAO,KAAK,GAAZ,IAAiB,IAAxB,EAA8B,OAA9B,CAAsC,CAAtC,CAAX,GAAsD,KAAtD,GAA8D,KAAK,GAAL,CAAS,UAAvE,GAAoF,QAA3F;AACH,KAHD;AAIH,CA9CD;;AAgDA;AACA,aAAa,sBAAW;AACpB,QAAI,OAAO,IAAX;AACA,SAAK,MAAL,GAAc;AACV,YAAI,KADM;AAEV,iBAAS,CAFC,EAEE;AACZ,kBAAU,KAHA,EAGO;AACjB,kBAAU,KAJA,CAIO;AAJP,KAAd;AAMA,SAAK,cAAL,GAAsB,IAAtB;AACA,SAAK,KAAL,GAAa,IAAb;AACA,SAAK,GAAL,GAAW,CAAX;;AAEA;AACA;AACA,SAAK,MAAL,GAAc,UAAS,MAAT,EAAiB;AAC3B,YAAI,UAAJ;AACA,YAAI,KAAK,KAAL,IAAc,KAAK,KAAL,CAAW,UAAX,GAAwB,CAA1C,EAA6C;AACzC,yBAAa,IAAI,UAAJ,CAAe,KAAK,KAAL,CAAW,UAAX,GAAwB,OAAO,UAA9C,CAAb;AACA,uBAAW,GAAX,CAAe,KAAK,KAApB;AACA,uBAAW,GAAX,CAAe,MAAf,EAAuB,KAAK,KAAL,CAAW,UAAlC;AACH,SAJD,MAIO;AACH,yBAAa,MAAb;AACH;;AAED,aAAK,KAAL,GAAa,UAAb;AACH,KAXD;;AAaA;AACA;AACA;AACA,SAAK,IAAL,GAAY,YAAU;AAClB,YAAI,aAAa,KAAK,KAAtB;AACA,YAAI,CAAC,UAAL,EAAiB;AACb,mBAAO,IAAP;AACH;;AAED,eAAM,IAAN,EAAY;;AAER;AACA,gBAAI,CAAC,KAAK,MAAL,CAAY,EAAjB,EAAqB;;AAEjB,qBAAK,MAAL,CAAY,EAAZ,GAAiB,IAAjB;AACA,qBAAK,MAAL,CAAY,QAAZ,GAAuB,KAAvB;AACA,qBAAK,MAAL,CAAY,QAAZ,GAAuB,IAAvB;AACH;;AAED;AACA,gBAAI,MAAM,IAAI,OAAJ,EAAV;AACA,gBAAI,GAAJ,GAAU,UAAV;AACA,gBAAI,IAAJ,GAAW,CAAX;AACA,gBAAI,GAAJ,GAAU,KAAK,GAAf;AACA,gBAAI,GAAJ,GAAU,IAAI,GAAd;AACA,iBAAK,KAAL,GAAa,IAAb;AACA,iBAAK,GAAL,IAAY,EAAZ;AACA,mBAAO,GAAP;AACH;;AAED,eAAO,IAAP;AACH,KA5BD;AA6BH,CA3DD;;AA6DA;;;;;;AAMA,kBAAiB,0BAAW;AACxB,QAAI,OAAO,IAAX;AACA,SAAK,GAAL,GAAW,IAAI,UAAJ,EAAX;AACA,SAAK,KAAL,GAAa,IAAI,SAAJ,EAAb;AACA,SAAK,GAAL,GAAW,IAAI,OAAJ,EAAX;AACA,SAAK,EAAL,GAAU,IAAV,CALwB,CAKR;;AAEhB,QAAI,aAAa,EAAC,MAAK,OAAN,EAAc,OAAM,KAApB,EAA0B,mBAAkB,EAAC,qBAAoB,CAArB,EAA5C,EAAjB;AACA,QAAI,aAAa,EAAC,MAAK,OAAN,EAAc,OAAM,MAApB,EAA2B,mBAAkB,EAAC,qBAAoB,CAArB,EAA7C,EAAjB;;AAEA,QAAI,WAAW,EAAf;AACA,aAAS,IAAT,GAAgB,MAAhB,CAXwB,CAWA;AACxB,aAAS,UAAT,GAAsB,IAAI,cAAM,MAAN,CAAa,IAAb,CAAkB,UAAtB,EAAtB;AACA,aAAS,UAAT,GAAsB,cAAM,MAAN,CAAa,IAAb,CAAkB,UAAxC,CAbwB,CAa4B;AACpD,aAAS,kBAAT,GAA8B,IAAI,cAAM,GAAN,CAAU,kBAAd,CAAiC,UAAjC,CAA9B;AACA,aAAS,kBAAT,GAA8B,IAAI,cAAM,GAAN,CAAU,kBAAd,CAAiC,UAAjC,CAA9B;AACA,aAAS,cAAT,GAA0B,IAAI,uBAAJ,CAAmB,EAAnB,EAAuB,EAAC,cAAa,cAAM,IAAN,CAAW,oBAAzB,EAAvB,CAA1B;AACA,aAAS,UAAT,CACK,IADL,CACU,SAAS,kBADnB,EAEK,IAFL,CAEU,SAAS,cAFnB;AAGA;;;;AAIA,oBAAe,SAAf,CAAyB,IAAzB,CAA8B,IAA9B,CAAmC,IAAnC;;AAEA;AACA,aAAS,cAAT,CAAwB,EAAxB,CAA2B,MAA3B,EAAmC,UAAS,OAAT,EAAiB;AAChD;AACA,aAAK,OAAL,CAAa,MAAb,EAAqB,OAArB;AACH,KAHD;;AAKA,SAAK,GAAL,GAAW,UAAS,GAAT,EAAc;AACrB,aAAK,EAAL,GAAU,IAAI,SAAJ,CAAc,GAAd,CAAV;AACA,aAAK,EAAL,CAAQ,SAAR,GAAoB,UAAS,GAAT,EAAc;AAC9B,gBAAI,IAAI,IAAI,IAAZ,CAD8B,CACZ;AAClB,gBAAI,SAAS,IAAI,UAAJ,EAAb;AACA,mBAAO,gBAAP,CAAwB,SAAxB,EAAmC,YAAU;AACzC,oBAAI,QAAQ,IAAI,UAAJ,CAAe,OAAO,MAAtB,CAAZ;AACA,qBAAK,QAAL,CAAc,KAAd;AACH,aAHD;AAIA,mBAAO,iBAAP,CAAyB,CAAzB;AACH,SARD;AASH,KAXD;;AAaA;AACA,SAAK,QAAL,GAAgB,UAAS,KAAT,EAAgB;AAC5B,aAAK,GAAL,CAAS,MAAT,CAAgB,KAAhB;;AAEA,eAAO,IAAP,EAAa;AACT,gBAAI,MAAM,KAAK,GAAL,CAAS,IAAT,EAAV;AACA,gBAAI,CAAC,GAAL,EAAU;AACN;AACH;;AAED,gBAAI,IAAI,gBAAJ,EAAJ,EAA4B;AACxB,oBAAI,IAAI,OAAJ,EAAJ,EAAmB;AACf,yBAAK,KAAL,CAAW,MAAX,CAAkB,GAAlB;AACA;AACH,iBAHD,MAGO;AACH,yBAAK,KAAL,CAAW,QAAX,CAAoB,GAApB;AACA;AACH;AACD;AACH;;AAED;AACA,iBAAK,GAAL,CAAS,IAAT,CAAc,GAAd;AACA,mBAAO,KAAK,UAAL,EAAP,EAA0B,CACzB;AACJ;AACJ,KAzBD;AA0BA;AACA,SAAK,UAAL,GAAkB,YAAW;AACzB;AACA,YAAI,OAAO,KAAK,GAAL,CAAS,GAAT,EAAX;AACA,YAAI,CAAC,IAAL,EAAW;AACP,mBAAO,KAAP;AACH;AACD,YAAI,QAAQ,KAAK,CAAL,CAAZ;AACA,YAAI,OAAO,KAAK,KAAK,MAAL,GAAc,CAAnB,CAAX;AACA;;;AAGA;AACA,aAAK,IAAI,CAAT,IAAc,IAAd,EAAoB;AAChB,gBAAI,MAAM,KAAK,CAAL,CAAV;;AAEA,gBAAI,IAAI,OAAJ,EAAJ,EAAmB;AACf,oBAAI,QAAQ,KAAK,KAAL,CAAW,MAAX,CAAkB,GAAlB,CAAZ;AACA,oBAAI,CAAC,KAAL,EAAY;AACR;AACH;AACD;;AAEA;AACA,yBAAS,UAAT,CAAoB,IAApB,CAAyB,EAAC,MAAK,OAAN,EAAe,SAAQ,GAAvB,EAA4B,KAAI,IAAI,GAAJ,GAAQ,GAAxC,EAA6C,KAAI,IAAI,GAAJ,GAAQ,GAAzD,EAA8D,MAAK,KAAnE,EAAzB;AACH,aATD,MASO,IAAG,IAAI,OAAJ,EAAH,EAAkB;AACrB,oBAAI,QAAQ,KAAK,KAAL,CAAW,QAAX,CAAoB,GAApB,CAAZ;AACA,oBAAI,CAAC,KAAL,EAAY;AACR;AACH;AACD;;AAEA;AACA;AACA,yBAAS,UAAT,CAAoB,IAApB,CAAyB,EAAC,MAAK,OAAN,EAAe,SAAQ,GAAvB,EAA4B,KAAI,IAAI,GAAJ,GAAQ,GAAxC,EAA6C,KAAI,IAAI,GAAJ,GAAQ,GAAzD,EAA8D,MAAK,KAAnE,EAAzB;AACH;AACJ;;AAED,iBAAS,UAAT,CAAoB,KAApB;AACA;;AAEA,eAAO,IAAP;AACH,KAzCD;AA0CH,CAnHD;;AAqHA,gBAAe,SAAf,GAA2B,IAAI,eAAJ,EAA3B;;kBAGe,e;;;AC3zBf;;;AAGA;;;;;;;;AAEA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;AACA;;;;;;;;IAGM,G;;;kCAOiB;AACnB,aAAQ,OAAO,WAAP,IACA,OAAO,OAAO,WAAP,CAAmB,eAA1B,KAA8C,UAD9C,IAEA,OAAO,WAAP,CAAmB,eAAnB,CAAmC,2CAAnC,CAFR;AAGD;;;wBAToB;AACnB;AACA,aAAO,KAAG,WAAV;AACD;;;wBAQmB;AAClB,aAAO,gBAAP;AACD;;;wBAE0B;AACzB,UAAG,CAAC,IAAI,aAAR,EAAuB;AACpB,YAAI,aAAJ,GAAoB;AACnB,yBAAe,IADI;AAEnB,yBAAe,CAAC,CAFG;AAGnB,iBAAO,KAHY;AAInB,mBAAS,SAJU;AAKnB,kBAAQ,mBALW;AAMnB;AACA,uBAAa,UAPM;AAQnB,8BAAoB,KARD;AASnB,+BAAqB,CATF;AAUnB,iCAAuB,IAVJ;AAWnB,sCAA4B,KAXT;AAYnB,oCAA0B,CAZP;AAanB,wCAA8B,IAbX;AAcnB,+BAAqB;AAdF,SAApB;AAgBF;AACD,aAAO,IAAI,aAAX;AACD,K;sBAEwB,a,EAAe;AACtC,UAAI,aAAJ,GAAoB,aAApB;AACD;;;AAED,iBAAyB;AAAA,QAAb,MAAa,uEAAJ,EAAI;;AAAA;;AAEvB,QAAI,gBAAgB,IAAI,aAAxB;AACA,SAAK,IAAI,IAAT,IAAiB,aAAjB,EAAgC;AAC5B,UAAI,QAAQ,MAAZ,EAAoB;AAAE;AAAW;AACjC,aAAO,IAAP,IAAe,cAAc,IAAd,CAAf;AACH;AACD,SAAK,MAAL,GAAc,MAAd;AACA;AACA,QAAI,WAAW,KAAK,QAAL,GAAgB,IAAI,gBAAJ,EAA/B;AACA,aAAS,OAAT,GAAmB,SAAS,OAAT,CAAkB,KAAlB,EAAkC;AAAA,wCAAN,IAAM;AAAN,YAAM;AAAA;;AACnD,eAAS,IAAT,kBAAc,KAAd,EAAqB,KAArB,SAA+B,IAA/B;AACD,KAFD;;AAIA,aAAS,GAAT,GAAe,SAAS,GAAT,CAAc,KAAd,EAA8B;AAAA,yCAAN,IAAM;AAAN,YAAM;AAAA;;AAC3C,eAAS,cAAT,kBAAwB,KAAxB,SAAkC,IAAlC;AACD,KAFD;AAGA,SAAK,EAAL,GAAU,SAAS,EAAT,CAAY,IAAZ,CAAiB,QAAjB,CAAV;AACA,SAAK,GAAL,GAAW,SAAS,GAAT,CAAa,IAAb,CAAkB,QAAlB,CAAX;AACA,SAAK,OAAL,GAAe,SAAS,OAAT,CAAiB,IAAjB,CAAsB,QAAtB,CAAf;;AAEA,SAAK,cAAL,GAAsB,IAAI,wBAAJ,CAAmB,IAAnB,CAAtB;AACA,SAAK,gBAAL,GAAwB,IAAI,0BAAJ,CAAqB,IAArB,CAAxB;AACF;AACE,SAAK,eAAL,GAAuB,IAAI,yBAAJ,CAAoB,IAApB,CAAvB;AACA,SAAK,SAAL,GAAiB,SAAjB;AACD;;;;8BAES;AACR,WAAK,cAAL,CAAoB,OAApB;AACA,WAAK,gBAAL,CAAsB,OAAtB;AACH;AACG,WAAK,eAAL,CAAqB,OAArB;AACD;;;gCAEW,K,EAA6D;AAAA,UAAtD,WAAsD,uEAA1C,KAA0C;AAAA,UAApC,SAAoC,uEAA1B,SAA0B;AAAA,UAAf,aAAe;AAAE;AACzE,WAAK,SAAL,GAAiB,SAAjB;AACA,WAAK,KAAL,GAAa,KAAb;AACA,WAAK,OAAL,CAAa,iBAAM,eAAnB,EAAoC,EAAC,OAAM,KAAP,EAAc,aAAY,WAA1B,EAAuC,WAAU,SAAjD,EAA4D,eAAc,aAA1E,EAApC;AACD;;;oCAEe,S,EAAU,W,EAAa;AACrC,WAAK,OAAL,CAAa,iBAAM,mBAAnB,EAAwC,EAAC,WAAW,SAAZ,EAAuB,WAAU,KAAK,SAAtC,EAAiD,aAAY,WAA7D,EAAxC;AACD;;;;;;kBAIY,G",
  "file": "generated.js",
  "sourceRoot": "",
  "sourcesContent": [
    "(function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c=\"function\"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error(\"Cannot find module '\"+i+\"'\");throw a.code=\"MODULE_NOT_FOUND\",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u=\"function\"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()",
    "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nfunction EventEmitter() {\n  this._events = this._events || {};\n  this._maxListeners = this._maxListeners || undefined;\n}\nmodule.exports = EventEmitter;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nEventEmitter.defaultMaxListeners = 10;\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function(n) {\n  if (!isNumber(n) || n < 0 || isNaN(n))\n    throw TypeError('n must be a positive number');\n  this._maxListeners = n;\n  return this;\n};\n\nEventEmitter.prototype.emit = function(type) {\n  var er, handler, len, args, i, listeners;\n\n  if (!this._events)\n    this._events = {};\n\n  // If there is no 'error' event listener then throw.\n  if (type === 'error') {\n    if (!this._events.error ||\n        (isObject(this._events.error) && !this._events.error.length)) {\n      er = arguments[1];\n      if (er instanceof Error) {\n        throw er; // Unhandled 'error' event\n      } else {\n        // At least give some kind of context to the user\n        var err = new Error('Uncaught, unspecified \"error\" event. (' + er + ')');\n        err.context = er;\n        throw err;\n      }\n    }\n  }\n\n  handler = this._events[type];\n\n  if (isUndefined(handler))\n    return false;\n\n  if (isFunction(handler)) {\n    switch (arguments.length) {\n      // fast cases\n      case 1:\n        handler.call(this);\n        break;\n      case 2:\n        handler.call(this, arguments[1]);\n        break;\n      case 3:\n        handler.call(this, arguments[1], arguments[2]);\n        break;\n      // slower\n      default:\n        args = Array.prototype.slice.call(arguments, 1);\n        handler.apply(this, args);\n    }\n  } else if (isObject(handler)) {\n    args = Array.prototype.slice.call(arguments, 1);\n    listeners = handler.slice();\n    len = listeners.length;\n    for (i = 0; i < len; i++)\n      listeners[i].apply(this, args);\n  }\n\n  return true;\n};\n\nEventEmitter.prototype.addListener = function(type, listener) {\n  var m;\n\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  if (!this._events)\n    this._events = {};\n\n  // To avoid recursion in the case that type === \"newListener\"! Before\n  // adding it to the listeners, first emit \"newListener\".\n  if (this._events.newListener)\n    this.emit('newListener', type,\n              isFunction(listener.listener) ?\n              listener.listener : listener);\n\n  if (!this._events[type])\n    // Optimize the case of one listener. Don't need the extra array object.\n    this._events[type] = listener;\n  else if (isObject(this._events[type]))\n    // If we've already got an array, just append.\n    this._events[type].push(listener);\n  else\n    // Adding the second element, need to change to array.\n    this._events[type] = [this._events[type], listener];\n\n  // Check for listener leak\n  if (isObject(this._events[type]) && !this._events[type].warned) {\n    if (!isUndefined(this._maxListeners)) {\n      m = this._maxListeners;\n    } else {\n      m = EventEmitter.defaultMaxListeners;\n    }\n\n    if (m && m > 0 && this._events[type].length > m) {\n      this._events[type].warned = true;\n      console.error('(node) warning: possible EventEmitter memory ' +\n                    'leak detected. %d listeners added. ' +\n                    'Use emitter.setMaxListeners() to increase limit.',\n                    this._events[type].length);\n      if (typeof console.trace === 'function') {\n        // not supported in IE 10\n        console.trace();\n      }\n    }\n  }\n\n  return this;\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.once = function(type, listener) {\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  var fired = false;\n\n  function g() {\n    this.removeListener(type, g);\n\n    if (!fired) {\n      fired = true;\n      listener.apply(this, arguments);\n    }\n  }\n\n  g.listener = listener;\n  this.on(type, g);\n\n  return this;\n};\n\n// emits a 'removeListener' event iff the listener was removed\nEventEmitter.prototype.removeListener = function(type, listener) {\n  var list, position, length, i;\n\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  if (!this._events || !this._events[type])\n    return this;\n\n  list = this._events[type];\n  length = list.length;\n  position = -1;\n\n  if (list === listener ||\n      (isFunction(list.listener) && list.listener === listener)) {\n    delete this._events[type];\n    if (this._events.removeListener)\n      this.emit('removeListener', type, listener);\n\n  } else if (isObject(list)) {\n    for (i = length; i-- > 0;) {\n      if (list[i] === listener ||\n          (list[i].listener && list[i].listener === listener)) {\n        position = i;\n        break;\n      }\n    }\n\n    if (position < 0)\n      return this;\n\n    if (list.length === 1) {\n      list.length = 0;\n      delete this._events[type];\n    } else {\n      list.splice(position, 1);\n    }\n\n    if (this._events.removeListener)\n      this.emit('removeListener', type, listener);\n  }\n\n  return this;\n};\n\nEventEmitter.prototype.removeAllListeners = function(type) {\n  var key, listeners;\n\n  if (!this._events)\n    return this;\n\n  // not listening for removeListener, no need to emit\n  if (!this._events.removeListener) {\n    if (arguments.length === 0)\n      this._events = {};\n    else if (this._events[type])\n      delete this._events[type];\n    return this;\n  }\n\n  // emit removeListener for all listeners on all events\n  if (arguments.length === 0) {\n    for (key in this._events) {\n      if (key === 'removeListener') continue;\n      this.removeAllListeners(key);\n    }\n    this.removeAllListeners('removeListener');\n    this._events = {};\n    return this;\n  }\n\n  listeners = this._events[type];\n\n  if (isFunction(listeners)) {\n    this.removeListener(type, listeners);\n  } else if (listeners) {\n    // LIFO order\n    while (listeners.length)\n      this.removeListener(type, listeners[listeners.length - 1]);\n  }\n  delete this._events[type];\n\n  return this;\n};\n\nEventEmitter.prototype.listeners = function(type) {\n  var ret;\n  if (!this._events || !this._events[type])\n    ret = [];\n  else if (isFunction(this._events[type]))\n    ret = [this._events[type]];\n  else\n    ret = this._events[type].slice();\n  return ret;\n};\n\nEventEmitter.prototype.listenerCount = function(type) {\n  if (this._events) {\n    var evlistener = this._events[type];\n\n    if (isFunction(evlistener))\n      return 1;\n    else if (evlistener)\n      return evlistener.length;\n  }\n  return 0;\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  return emitter.listenerCount(type);\n};\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * A stream-based aac to mp4 converter. This utility can be used to\n * deliver mp4s to a SourceBuffer on platforms that support native\n * Media Source Extensions.\n */\n'use strict';\nvar Stream = require('../utils/stream.js');\nvar aacUtils = require('./utils');\n\n// Constants\nvar AacStream;\n\n/**\n * Splits an incoming stream of binary data into ADTS and ID3 Frames.\n */\n\nAacStream = function() {\n  var\n    everything = new Uint8Array(),\n    timeStamp = 0;\n\n  AacStream.prototype.init.call(this);\n\n  this.setTimestamp = function(timestamp) {\n    timeStamp = timestamp;\n  };\n\n  this.push = function(bytes) {\n    var\n      frameSize = 0,\n      byteIndex = 0,\n      bytesLeft,\n      chunk,\n      packet,\n      tempLength;\n\n    // If there are bytes remaining from the last segment, prepend them to the\n    // bytes that were pushed in\n    if (everything.length) {\n      tempLength = everything.length;\n      everything = new Uint8Array(bytes.byteLength + tempLength);\n      everything.set(everything.subarray(0, tempLength));\n      everything.set(bytes, tempLength);\n    } else {\n      everything = bytes;\n    }\n\n    while (everything.length - byteIndex >= 3) {\n      if ((everything[byteIndex] === 'I'.charCodeAt(0)) &&\n          (everything[byteIndex + 1] === 'D'.charCodeAt(0)) &&\n          (everything[byteIndex + 2] === '3'.charCodeAt(0))) {\n\n        // Exit early because we don't have enough to parse\n        // the ID3 tag header\n        if (everything.length - byteIndex < 10) {\n          break;\n        }\n\n        // check framesize\n        frameSize = aacUtils.parseId3TagSize(everything, byteIndex);\n\n        // Exit early if we don't have enough in the buffer\n        // to emit a full packet\n        // Add to byteIndex to support multiple ID3 tags in sequence\n        if (byteIndex + frameSize > everything.length) {\n          break;\n        }\n        chunk = {\n          type: 'timed-metadata',\n          data: everything.subarray(byteIndex, byteIndex + frameSize)\n        };\n        this.trigger('data', chunk);\n        byteIndex += frameSize;\n        continue;\n      } else if (((everything[byteIndex] & 0xff) === 0xff) &&\n                 ((everything[byteIndex + 1] & 0xf0) === 0xf0)) {\n\n        // Exit early because we don't have enough to parse\n        // the ADTS frame header\n        if (everything.length - byteIndex < 7) {\n          break;\n        }\n\n        frameSize = aacUtils.parseAdtsSize(everything, byteIndex);\n\n        // Exit early if we don't have enough in the buffer\n        // to emit a full packet\n        if (byteIndex + frameSize > everything.length) {\n          break;\n        }\n\n        packet = {\n          type: 'audio',\n          data: everything.subarray(byteIndex, byteIndex + frameSize),\n          pts: timeStamp,\n          dts: timeStamp\n        };\n        this.trigger('data', packet);\n        byteIndex += frameSize;\n        continue;\n      }\n      byteIndex++;\n    }\n    bytesLeft = everything.length - byteIndex;\n\n    if (bytesLeft > 0) {\n      everything = everything.subarray(byteIndex);\n    } else {\n      everything = new Uint8Array();\n    }\n  };\n\n  this.reset = function() {\n    everything = new Uint8Array();\n    this.trigger('reset');\n  };\n\n  this.endTimeline = function() {\n    everything = new Uint8Array();\n    this.trigger('endedtimeline');\n  };\n};\n\nAacStream.prototype = new Stream();\n\nmodule.exports = AacStream;\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * Utilities to detect basic properties and metadata about Aac data.\n */\n'use strict';\n\nvar ADTS_SAMPLING_FREQUENCIES = [\n  96000,\n  88200,\n  64000,\n  48000,\n  44100,\n  32000,\n  24000,\n  22050,\n  16000,\n  12000,\n  11025,\n  8000,\n  7350\n];\n\nvar parseId3TagSize = function(header, byteIndex) {\n  var\n    returnSize = (header[byteIndex + 6] << 21) |\n                 (header[byteIndex + 7] << 14) |\n                 (header[byteIndex + 8] << 7) |\n                 (header[byteIndex + 9]),\n    flags = header[byteIndex + 5],\n    footerPresent = (flags & 16) >> 4;\n\n  // if we get a negative returnSize clamp it to 0\n  returnSize = returnSize >= 0 ? returnSize : 0;\n\n  if (footerPresent) {\n    return returnSize + 20;\n  }\n  return returnSize + 10;\n};\n\nvar getId3Offset = function(data, offset) {\n  if (data.length - offset < 10 ||\n      data[offset] !== 'I'.charCodeAt(0) ||\n      data[offset + 1] !== 'D'.charCodeAt(0) ||\n      data[offset + 2] !== '3'.charCodeAt(0)) {\n    return offset;\n  }\n\n  offset += parseId3TagSize(data, offset);\n\n  return getId3Offset(data, offset);\n};\n\n\n// TODO: use vhs-utils\nvar isLikelyAacData = function(data) {\n  var offset = getId3Offset(data, 0);\n\n  return data.length >= offset + 2 &&\n    (data[offset] & 0xFF) === 0xFF &&\n    (data[offset + 1] & 0xF0) === 0xF0 &&\n    // verify that the 2 layer bits are 0, aka this\n    // is not mp3 data but aac data.\n    (data[offset + 1] & 0x16) === 0x10;\n};\n\nvar parseSyncSafeInteger = function(data) {\n  return (data[0] << 21) |\n          (data[1] << 14) |\n          (data[2] << 7) |\n          (data[3]);\n};\n\n// return a percent-encoded representation of the specified byte range\n// @see http://en.wikipedia.org/wiki/Percent-encoding\nvar percentEncode = function(bytes, start, end) {\n  var i, result = '';\n  for (i = start; i < end; i++) {\n    result += '%' + ('00' + bytes[i].toString(16)).slice(-2);\n  }\n  return result;\n};\n\n// return the string representation of the specified byte range,\n// interpreted as ISO-8859-1.\nvar parseIso88591 = function(bytes, start, end) {\n  return unescape(percentEncode(bytes, start, end)); // jshint ignore:line\n};\n\nvar parseAdtsSize = function(header, byteIndex) {\n  var\n    lowThree = (header[byteIndex + 5] & 0xE0) >> 5,\n    middle = header[byteIndex + 4] << 3,\n    highTwo = header[byteIndex + 3] & 0x3 << 11;\n\n  return (highTwo | middle) | lowThree;\n};\n\nvar parseType = function(header, byteIndex) {\n  if ((header[byteIndex] === 'I'.charCodeAt(0)) &&\n      (header[byteIndex + 1] === 'D'.charCodeAt(0)) &&\n      (header[byteIndex + 2] === '3'.charCodeAt(0))) {\n    return 'timed-metadata';\n  } else if ((header[byteIndex] & 0xff === 0xff) &&\n             ((header[byteIndex + 1] & 0xf0) === 0xf0)) {\n    return 'audio';\n  }\n  return null;\n};\n\nvar parseSampleRate = function(packet) {\n  var i = 0;\n\n  while (i + 5 < packet.length) {\n    if (packet[i] !== 0xFF || (packet[i + 1] & 0xF6) !== 0xF0) {\n      // If a valid header was not found,  jump one forward and attempt to\n      // find a valid ADTS header starting at the next byte\n      i++;\n      continue;\n    }\n    return ADTS_SAMPLING_FREQUENCIES[(packet[i + 2] & 0x3c) >>> 2];\n  }\n\n  return null;\n};\n\nvar parseAacTimestamp = function(packet) {\n  var frameStart, frameSize, frame, frameHeader;\n\n  // find the start of the first frame and the end of the tag\n  frameStart = 10;\n  if (packet[5] & 0x40) {\n    // advance the frame start past the extended header\n    frameStart += 4; // header size field\n    frameStart += parseSyncSafeInteger(packet.subarray(10, 14));\n  }\n\n  // parse one or more ID3 frames\n  // http://id3.org/id3v2.3.0#ID3v2_frame_overview\n  do {\n    // determine the number of bytes in this frame\n    frameSize = parseSyncSafeInteger(packet.subarray(frameStart + 4, frameStart + 8));\n    if (frameSize < 1) {\n      return null;\n    }\n    frameHeader = String.fromCharCode(packet[frameStart],\n                                      packet[frameStart + 1],\n                                      packet[frameStart + 2],\n                                      packet[frameStart + 3]);\n\n    if (frameHeader === 'PRIV') {\n      frame = packet.subarray(frameStart + 10, frameStart + frameSize + 10);\n\n      for (var i = 0; i < frame.byteLength; i++) {\n        if (frame[i] === 0) {\n          var owner = parseIso88591(frame, 0, i);\n          if (owner === 'com.apple.streaming.transportStreamTimestamp') {\n            var d = frame.subarray(i + 1);\n            var size = ((d[3] & 0x01)  << 30) |\n                       (d[4]  << 22) |\n                       (d[5] << 14) |\n                       (d[6] << 6) |\n                       (d[7] >>> 2);\n            size *= 4;\n            size += d[7] & 0x03;\n\n            return size;\n          }\n          break;\n        }\n      }\n    }\n\n    frameStart += 10; // advance past the frame header\n    frameStart += frameSize; // advance past the frame body\n  } while (frameStart < packet.byteLength);\n  return null;\n};\n\nmodule.exports = {\n  isLikelyAacData: isLikelyAacData,\n  parseId3TagSize: parseId3TagSize,\n  parseAdtsSize: parseAdtsSize,\n  parseType: parseType,\n  parseSampleRate: parseSampleRate,\n  parseAacTimestamp: parseAacTimestamp\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\n'use strict';\n\nvar Stream = require('../utils/stream.js');\nvar ONE_SECOND_IN_TS = require('../utils/clock').ONE_SECOND_IN_TS;\n\nvar AdtsStream;\n\nvar\n  ADTS_SAMPLING_FREQUENCIES = [\n    96000,\n    88200,\n    64000,\n    48000,\n    44100,\n    32000,\n    24000,\n    22050,\n    16000,\n    12000,\n    11025,\n    8000,\n    7350\n  ];\n\n/*\n * Accepts a ElementaryStream and emits data events with parsed\n * AAC Audio Frames of the individual packets. Input audio in ADTS\n * format is unpacked and re-emitted as AAC frames.\n *\n * @see http://wiki.multimedia.cx/index.php?title=ADTS\n * @see http://wiki.multimedia.cx/?title=Understanding_AAC\n */\nAdtsStream = function(handlePartialSegments) {\n  var\n    buffer,\n    frameNum = 0;\n\n  AdtsStream.prototype.init.call(this);\n\n  this.push = function(packet) {\n    var\n      i = 0,\n      frameLength,\n      protectionSkipBytes,\n      frameEnd,\n      oldBuffer,\n      sampleCount,\n      adtsFrameDuration;\n\n    if (!handlePartialSegments) {\n      frameNum = 0;\n    }\n\n    if (packet.type !== 'audio') {\n      // ignore non-audio data\n      return;\n    }\n\n    // Prepend any data in the buffer to the input data so that we can parse\n    // aac frames the cross a PES packet boundary\n    if (buffer) {\n      oldBuffer = buffer;\n      buffer = new Uint8Array(oldBuffer.byteLength + packet.data.byteLength);\n      buffer.set(oldBuffer);\n      buffer.set(packet.data, oldBuffer.byteLength);\n    } else {\n      buffer = packet.data;\n    }\n\n    // unpack any ADTS frames which have been fully received\n    // for details on the ADTS header, see http://wiki.multimedia.cx/index.php?title=ADTS\n    while (i + 5 < buffer.length) {\n\n      // Look for the start of an ADTS header..\n      if ((buffer[i] !== 0xFF) || (buffer[i + 1] & 0xF6) !== 0xF0) {\n        // If a valid header was not found,  jump one forward and attempt to\n        // find a valid ADTS header starting at the next byte\n        i++;\n        continue;\n      }\n\n      // The protection skip bit tells us if we have 2 bytes of CRC data at the\n      // end of the ADTS header\n      protectionSkipBytes = (~buffer[i + 1] & 0x01) * 2;\n\n      // Frame length is a 13 bit integer starting 16 bits from the\n      // end of the sync sequence\n      frameLength = ((buffer[i + 3] & 0x03) << 11) |\n        (buffer[i + 4] << 3) |\n        ((buffer[i + 5] & 0xe0) >> 5);\n\n      sampleCount = ((buffer[i + 6] & 0x03) + 1) * 1024;\n      adtsFrameDuration = (sampleCount * ONE_SECOND_IN_TS) /\n        ADTS_SAMPLING_FREQUENCIES[(buffer[i + 2] & 0x3c) >>> 2];\n\n      frameEnd = i + frameLength;\n\n      // If we don't have enough data to actually finish this ADTS frame, return\n      // and wait for more data\n      if (buffer.byteLength < frameEnd) {\n        return;\n      }\n\n      // Otherwise, deliver the complete AAC frame\n      this.trigger('data', {\n        pts: packet.pts + (frameNum * adtsFrameDuration),\n        dts: packet.dts + (frameNum * adtsFrameDuration),\n        sampleCount: sampleCount,\n        audioobjecttype: ((buffer[i + 2] >>> 6) & 0x03) + 1,\n        channelcount: ((buffer[i + 2] & 1) << 2) |\n          ((buffer[i + 3] & 0xc0) >>> 6),\n        samplerate: ADTS_SAMPLING_FREQUENCIES[(buffer[i + 2] & 0x3c) >>> 2],\n        samplingfrequencyindex: (buffer[i + 2] & 0x3c) >>> 2,\n        // assume ISO/IEC 14496-12 AudioSampleEntry default of 16\n        samplesize: 16,\n        data: buffer.subarray(i + 7 + protectionSkipBytes, frameEnd)\n      });\n\n      frameNum++;\n\n      // If the buffer is empty, clear it and return\n      if (buffer.byteLength === frameEnd) {\n        buffer = undefined;\n        return;\n      }\n\n      // Remove the finished frame from the buffer and start the process again\n      buffer = buffer.subarray(frameEnd);\n    }\n  };\n\n  this.flush = function() {\n    frameNum = 0;\n    this.trigger('done');\n  };\n\n  this.reset = function() {\n    buffer = void 0;\n    this.trigger('reset');\n  };\n\n  this.endTimeline = function() {\n    buffer = void 0;\n    this.trigger('endedtimeline');\n  };\n};\n\nAdtsStream.prototype = new Stream();\n\nmodule.exports = AdtsStream;\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\n'use strict';\n\nvar Stream = require('../utils/stream.js');\nvar ExpGolomb = require('../utils/exp-golomb.js');\n\nvar H264Stream, NalByteStream;\nvar PROFILES_WITH_OPTIONAL_SPS_DATA;\n\n/**\n * Accepts a NAL unit byte stream and unpacks the embedded NAL units.\n */\nNalByteStream = function() {\n  var\n    syncPoint = 0,\n    i,\n    buffer;\n  NalByteStream.prototype.init.call(this);\n\n  /*\n   * Scans a byte stream and triggers a data event with the NAL units found.\n   * @param {Object} data Event received from H264Stream\n   * @param {Uint8Array} data.data The h264 byte stream to be scanned\n   *\n   * @see H264Stream.push\n   */\n  this.push = function(data) {\n    var swapBuffer;\n\n    if (!buffer) {\n      buffer = data.data;\n    } else {\n      swapBuffer = new Uint8Array(buffer.byteLength + data.data.byteLength);\n      swapBuffer.set(buffer);\n      swapBuffer.set(data.data, buffer.byteLength);\n      buffer = swapBuffer;\n    }\n    var len = buffer.byteLength;\n\n    // Rec. ITU-T H.264, Annex B\n    // scan for NAL unit boundaries\n\n    // a match looks like this:\n    // 0 0 1 .. NAL .. 0 0 1\n    // ^ sync point        ^ i\n    // or this:\n    // 0 0 1 .. NAL .. 0 0 0\n    // ^ sync point        ^ i\n\n    // advance the sync point to a NAL start, if necessary\n    for (; syncPoint < len - 3; syncPoint++) {\n      if (buffer[syncPoint + 2] === 1) {\n        // the sync point is properly aligned\n        i = syncPoint + 5;\n        break;\n      }\n    }\n\n    while (i < len) {\n      // look at the current byte to determine if we've hit the end of\n      // a NAL unit boundary\n      switch (buffer[i]) {\n      case 0:\n        // skip past non-sync sequences\n        if (buffer[i - 1] !== 0) {\n          i += 2;\n          break;\n        } else if (buffer[i - 2] !== 0) {\n          i++;\n          break;\n        }\n\n        // deliver the NAL unit if it isn't empty\n        if (syncPoint + 3 !== i - 2) {\n          this.trigger('data', buffer.subarray(syncPoint + 3, i - 2));\n        }\n\n        // drop trailing zeroes\n        do {\n          i++;\n        } while (buffer[i] !== 1 && i < len);\n        syncPoint = i - 2;\n        i += 3;\n        break;\n      case 1:\n        // skip past non-sync sequences\n        if (buffer[i - 1] !== 0 ||\n            buffer[i - 2] !== 0) {\n          i += 3;\n          break;\n        }\n\n        // deliver the NAL unit\n        this.trigger('data', buffer.subarray(syncPoint + 3, i - 2));\n        syncPoint = i - 2;\n        i += 3;\n        break;\n      default:\n        // the current byte isn't a one or zero, so it cannot be part\n        // of a sync sequence\n        i += 3;\n        break;\n      }\n    }\n    // filter out the NAL units that were delivered\n    buffer = buffer.subarray(syncPoint);\n    i -= syncPoint;\n    syncPoint = 0;\n  };\n\n  this.reset = function() {\n    buffer = null;\n    syncPoint = 0;\n    this.trigger('reset');\n  };\n\n  this.flush = function() {\n    // deliver the last buffered NAL unit\n    if (buffer && buffer.byteLength > 3) {\n      this.trigger('data', buffer.subarray(syncPoint + 3));\n    }\n    // reset the stream state\n    buffer = null;\n    syncPoint = 0;\n    this.trigger('done');\n  };\n\n  this.endTimeline = function() {\n    this.flush();\n    this.trigger('endedtimeline');\n  };\n};\nNalByteStream.prototype = new Stream();\n\n// values of profile_idc that indicate additional fields are included in the SPS\n// see Recommendation ITU-T H.264 (4/2013),\n// 7.3.2.1.1 Sequence parameter set data syntax\nPROFILES_WITH_OPTIONAL_SPS_DATA = {\n  100: true,\n  110: true,\n  122: true,\n  244: true,\n  44: true,\n  83: true,\n  86: true,\n  118: true,\n  128: true,\n  138: true,\n  139: true,\n  134: true\n};\n\n/**\n * Accepts input from a ElementaryStream and produces H.264 NAL unit data\n * events.\n */\nH264Stream = function() {\n  var\n    nalByteStream = new NalByteStream(),\n    self,\n    trackId,\n    currentPts,\n    currentDts,\n\n    discardEmulationPreventionBytes,\n    readSequenceParameterSet,\n    skipScalingList;\n\n  H264Stream.prototype.init.call(this);\n  self = this;\n\n  /*\n   * Pushes a packet from a stream onto the NalByteStream\n   *\n   * @param {Object} packet - A packet received from a stream\n   * @param {Uint8Array} packet.data - The raw bytes of the packet\n   * @param {Number} packet.dts - Decode timestamp of the packet\n   * @param {Number} packet.pts - Presentation timestamp of the packet\n   * @param {Number} packet.trackId - The id of the h264 track this packet came from\n   * @param {('video'|'audio')} packet.type - The type of packet\n   *\n   */\n  this.push = function(packet) {\n    if (packet.type !== 'video') {\n      return;\n    }\n    trackId = packet.trackId;\n    currentPts = packet.pts;\n    currentDts = packet.dts;\n\n    nalByteStream.push(packet);\n  };\n\n  /*\n   * Identify NAL unit types and pass on the NALU, trackId, presentation and decode timestamps\n   * for the NALUs to the next stream component.\n   * Also, preprocess caption and sequence parameter NALUs.\n   *\n   * @param {Uint8Array} data - A NAL unit identified by `NalByteStream.push`\n   * @see NalByteStream.push\n   */\n  nalByteStream.on('data', function(data) {\n    var\n      event = {\n        trackId: trackId,\n        pts: currentPts,\n        dts: currentDts,\n        data: data\n      };\n\n    switch (data[0] & 0x1f) {\n    case 0x05:\n      event.nalUnitType = 'slice_layer_without_partitioning_rbsp_idr';\n      break;\n    case 0x06:\n      event.nalUnitType = 'sei_rbsp';\n      event.escapedRBSP = discardEmulationPreventionBytes(data.subarray(1));\n      break;\n    case 0x07:\n      event.nalUnitType = 'seq_parameter_set_rbsp';\n      event.escapedRBSP = discardEmulationPreventionBytes(data.subarray(1));\n      event.config = readSequenceParameterSet(event.escapedRBSP);\n      break;\n    case 0x08:\n      event.nalUnitType = 'pic_parameter_set_rbsp';\n      break;\n    case 0x09:\n      event.nalUnitType = 'access_unit_delimiter_rbsp';\n      break;\n\n    default:\n      break;\n    }\n    // This triggers data on the H264Stream\n    self.trigger('data', event);\n  });\n  nalByteStream.on('done', function() {\n    self.trigger('done');\n  });\n  nalByteStream.on('partialdone', function() {\n    self.trigger('partialdone');\n  });\n  nalByteStream.on('reset', function() {\n    self.trigger('reset');\n  });\n  nalByteStream.on('endedtimeline', function() {\n    self.trigger('endedtimeline');\n  });\n\n  this.flush = function() {\n    nalByteStream.flush();\n  };\n\n  this.partialFlush = function() {\n    nalByteStream.partialFlush();\n  };\n\n  this.reset = function() {\n    nalByteStream.reset();\n  };\n\n  this.endTimeline = function() {\n    nalByteStream.endTimeline();\n  };\n\n  /**\n   * Advance the ExpGolomb decoder past a scaling list. The scaling\n   * list is optionally transmitted as part of a sequence parameter\n   * set and is not relevant to transmuxing.\n   * @param count {number} the number of entries in this scaling list\n   * @param expGolombDecoder {object} an ExpGolomb pointed to the\n   * start of a scaling list\n   * @see Recommendation ITU-T H.264, Section 7.3.2.1.1.1\n   */\n  skipScalingList = function(count, expGolombDecoder) {\n    var\n      lastScale = 8,\n      nextScale = 8,\n      j,\n      deltaScale;\n\n    for (j = 0; j < count; j++) {\n      if (nextScale !== 0) {\n        deltaScale = expGolombDecoder.readExpGolomb();\n        nextScale = (lastScale + deltaScale + 256) % 256;\n      }\n\n      lastScale = (nextScale === 0) ? lastScale : nextScale;\n    }\n  };\n\n  /**\n   * Expunge any \"Emulation Prevention\" bytes from a \"Raw Byte\n   * Sequence Payload\"\n   * @param data {Uint8Array} the bytes of a RBSP from a NAL\n   * unit\n   * @return {Uint8Array} the RBSP without any Emulation\n   * Prevention Bytes\n   */\n  discardEmulationPreventionBytes = function(data) {\n    var\n      length = data.byteLength,\n      emulationPreventionBytesPositions = [],\n      i = 1,\n      newLength, newData;\n\n    // Find all `Emulation Prevention Bytes`\n    while (i < length - 2) {\n      if (data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 0x03) {\n        emulationPreventionBytesPositions.push(i + 2);\n        i += 2;\n      } else {\n        i++;\n      }\n    }\n\n    // If no Emulation Prevention Bytes were found just return the original\n    // array\n    if (emulationPreventionBytesPositions.length === 0) {\n      return data;\n    }\n\n    // Create a new array to hold the NAL unit data\n    newLength = length - emulationPreventionBytesPositions.length;\n    newData = new Uint8Array(newLength);\n    var sourceIndex = 0;\n\n    for (i = 0; i < newLength; sourceIndex++, i++) {\n      if (sourceIndex === emulationPreventionBytesPositions[0]) {\n        // Skip this byte\n        sourceIndex++;\n        // Remove this position index\n        emulationPreventionBytesPositions.shift();\n      }\n      newData[i] = data[sourceIndex];\n    }\n\n    return newData;\n  };\n\n  /**\n   * Read a sequence parameter set and return some interesting video\n   * properties. A sequence parameter set is the H264 metadata that\n   * describes the properties of upcoming video frames.\n   * @param data {Uint8Array} the bytes of a sequence parameter set\n   * @return {object} an object with configuration parsed from the\n   * sequence parameter set, including the dimensions of the\n   * associated video frames.\n   */\n  readSequenceParameterSet = function(data) {\n    var\n      frameCropLeftOffset = 0,\n      frameCropRightOffset = 0,\n      frameCropTopOffset = 0,\n      frameCropBottomOffset = 0,\n      sarScale = 1,\n      expGolombDecoder, profileIdc, levelIdc, profileCompatibility,\n      chromaFormatIdc, picOrderCntType,\n      numRefFramesInPicOrderCntCycle, picWidthInMbsMinus1,\n      picHeightInMapUnitsMinus1,\n      frameMbsOnlyFlag,\n      scalingListCount,\n      sarRatio,\n      aspectRatioIdc,\n      i;\n\n    expGolombDecoder = new ExpGolomb(data);\n    profileIdc = expGolombDecoder.readUnsignedByte(); // profile_idc\n    profileCompatibility = expGolombDecoder.readUnsignedByte(); // constraint_set[0-5]_flag\n    levelIdc = expGolombDecoder.readUnsignedByte(); // level_idc u(8)\n    expGolombDecoder.skipUnsignedExpGolomb(); // seq_parameter_set_id\n\n    // some profiles have more optional data we don't need\n    if (PROFILES_WITH_OPTIONAL_SPS_DATA[profileIdc]) {\n      chromaFormatIdc = expGolombDecoder.readUnsignedExpGolomb();\n      if (chromaFormatIdc === 3) {\n        expGolombDecoder.skipBits(1); // separate_colour_plane_flag\n      }\n      expGolombDecoder.skipUnsignedExpGolomb(); // bit_depth_luma_minus8\n      expGolombDecoder.skipUnsignedExpGolomb(); // bit_depth_chroma_minus8\n      expGolombDecoder.skipBits(1); // qpprime_y_zero_transform_bypass_flag\n      if (expGolombDecoder.readBoolean()) { // seq_scaling_matrix_present_flag\n        scalingListCount = (chromaFormatIdc !== 3) ? 8 : 12;\n        for (i = 0; i < scalingListCount; i++) {\n          if (expGolombDecoder.readBoolean()) { // seq_scaling_list_present_flag[ i ]\n            if (i < 6) {\n              skipScalingList(16, expGolombDecoder);\n            } else {\n              skipScalingList(64, expGolombDecoder);\n            }\n          }\n        }\n      }\n    }\n\n    expGolombDecoder.skipUnsignedExpGolomb(); // log2_max_frame_num_minus4\n    picOrderCntType = expGolombDecoder.readUnsignedExpGolomb();\n\n    if (picOrderCntType === 0) {\n      expGolombDecoder.readUnsignedExpGolomb(); // log2_max_pic_order_cnt_lsb_minus4\n    } else if (picOrderCntType === 1) {\n      expGolombDecoder.skipBits(1); // delta_pic_order_always_zero_flag\n      expGolombDecoder.skipExpGolomb(); // offset_for_non_ref_pic\n      expGolombDecoder.skipExpGolomb(); // offset_for_top_to_bottom_field\n      numRefFramesInPicOrderCntCycle = expGolombDecoder.readUnsignedExpGolomb();\n      for (i = 0; i < numRefFramesInPicOrderCntCycle; i++) {\n        expGolombDecoder.skipExpGolomb(); // offset_for_ref_frame[ i ]\n      }\n    }\n\n    expGolombDecoder.skipUnsignedExpGolomb(); // max_num_ref_frames\n    expGolombDecoder.skipBits(1); // gaps_in_frame_num_value_allowed_flag\n\n    picWidthInMbsMinus1 = expGolombDecoder.readUnsignedExpGolomb();\n    picHeightInMapUnitsMinus1 = expGolombDecoder.readUnsignedExpGolomb();\n\n    frameMbsOnlyFlag = expGolombDecoder.readBits(1);\n    if (frameMbsOnlyFlag === 0) {\n      expGolombDecoder.skipBits(1); // mb_adaptive_frame_field_flag\n    }\n\n    expGolombDecoder.skipBits(1); // direct_8x8_inference_flag\n    if (expGolombDecoder.readBoolean()) { // frame_cropping_flag\n      frameCropLeftOffset = expGolombDecoder.readUnsignedExpGolomb();\n      frameCropRightOffset = expGolombDecoder.readUnsignedExpGolomb();\n      frameCropTopOffset = expGolombDecoder.readUnsignedExpGolomb();\n      frameCropBottomOffset = expGolombDecoder.readUnsignedExpGolomb();\n    }\n    if (expGolombDecoder.readBoolean()) {\n      // vui_parameters_present_flag\n      if (expGolombDecoder.readBoolean()) {\n        // aspect_ratio_info_present_flag\n        aspectRatioIdc = expGolombDecoder.readUnsignedByte();\n        switch (aspectRatioIdc) {\n          case 1: sarRatio = [1, 1]; break;\n          case 2: sarRatio = [12, 11]; break;\n          case 3: sarRatio = [10, 11]; break;\n          case 4: sarRatio = [16, 11]; break;\n          case 5: sarRatio = [40, 33]; break;\n          case 6: sarRatio = [24, 11]; break;\n          case 7: sarRatio = [20, 11]; break;\n          case 8: sarRatio = [32, 11]; break;\n          case 9: sarRatio = [80, 33]; break;\n          case 10: sarRatio = [18, 11]; break;\n          case 11: sarRatio = [15, 11]; break;\n          case 12: sarRatio = [64, 33]; break;\n          case 13: sarRatio = [160, 99]; break;\n          case 14: sarRatio = [4, 3]; break;\n          case 15: sarRatio = [3, 2]; break;\n          case 16: sarRatio = [2, 1]; break;\n          case 255: {\n            sarRatio = [expGolombDecoder.readUnsignedByte() << 8 |\n                        expGolombDecoder.readUnsignedByte(),\n                        expGolombDecoder.readUnsignedByte() << 8 |\n                        expGolombDecoder.readUnsignedByte() ];\n            break;\n          }\n        }\n        if (sarRatio) {\n          sarScale = sarRatio[0] / sarRatio[1];\n        }\n      }\n    }\n    return {\n      profileIdc: profileIdc,\n      levelIdc: levelIdc,\n      profileCompatibility: profileCompatibility,\n      width: Math.ceil((((picWidthInMbsMinus1 + 1) * 16) - frameCropLeftOffset * 2 - frameCropRightOffset * 2) * sarScale),\n      height: ((2 - frameMbsOnlyFlag) * (picHeightInMapUnitsMinus1 + 1) * 16) - (frameCropTopOffset * 2) - (frameCropBottomOffset * 2),\n      sarRatio: sarRatio\n    };\n  };\n\n};\nH264Stream.prototype = new Stream();\n\nmodule.exports = {\n  H264Stream: H264Stream,\n  NalByteStream: NalByteStream\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\nmodule.exports = {\n  Adts: require('./adts'),\n  h264: require('./h264')\n};\n",
    "// constants\nvar AUDIO_PROPERTIES = [\n  'audioobjecttype',\n  'channelcount',\n  'samplerate',\n  'samplingfrequencyindex',\n  'samplesize'\n];\n\nmodule.exports = AUDIO_PROPERTIES;\n",
    "var VIDEO_PROPERTIES = [\n  'width',\n  'height',\n  'profileIdc',\n  'levelIdc',\n  'profileCompatibility',\n  'sarRatio'\n];\n\n\nmodule.exports = VIDEO_PROPERTIES;\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\nvar highPrefix = [33, 16, 5, 32, 164, 27];\nvar lowPrefix = [33, 65, 108, 84, 1, 2, 4, 8, 168, 2, 4, 8, 17, 191, 252];\nvar zeroFill = function(count) {\n  var a = [];\n  while (count--) {\n    a.push(0);\n  }\n  return a;\n};\n\nvar makeTable = function(metaTable) {\n  return Object.keys(metaTable).reduce(function(obj, key) {\n    obj[key] = new Uint8Array(metaTable[key].reduce(function(arr, part) {\n      return arr.concat(part);\n    }, []));\n    return obj;\n  }, {});\n};\n\n\nvar silence;\n\nmodule.exports = function() {\n  if (!silence) {\n    // Frames-of-silence to use for filling in missing AAC frames\n    var coneOfSilence = {\n      96000: [highPrefix, [227, 64], zeroFill(154), [56]],\n      88200: [highPrefix, [231], zeroFill(170), [56]],\n      64000: [highPrefix, [248, 192], zeroFill(240), [56]],\n      48000: [highPrefix, [255, 192], zeroFill(268), [55, 148, 128], zeroFill(54), [112]],\n      44100: [highPrefix, [255, 192], zeroFill(268), [55, 163, 128], zeroFill(84), [112]],\n      32000: [highPrefix, [255, 192], zeroFill(268), [55, 234], zeroFill(226), [112]],\n      24000: [highPrefix, [255, 192], zeroFill(268), [55, 255, 128], zeroFill(268), [111, 112], zeroFill(126), [224]],\n      16000: [highPrefix, [255, 192], zeroFill(268), [55, 255, 128], zeroFill(268), [111, 255], zeroFill(269), [223, 108], zeroFill(195), [1, 192]],\n      12000: [lowPrefix, zeroFill(268), [3, 127, 248], zeroFill(268), [6, 255, 240], zeroFill(268), [13, 255, 224], zeroFill(268), [27, 253, 128], zeroFill(259), [56]],\n      11025: [lowPrefix, zeroFill(268), [3, 127, 248], zeroFill(268), [6, 255, 240], zeroFill(268), [13, 255, 224], zeroFill(268), [27, 255, 192], zeroFill(268), [55, 175, 128], zeroFill(108), [112]],\n      8000: [lowPrefix, zeroFill(268), [3, 121, 16], zeroFill(47), [7]]\n    };\n    silence = makeTable(coneOfSilence);\n  }\n  return silence;\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\n'use strict';\n\nvar Stream = require('../utils/stream.js');\n\n/**\n * The final stage of the transmuxer that emits the flv tags\n * for audio, video, and metadata. Also tranlates in time and\n * outputs caption data and id3 cues.\n */\nvar CoalesceStream = function(options) {\n  // Number of Tracks per output segment\n  // If greater than 1, we combine multiple\n  // tracks into a single segment\n  this.numberOfTracks = 0;\n  this.metadataStream = options.metadataStream;\n\n  this.videoTags = [];\n  this.audioTags = [];\n  this.videoTrack = null;\n  this.audioTrack = null;\n  this.pendingCaptions = [];\n  this.pendingMetadata = [];\n  this.pendingTracks = 0;\n  this.processedTracks = 0;\n\n  CoalesceStream.prototype.init.call(this);\n\n  // Take output from multiple\n  this.push = function(output) {\n    // buffer incoming captions until the associated video segment\n    // finishes\n    if (output.text) {\n      return this.pendingCaptions.push(output);\n    }\n    // buffer incoming id3 tags until the final flush\n    if (output.frames) {\n      return this.pendingMetadata.push(output);\n    }\n\n    if (output.track.type === 'video') {\n      this.videoTrack = output.track;\n      this.videoTags = output.tags;\n      this.pendingTracks++;\n    }\n    if (output.track.type === 'audio') {\n      this.audioTrack = output.track;\n      this.audioTags = output.tags;\n      this.pendingTracks++;\n    }\n  };\n};\n\nCoalesceStream.prototype = new Stream();\nCoalesceStream.prototype.flush = function(flushSource) {\n  var\n    id3,\n    caption,\n    i,\n    timelineStartPts,\n    event = {\n      tags: {},\n      captions: [],\n      captionStreams: {},\n      metadata: []\n    };\n\n  if (this.pendingTracks < this.numberOfTracks) {\n    if (flushSource !== 'VideoSegmentStream' &&\n        flushSource !== 'AudioSegmentStream') {\n      // Return because we haven't received a flush from a data-generating\n      // portion of the segment (meaning that we have only recieved meta-data\n      // or captions.)\n      return;\n    } else if (this.pendingTracks === 0) {\n      // In the case where we receive a flush without any data having been\n      // received we consider it an emitted track for the purposes of coalescing\n      // `done` events.\n      // We do this for the case where there is an audio and video track in the\n      // segment but no audio data. (seen in several playlists with alternate\n      // audio tracks and no audio present in the main TS segments.)\n      this.processedTracks++;\n\n      if (this.processedTracks < this.numberOfTracks) {\n        return;\n      }\n    }\n  }\n\n  this.processedTracks += this.pendingTracks;\n  this.pendingTracks = 0;\n\n  if (this.processedTracks < this.numberOfTracks) {\n    return;\n  }\n\n  if (this.videoTrack) {\n    timelineStartPts = this.videoTrack.timelineStartInfo.pts;\n  } else if (this.audioTrack) {\n    timelineStartPts = this.audioTrack.timelineStartInfo.pts;\n  }\n\n  event.tags.videoTags = this.videoTags;\n  event.tags.audioTags = this.audioTags;\n\n  // Translate caption PTS times into second offsets into the\n  // video timeline for the segment, and add track info\n  for (i = 0; i < this.pendingCaptions.length; i++) {\n    caption = this.pendingCaptions[i];\n    caption.startTime = caption.startPts - timelineStartPts;\n    caption.startTime /= 90e3;\n    caption.endTime = caption.endPts - timelineStartPts;\n    caption.endTime /= 90e3;\n    event.captionStreams[caption.stream] = true;\n    event.captions.push(caption);\n  }\n\n  // Translate ID3 frame PTS times into second offsets into the\n  // video timeline for the segment\n  for (i = 0; i < this.pendingMetadata.length; i++) {\n    id3 = this.pendingMetadata[i];\n    id3.cueTime = id3.pts - timelineStartPts;\n    id3.cueTime /= 90e3;\n    event.metadata.push(id3);\n  }\n  // We add this to every single emitted segment even though we only need\n  // it for the first\n  event.metadata.dispatchType = this.metadataStream.dispatchType;\n\n  // Reset stream state\n  this.videoTrack = null;\n  this.audioTrack = null;\n  this.videoTags = [];\n  this.audioTags = [];\n  this.pendingCaptions.length = 0;\n  this.pendingMetadata.length = 0;\n  this.pendingTracks = 0;\n  this.processedTracks = 0;\n\n  // Emit the final segment\n  this.trigger('data', event);\n\n  this.trigger('done');\n};\n\nmodule.exports = CoalesceStream;\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\n'use strict';\n\nvar FlvTag = require('./flv-tag.js');\n\n// For information on the FLV format, see\n// http://download.macromedia.com/f4v/video_file_format_spec_v10_1.pdf.\n// Technically, this function returns the header and a metadata FLV tag\n// if duration is greater than zero\n// duration in seconds\n// @return {object} the bytes of the FLV header as a Uint8Array\nvar getFlvHeader = function(duration, audio, video) { // :ByteArray {\n  var\n    headBytes = new Uint8Array(3 + 1 + 1 + 4),\n    head = new DataView(headBytes.buffer),\n    metadata,\n    result,\n    metadataLength;\n\n  // default arguments\n  duration = duration || 0;\n  audio = audio === undefined ? true : audio;\n  video = video === undefined ? true : video;\n\n  // signature\n  head.setUint8(0, 0x46); // 'F'\n  head.setUint8(1, 0x4c); // 'L'\n  head.setUint8(2, 0x56); // 'V'\n\n  // version\n  head.setUint8(3, 0x01);\n\n  // flags\n  head.setUint8(4, (audio ? 0x04 : 0x00) | (video ? 0x01 : 0x00));\n\n  // data offset, should be 9 for FLV v1\n  head.setUint32(5, headBytes.byteLength);\n\n  // init the first FLV tag\n  if (duration <= 0) {\n    // no duration available so just write the first field of the first\n    // FLV tag\n    result = new Uint8Array(headBytes.byteLength + 4);\n    result.set(headBytes);\n    result.set([0, 0, 0, 0], headBytes.byteLength);\n    return result;\n  }\n\n  // write out the duration metadata tag\n  metadata = new FlvTag(FlvTag.METADATA_TAG);\n  metadata.pts = metadata.dts = 0;\n  metadata.writeMetaDataDouble('duration', duration);\n  metadataLength = metadata.finalize().length;\n  result = new Uint8Array(headBytes.byteLength + metadataLength);\n  result.set(headBytes);\n  result.set(head.byteLength, metadataLength);\n\n  return result;\n};\n\nmodule.exports = getFlvHeader;\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * An object that stores the bytes of an FLV tag and methods for\n * querying and manipulating that data.\n * @see http://download.macromedia.com/f4v/video_file_format_spec_v10_1.pdf\n */\n'use strict';\n\nvar FlvTag;\n\n// (type:uint, extraData:Boolean = false) extends ByteArray\nFlvTag = function(type, extraData) {\n  var\n    // Counter if this is a metadata tag, nal start marker if this is a video\n    // tag. unused if this is an audio tag\n    adHoc = 0, // :uint\n\n    // The default size is 16kb but this is not enough to hold iframe\n    // data and the resizing algorithm costs a bit so we create a larger\n    // starting buffer for video tags\n    bufferStartSize = 16384,\n\n    // checks whether the FLV tag has enough capacity to accept the proposed\n    // write and re-allocates the internal buffers if necessary\n    prepareWrite = function(flv, count) {\n      var\n        bytes,\n        minLength = flv.position + count;\n      if (minLength < flv.bytes.byteLength) {\n        // there's enough capacity so do nothing\n        return;\n      }\n\n      // allocate a new buffer and copy over the data that will not be modified\n      bytes = new Uint8Array(minLength * 2);\n      bytes.set(flv.bytes.subarray(0, flv.position), 0);\n      flv.bytes = bytes;\n      flv.view = new DataView(flv.bytes.buffer);\n    },\n\n    // commonly used metadata properties\n    widthBytes = FlvTag.widthBytes || new Uint8Array('width'.length),\n    heightBytes = FlvTag.heightBytes || new Uint8Array('height'.length),\n    videocodecidBytes = FlvTag.videocodecidBytes || new Uint8Array('videocodecid'.length),\n    i;\n\n  if (!FlvTag.widthBytes) {\n    // calculating the bytes of common metadata names ahead of time makes the\n    // corresponding writes faster because we don't have to loop over the\n    // characters\n    // re-test with test/perf.html if you're planning on changing this\n    for (i = 0; i < 'width'.length; i++) {\n      widthBytes[i] = 'width'.charCodeAt(i);\n    }\n    for (i = 0; i < 'height'.length; i++) {\n      heightBytes[i] = 'height'.charCodeAt(i);\n    }\n    for (i = 0; i < 'videocodecid'.length; i++) {\n      videocodecidBytes[i] = 'videocodecid'.charCodeAt(i);\n    }\n\n    FlvTag.widthBytes = widthBytes;\n    FlvTag.heightBytes = heightBytes;\n    FlvTag.videocodecidBytes = videocodecidBytes;\n  }\n\n  this.keyFrame = false; // :Boolean\n\n  switch (type) {\n  case FlvTag.VIDEO_TAG:\n    this.length = 16;\n    // Start the buffer at 256k\n    bufferStartSize *= 6;\n    break;\n  case FlvTag.AUDIO_TAG:\n    this.length = 13;\n    this.keyFrame = true;\n    break;\n  case FlvTag.METADATA_TAG:\n    this.length = 29;\n    this.keyFrame = true;\n    break;\n  default:\n    throw new Error('Unknown FLV tag type');\n  }\n\n  this.bytes = new Uint8Array(bufferStartSize);\n  this.view = new DataView(this.bytes.buffer);\n  this.bytes[0] = type;\n  this.position = this.length;\n  this.keyFrame = extraData; // Defaults to false\n\n  // presentation timestamp\n  this.pts = 0;\n  // decoder timestamp\n  this.dts = 0;\n\n  // ByteArray#writeBytes(bytes:ByteArray, offset:uint = 0, length:uint = 0)\n  this.writeBytes = function(bytes, offset, length) {\n    var\n      start = offset || 0,\n      end;\n    length = length || bytes.byteLength;\n    end = start + length;\n\n    prepareWrite(this, length);\n    this.bytes.set(bytes.subarray(start, end), this.position);\n\n    this.position += length;\n    this.length = Math.max(this.length, this.position);\n  };\n\n  // ByteArray#writeByte(value:int):void\n  this.writeByte = function(byte) {\n    prepareWrite(this, 1);\n    this.bytes[this.position] = byte;\n    this.position++;\n    this.length = Math.max(this.length, this.position);\n  };\n\n  // ByteArray#writeShort(value:int):void\n  this.writeShort = function(short) {\n    prepareWrite(this, 2);\n    this.view.setUint16(this.position, short);\n    this.position += 2;\n    this.length = Math.max(this.length, this.position);\n  };\n\n  // Negative index into array\n  // (pos:uint):int\n  this.negIndex = function(pos) {\n    return this.bytes[this.length - pos];\n  };\n\n  // The functions below ONLY work when this[0] == VIDEO_TAG.\n  // We are not going to check for that because we dont want the overhead\n  // (nal:ByteArray = null):int\n  this.nalUnitSize = function() {\n    if (adHoc === 0) {\n      return 0;\n    }\n\n    return this.length - (adHoc + 4);\n  };\n\n  this.startNalUnit = function() {\n    // remember position and add 4 bytes\n    if (adHoc > 0) {\n      throw new Error('Attempted to create new NAL wihout closing the old one');\n    }\n\n    // reserve 4 bytes for nal unit size\n    adHoc = this.length;\n    this.length += 4;\n    this.position = this.length;\n  };\n\n  // (nal:ByteArray = null):void\n  this.endNalUnit = function(nalContainer) {\n    var\n      nalStart, // :uint\n      nalLength; // :uint\n\n    // Rewind to the marker and write the size\n    if (this.length === adHoc + 4) {\n      // we started a nal unit, but didnt write one, so roll back the 4 byte size value\n      this.length -= 4;\n    } else if (adHoc > 0) {\n      nalStart = adHoc + 4;\n      nalLength = this.length - nalStart;\n\n      this.position = adHoc;\n      this.view.setUint32(this.position, nalLength);\n      this.position = this.length;\n\n      if (nalContainer) {\n        // Add the tag to the NAL unit\n        nalContainer.push(this.bytes.subarray(nalStart, nalStart + nalLength));\n      }\n    }\n\n    adHoc = 0;\n  };\n\n  /**\n   * Write out a 64-bit floating point valued metadata property. This method is\n   * called frequently during a typical parse and needs to be fast.\n   */\n  // (key:String, val:Number):void\n  this.writeMetaDataDouble = function(key, val) {\n    var i;\n    prepareWrite(this, 2 + key.length + 9);\n\n    // write size of property name\n    this.view.setUint16(this.position, key.length);\n    this.position += 2;\n\n    // this next part looks terrible but it improves parser throughput by\n    // 10kB/s in my testing\n\n    // write property name\n    if (key === 'width') {\n      this.bytes.set(widthBytes, this.position);\n      this.position += 5;\n    } else if (key === 'height') {\n      this.bytes.set(heightBytes, this.position);\n      this.position += 6;\n    } else if (key === 'videocodecid') {\n      this.bytes.set(videocodecidBytes, this.position);\n      this.position += 12;\n    } else {\n      for (i = 0; i < key.length; i++) {\n        this.bytes[this.position] = key.charCodeAt(i);\n        this.position++;\n      }\n    }\n\n    // skip null byte\n    this.position++;\n\n    // write property value\n    this.view.setFloat64(this.position, val);\n    this.position += 8;\n\n    // update flv tag length\n    this.length = Math.max(this.length, this.position);\n    ++adHoc;\n  };\n\n  // (key:String, val:Boolean):void\n  this.writeMetaDataBoolean = function(key, val) {\n    var i;\n    prepareWrite(this, 2);\n    this.view.setUint16(this.position, key.length);\n    this.position += 2;\n    for (i = 0; i < key.length; i++) {\n      // if key.charCodeAt(i) >= 255, handle error\n      prepareWrite(this, 1);\n      this.bytes[this.position] = key.charCodeAt(i);\n      this.position++;\n    }\n    prepareWrite(this, 2);\n    this.view.setUint8(this.position, 0x01);\n    this.position++;\n    this.view.setUint8(this.position, val ? 0x01 : 0x00);\n    this.position++;\n    this.length = Math.max(this.length, this.position);\n    ++adHoc;\n  };\n\n  // ():ByteArray\n  this.finalize = function() {\n    var\n      dtsDelta, // :int\n      len; // :int\n\n    switch (this.bytes[0]) {\n      // Video Data\n    case FlvTag.VIDEO_TAG:\n       // We only support AVC, 1 = key frame (for AVC, a seekable\n       // frame), 2 = inter frame (for AVC, a non-seekable frame)\n      this.bytes[11] = ((this.keyFrame || extraData) ? 0x10 : 0x20) | 0x07;\n      this.bytes[12] = extraData ?  0x00 : 0x01;\n\n      dtsDelta = this.pts - this.dts;\n      this.bytes[13] = (dtsDelta & 0x00FF0000) >>> 16;\n      this.bytes[14] = (dtsDelta & 0x0000FF00) >>>  8;\n      this.bytes[15] = (dtsDelta & 0x000000FF) >>>  0;\n      break;\n\n    case FlvTag.AUDIO_TAG:\n      this.bytes[11] = 0xAF; // 44 kHz, 16-bit stereo\n      this.bytes[12] = extraData ? 0x00 : 0x01;\n      break;\n\n    case FlvTag.METADATA_TAG:\n      this.position = 11;\n      this.view.setUint8(this.position, 0x02); // String type\n      this.position++;\n      this.view.setUint16(this.position, 0x0A); // 10 Bytes\n      this.position += 2;\n      // set \"onMetaData\"\n      this.bytes.set([0x6f, 0x6e, 0x4d, 0x65,\n                      0x74, 0x61, 0x44, 0x61,\n                      0x74, 0x61], this.position);\n      this.position += 10;\n      this.bytes[this.position] = 0x08; // Array type\n      this.position++;\n      this.view.setUint32(this.position, adHoc);\n      this.position = this.length;\n      this.bytes.set([0, 0, 9], this.position);\n      this.position += 3; // End Data Tag\n      this.length = this.position;\n      break;\n    }\n\n    len = this.length - 11;\n\n    // write the DataSize field\n    this.bytes[ 1] = (len & 0x00FF0000) >>> 16;\n    this.bytes[ 2] = (len & 0x0000FF00) >>>  8;\n    this.bytes[ 3] = (len & 0x000000FF) >>>  0;\n    // write the Timestamp\n    this.bytes[ 4] = (this.dts & 0x00FF0000) >>> 16;\n    this.bytes[ 5] = (this.dts & 0x0000FF00) >>>  8;\n    this.bytes[ 6] = (this.dts & 0x000000FF) >>>  0;\n    this.bytes[ 7] = (this.dts & 0xFF000000) >>> 24;\n    // write the StreamID\n    this.bytes[ 8] = 0;\n    this.bytes[ 9] = 0;\n    this.bytes[10] = 0;\n\n    // Sometimes we're at the end of the view and have one slot to write a\n    // uint32, so, prepareWrite of count 4, since, view is uint8\n    prepareWrite(this, 4);\n    this.view.setUint32(this.length, this.length);\n    this.length += 4;\n    this.position += 4;\n\n    // trim down the byte buffer to what is actually being used\n    this.bytes = this.bytes.subarray(0, this.length);\n    this.frameTime = FlvTag.frameTime(this.bytes);\n    // if bytes.bytelength isn't equal to this.length, handle error\n    return this;\n  };\n};\n\nFlvTag.AUDIO_TAG = 0x08; // == 8, :uint\nFlvTag.VIDEO_TAG = 0x09; // == 9, :uint\nFlvTag.METADATA_TAG = 0x12; // == 18, :uint\n\n// (tag:ByteArray):Boolean {\nFlvTag.isAudioFrame = function(tag) {\n  return FlvTag.AUDIO_TAG === tag[0];\n};\n\n// (tag:ByteArray):Boolean {\nFlvTag.isVideoFrame = function(tag) {\n  return FlvTag.VIDEO_TAG === tag[0];\n};\n\n// (tag:ByteArray):Boolean {\nFlvTag.isMetaData = function(tag) {\n  return FlvTag.METADATA_TAG === tag[0];\n};\n\n// (tag:ByteArray):Boolean {\nFlvTag.isKeyFrame = function(tag) {\n  if (FlvTag.isVideoFrame(tag)) {\n    return tag[11] === 0x17;\n  }\n\n  if (FlvTag.isAudioFrame(tag)) {\n    return true;\n  }\n\n  if (FlvTag.isMetaData(tag)) {\n    return true;\n  }\n\n  return false;\n};\n\n// (tag:ByteArray):uint {\nFlvTag.frameTime = function(tag) {\n  var pts = tag[ 4] << 16; // :uint\n  pts |= tag[ 5] <<  8;\n  pts |= tag[ 6] <<  0;\n  pts |= tag[ 7] << 24;\n  return pts;\n};\n\nmodule.exports = FlvTag;\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\nmodule.exports = {\n  tag: require('./flv-tag'),\n  Transmuxer: require('./transmuxer'),\n  getFlvHeader: require('./flv-header')\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\n'use strict';\n\nvar TagList = function() {\n  var self = this;\n\n  this.list = [];\n\n  this.push = function(tag) {\n    this.list.push({\n      bytes: tag.bytes,\n      dts: tag.dts,\n      pts: tag.pts,\n      keyFrame: tag.keyFrame,\n      metaDataTag: tag.metaDataTag\n    });\n  };\n\n  Object.defineProperty(this, 'length', {\n    get: function() {\n      return self.list.length;\n    }\n  });\n};\n\nmodule.exports = TagList;\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\n'use strict';\n\nvar Stream = require('../utils/stream.js');\nvar FlvTag = require('./flv-tag.js');\nvar m2ts = require('../m2ts/m2ts.js');\nvar AdtsStream = require('../codecs/adts.js');\nvar H264Stream = require('../codecs/h264').H264Stream;\nvar CoalesceStream = require('./coalesce-stream.js');\nvar TagList = require('./tag-list.js');\n\nvar\n  Transmuxer,\n  VideoSegmentStream,\n  AudioSegmentStream,\n  collectTimelineInfo,\n  metaDataTag,\n  extraDataTag;\n\n/**\n * Store information about the start and end of the tracka and the\n * duration for each frame/sample we process in order to calculate\n * the baseMediaDecodeTime\n */\ncollectTimelineInfo = function(track, data) {\n  if (typeof data.pts === 'number') {\n    if (track.timelineStartInfo.pts === undefined) {\n      track.timelineStartInfo.pts = data.pts;\n    } else {\n      track.timelineStartInfo.pts =\n        Math.min(track.timelineStartInfo.pts, data.pts);\n    }\n  }\n\n  if (typeof data.dts === 'number') {\n    if (track.timelineStartInfo.dts === undefined) {\n      track.timelineStartInfo.dts = data.dts;\n    } else {\n      track.timelineStartInfo.dts =\n        Math.min(track.timelineStartInfo.dts, data.dts);\n    }\n  }\n};\n\nmetaDataTag = function(track, pts) {\n  var\n    tag = new FlvTag(FlvTag.METADATA_TAG); // :FlvTag\n\n  tag.dts = pts;\n  tag.pts = pts;\n\n  tag.writeMetaDataDouble('videocodecid', 7);\n  tag.writeMetaDataDouble('width', track.width);\n  tag.writeMetaDataDouble('height', track.height);\n\n  return tag;\n};\n\nextraDataTag = function(track, pts) {\n  var\n    i,\n    tag = new FlvTag(FlvTag.VIDEO_TAG, true);\n\n  tag.dts = pts;\n  tag.pts = pts;\n\n  tag.writeByte(0x01);// version\n  tag.writeByte(track.profileIdc);// profile\n  tag.writeByte(track.profileCompatibility);// compatibility\n  tag.writeByte(track.levelIdc);// level\n  tag.writeByte(0xFC | 0x03); // reserved (6 bits), NULA length size - 1 (2 bits)\n  tag.writeByte(0xE0 | 0x01); // reserved (3 bits), num of SPS (5 bits)\n  tag.writeShort(track.sps[0].length); // data of SPS\n  tag.writeBytes(track.sps[0]); // SPS\n\n  tag.writeByte(track.pps.length); // num of PPS (will there ever be more that 1 PPS?)\n  for (i = 0; i < track.pps.length; ++i) {\n    tag.writeShort(track.pps[i].length); // 2 bytes for length of PPS\n    tag.writeBytes(track.pps[i]); // data of PPS\n  }\n\n  return tag;\n};\n\n/**\n * Constructs a single-track, media segment from AAC data\n * events. The output of this stream can be fed to flash.\n */\nAudioSegmentStream = function(track) {\n  var\n    adtsFrames = [],\n    videoKeyFrames = [],\n    oldExtraData;\n\n  AudioSegmentStream.prototype.init.call(this);\n\n  this.push = function(data) {\n    collectTimelineInfo(track, data);\n\n    if (track) {\n      track.audioobjecttype = data.audioobjecttype;\n      track.channelcount = data.channelcount;\n      track.samplerate = data.samplerate;\n      track.samplingfrequencyindex = data.samplingfrequencyindex;\n      track.samplesize = data.samplesize;\n      track.extraData = (track.audioobjecttype << 11) |\n                        (track.samplingfrequencyindex << 7) |\n                        (track.channelcount << 3);\n    }\n\n    data.pts = Math.round(data.pts / 90);\n    data.dts = Math.round(data.dts / 90);\n\n    // buffer audio data until end() is called\n    adtsFrames.push(data);\n  };\n\n  this.flush = function() {\n    var currentFrame, adtsFrame, lastMetaPts, tags = new TagList();\n    // return early if no audio data has been observed\n    if (adtsFrames.length === 0) {\n      this.trigger('done', 'AudioSegmentStream');\n      return;\n    }\n\n    lastMetaPts = -Infinity;\n\n    while (adtsFrames.length) {\n      currentFrame = adtsFrames.shift();\n\n      // write out a metadata frame at every video key frame\n      if (videoKeyFrames.length && currentFrame.pts >= videoKeyFrames[0]) {\n        lastMetaPts = videoKeyFrames.shift();\n        this.writeMetaDataTags(tags, lastMetaPts);\n      }\n\n      // also write out metadata tags every 1 second so that the decoder\n      // is re-initialized quickly after seeking into a different\n      // audio configuration.\n      if (track.extraData !== oldExtraData || currentFrame.pts - lastMetaPts >= 1000) {\n        this.writeMetaDataTags(tags, currentFrame.pts);\n        oldExtraData = track.extraData;\n        lastMetaPts = currentFrame.pts;\n      }\n\n      adtsFrame = new FlvTag(FlvTag.AUDIO_TAG);\n      adtsFrame.pts = currentFrame.pts;\n      adtsFrame.dts = currentFrame.dts;\n\n      adtsFrame.writeBytes(currentFrame.data);\n\n      tags.push(adtsFrame.finalize());\n    }\n\n    videoKeyFrames.length = 0;\n    oldExtraData = null;\n    this.trigger('data', {track: track, tags: tags.list});\n\n    this.trigger('done', 'AudioSegmentStream');\n  };\n\n  this.writeMetaDataTags = function(tags, pts) {\n    var adtsFrame;\n\n    adtsFrame = new FlvTag(FlvTag.METADATA_TAG);\n    // For audio, DTS is always the same as PTS. We want to set the DTS\n    // however so we can compare with video DTS to determine approximate\n    // packet order\n    adtsFrame.pts = pts;\n    adtsFrame.dts = pts;\n\n    // AAC is always 10\n    adtsFrame.writeMetaDataDouble('audiocodecid', 10);\n    adtsFrame.writeMetaDataBoolean('stereo', track.channelcount === 2);\n    adtsFrame.writeMetaDataDouble('audiosamplerate', track.samplerate);\n    // Is AAC always 16 bit?\n    adtsFrame.writeMetaDataDouble('audiosamplesize', 16);\n\n    tags.push(adtsFrame.finalize());\n\n    adtsFrame = new FlvTag(FlvTag.AUDIO_TAG, true);\n    // For audio, DTS is always the same as PTS. We want to set the DTS\n    // however so we can compare with video DTS to determine approximate\n    // packet order\n    adtsFrame.pts = pts;\n    adtsFrame.dts = pts;\n\n    adtsFrame.view.setUint16(adtsFrame.position, track.extraData);\n    adtsFrame.position += 2;\n    adtsFrame.length = Math.max(adtsFrame.length, adtsFrame.position);\n\n    tags.push(adtsFrame.finalize());\n  };\n\n  this.onVideoKeyFrame = function(pts) {\n    videoKeyFrames.push(pts);\n  };\n};\nAudioSegmentStream.prototype = new Stream();\n\n/**\n * Store FlvTags for the h264 stream\n * @param track {object} track metadata configuration\n */\nVideoSegmentStream = function(track) {\n  var\n    nalUnits = [],\n    config,\n    h264Frame;\n  VideoSegmentStream.prototype.init.call(this);\n\n  this.finishFrame = function(tags, frame) {\n    if (!frame) {\n      return;\n    }\n    // Check if keyframe and the length of tags.\n    // This makes sure we write metadata on the first frame of a segment.\n    if (config && track && track.newMetadata &&\n        (frame.keyFrame || tags.length === 0)) {\n      // Push extra data on every IDR frame in case we did a stream change + seek\n      var metaTag = metaDataTag(config, frame.dts).finalize();\n      var extraTag = extraDataTag(track, frame.dts).finalize();\n\n      metaTag.metaDataTag = extraTag.metaDataTag = true;\n\n      tags.push(metaTag);\n      tags.push(extraTag);\n      track.newMetadata = false;\n\n      this.trigger('keyframe', frame.dts);\n    }\n\n    frame.endNalUnit();\n    tags.push(frame.finalize());\n    h264Frame = null;\n  };\n\n  this.push = function(data) {\n    collectTimelineInfo(track, data);\n\n    data.pts = Math.round(data.pts / 90);\n    data.dts = Math.round(data.dts / 90);\n\n    // buffer video until flush() is called\n    nalUnits.push(data);\n  };\n\n  this.flush = function() {\n    var\n      currentNal,\n      tags = new TagList();\n\n    // Throw away nalUnits at the start of the byte stream until we find\n    // the first AUD\n    while (nalUnits.length) {\n      if (nalUnits[0].nalUnitType === 'access_unit_delimiter_rbsp') {\n        break;\n      }\n      nalUnits.shift();\n    }\n\n    // return early if no video data has been observed\n    if (nalUnits.length === 0) {\n      this.trigger('done', 'VideoSegmentStream');\n      return;\n    }\n\n    while (nalUnits.length) {\n      currentNal = nalUnits.shift();\n\n      // record the track config\n      if (currentNal.nalUnitType === 'seq_parameter_set_rbsp') {\n        track.newMetadata = true;\n        config = currentNal.config;\n        track.width = config.width;\n        track.height = config.height;\n        track.sps = [currentNal.data];\n        track.profileIdc = config.profileIdc;\n        track.levelIdc = config.levelIdc;\n        track.profileCompatibility = config.profileCompatibility;\n        h264Frame.endNalUnit();\n      } else if (currentNal.nalUnitType === 'pic_parameter_set_rbsp') {\n        track.newMetadata = true;\n        track.pps = [currentNal.data];\n        h264Frame.endNalUnit();\n      } else if (currentNal.nalUnitType === 'access_unit_delimiter_rbsp') {\n        if (h264Frame) {\n          this.finishFrame(tags, h264Frame);\n        }\n        h264Frame = new FlvTag(FlvTag.VIDEO_TAG);\n        h264Frame.pts = currentNal.pts;\n        h264Frame.dts = currentNal.dts;\n      } else {\n        if (currentNal.nalUnitType === 'slice_layer_without_partitioning_rbsp_idr') {\n          // the current sample is a key frame\n          h264Frame.keyFrame = true;\n        }\n        h264Frame.endNalUnit();\n      }\n      h264Frame.startNalUnit();\n      h264Frame.writeBytes(currentNal.data);\n    }\n    if (h264Frame) {\n      this.finishFrame(tags, h264Frame);\n    }\n\n    this.trigger('data', {track: track, tags: tags.list});\n\n    // Continue with the flush process now\n    this.trigger('done', 'VideoSegmentStream');\n  };\n};\n\nVideoSegmentStream.prototype = new Stream();\n\n/**\n * An object that incrementally transmuxes MPEG2 Trasport Stream\n * chunks into an FLV.\n */\nTransmuxer = function(options) {\n  var\n    self = this,\n\n    packetStream, parseStream, elementaryStream,\n    videoTimestampRolloverStream, audioTimestampRolloverStream,\n    timedMetadataTimestampRolloverStream,\n    adtsStream, h264Stream,\n    videoSegmentStream, audioSegmentStream, captionStream,\n    coalesceStream;\n\n  Transmuxer.prototype.init.call(this);\n\n  options = options || {};\n\n  // expose the metadata stream\n  this.metadataStream = new m2ts.MetadataStream();\n\n  options.metadataStream = this.metadataStream;\n\n  // set up the parsing pipeline\n  packetStream = new m2ts.TransportPacketStream();\n  parseStream = new m2ts.TransportParseStream();\n  elementaryStream = new m2ts.ElementaryStream();\n  videoTimestampRolloverStream = new m2ts.TimestampRolloverStream('video');\n  audioTimestampRolloverStream = new m2ts.TimestampRolloverStream('audio');\n  timedMetadataTimestampRolloverStream = new m2ts.TimestampRolloverStream('timed-metadata');\n\n  adtsStream = new AdtsStream();\n  h264Stream = new H264Stream();\n  coalesceStream = new CoalesceStream(options);\n\n  // disassemble MPEG2-TS packets into elementary streams\n  packetStream\n    .pipe(parseStream)\n    .pipe(elementaryStream);\n\n  // !!THIS ORDER IS IMPORTANT!!\n  // demux the streams\n  elementaryStream\n    .pipe(videoTimestampRolloverStream)\n    .pipe(h264Stream);\n  elementaryStream\n    .pipe(audioTimestampRolloverStream)\n    .pipe(adtsStream);\n\n  elementaryStream\n    .pipe(timedMetadataTimestampRolloverStream)\n    .pipe(this.metadataStream)\n    .pipe(coalesceStream);\n  // if CEA-708 parsing is available, hook up a caption stream\n  captionStream = new m2ts.CaptionStream();\n  h264Stream.pipe(captionStream)\n    .pipe(coalesceStream);\n\n  // hook up the segment streams once track metadata is delivered\n  elementaryStream.on('data', function(data) {\n    var i, videoTrack, audioTrack;\n\n    if (data.type === 'metadata') {\n      i = data.tracks.length;\n\n      // scan the tracks listed in the metadata\n      while (i--) {\n        if (data.tracks[i].type === 'video') {\n          videoTrack = data.tracks[i];\n        } else if (data.tracks[i].type === 'audio') {\n          audioTrack = data.tracks[i];\n        }\n      }\n\n      // hook up the video segment stream to the first track with h264 data\n      if (videoTrack && !videoSegmentStream) {\n        coalesceStream.numberOfTracks++;\n        videoSegmentStream = new VideoSegmentStream(videoTrack);\n\n        // Set up the final part of the video pipeline\n        h264Stream\n          .pipe(videoSegmentStream)\n          .pipe(coalesceStream);\n      }\n\n      if (audioTrack && !audioSegmentStream) {\n        // hook up the audio segment stream to the first track with aac data\n        coalesceStream.numberOfTracks++;\n        audioSegmentStream = new AudioSegmentStream(audioTrack);\n\n        // Set up the final part of the audio pipeline\n        adtsStream\n          .pipe(audioSegmentStream)\n          .pipe(coalesceStream);\n\n        if (videoSegmentStream) {\n          videoSegmentStream.on('keyframe', audioSegmentStream.onVideoKeyFrame);\n        }\n      }\n    }\n  });\n\n  // feed incoming data to the front of the parsing pipeline\n  this.push = function(data) {\n    packetStream.push(data);\n  };\n\n  // flush any buffered data\n  this.flush = function() {\n    // Start at the top of the pipeline and flush all pending work\n    packetStream.flush();\n  };\n\n  // Caption data has to be reset when seeking outside buffered range\n  this.resetCaptions = function() {\n    captionStream.reset();\n  };\n\n  // Re-emit any data coming from the coalesce stream to the outside world\n  coalesceStream.on('data', function(event) {\n    self.trigger('data', event);\n  });\n\n  // Let the consumer know we have finished flushing the entire pipeline\n  coalesceStream.on('done', function() {\n    self.trigger('done');\n  });\n};\nTransmuxer.prototype = new Stream();\n\n// forward compatibility\nmodule.exports = Transmuxer;\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\n'use strict';\n\nvar muxjs = {\n  codecs: require('./codecs'),\n  mp4: require('./mp4'),\n  flv: require('./flv'),\n  mp2t: require('./m2ts'),\n  partial: require('./partial')\n};\n\n// include all the tools when the full library is required\nmuxjs.mp4.tools = require('./tools/mp4-inspector');\nmuxjs.flv.tools = require('./tools/flv-inspector');\nmuxjs.mp2t.tools = require('./tools/ts-inspector');\n\n\nmodule.exports = muxjs;\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * Reads in-band caption information from a video elementary\n * stream. Captions must follow the CEA-708 standard for injection\n * into an MPEG-2 transport streams.\n * @see https://en.wikipedia.org/wiki/CEA-708\n * @see https://www.gpo.gov/fdsys/pkg/CFR-2007-title47-vol1/pdf/CFR-2007-title47-vol1-sec15-119.pdf\n */\n\n'use strict';\n\n// -----------------\n// Link To Transport\n// -----------------\n\nvar Stream = require('../utils/stream');\nvar cea708Parser = require('../tools/caption-packet-parser');\n\nvar CaptionStream = function() {\n\n  CaptionStream.prototype.init.call(this);\n\n  this.captionPackets_ = [];\n\n  this.ccStreams_ = [\n    new Cea608Stream(0, 0), // eslint-disable-line no-use-before-define\n    new Cea608Stream(0, 1), // eslint-disable-line no-use-before-define\n    new Cea608Stream(1, 0), // eslint-disable-line no-use-before-define\n    new Cea608Stream(1, 1) // eslint-disable-line no-use-before-define\n  ];\n\n  this.reset();\n\n  // forward data and done events from CCs to this CaptionStream\n  this.ccStreams_.forEach(function(cc) {\n    cc.on('data', this.trigger.bind(this, 'data'));\n    cc.on('partialdone', this.trigger.bind(this, 'partialdone'));\n    cc.on('done', this.trigger.bind(this, 'done'));\n  }, this);\n\n};\n\nCaptionStream.prototype = new Stream();\nCaptionStream.prototype.push = function(event) {\n  var sei, userData, newCaptionPackets;\n\n  // only examine SEI NALs\n  if (event.nalUnitType !== 'sei_rbsp') {\n    return;\n  }\n\n  // parse the sei\n  sei = cea708Parser.parseSei(event.escapedRBSP);\n\n  // ignore everything but user_data_registered_itu_t_t35\n  if (sei.payloadType !== cea708Parser.USER_DATA_REGISTERED_ITU_T_T35) {\n    return;\n  }\n\n  // parse out the user data payload\n  userData = cea708Parser.parseUserData(sei);\n\n  // ignore unrecognized userData\n  if (!userData) {\n    return;\n  }\n\n  // Sometimes, the same segment # will be downloaded twice. To stop the\n  // caption data from being processed twice, we track the latest dts we've\n  // received and ignore everything with a dts before that. However, since\n  // data for a specific dts can be split across packets on either side of\n  // a segment boundary, we need to make sure we *don't* ignore the packets\n  // from the *next* segment that have dts === this.latestDts_. By constantly\n  // tracking the number of packets received with dts === this.latestDts_, we\n  // know how many should be ignored once we start receiving duplicates.\n  if (event.dts < this.latestDts_) {\n    // We've started getting older data, so set the flag.\n    this.ignoreNextEqualDts_ = true;\n    return;\n  } else if ((event.dts === this.latestDts_) && (this.ignoreNextEqualDts_)) {\n    this.numSameDts_--;\n    if (!this.numSameDts_) {\n      // We've received the last duplicate packet, time to start processing again\n      this.ignoreNextEqualDts_ = false;\n    }\n    return;\n  }\n\n  // parse out CC data packets and save them for later\n  newCaptionPackets = cea708Parser.parseCaptionPackets(event.pts, userData);\n  this.captionPackets_ = this.captionPackets_.concat(newCaptionPackets);\n  if (this.latestDts_ !== event.dts) {\n    this.numSameDts_ = 0;\n  }\n  this.numSameDts_++;\n  this.latestDts_ = event.dts;\n};\n\nCaptionStream.prototype.flushCCStreams = function(flushType) {\n  this.ccStreams_.forEach(function(cc) {\n    return flushType === 'flush' ? cc.flush() : cc.partialFlush();\n  }, this);\n};\n\nCaptionStream.prototype.flushStream = function(flushType) {\n  // make sure we actually parsed captions before proceeding\n  if (!this.captionPackets_.length) {\n    this.flushCCStreams(flushType);\n    return;\n  }\n\n  // In Chrome, the Array#sort function is not stable so add a\n  // presortIndex that we can use to ensure we get a stable-sort\n  this.captionPackets_.forEach(function(elem, idx) {\n    elem.presortIndex = idx;\n  });\n\n  // sort caption byte-pairs based on their PTS values\n  this.captionPackets_.sort(function(a, b) {\n    if (a.pts === b.pts) {\n      return a.presortIndex - b.presortIndex;\n    }\n    return a.pts - b.pts;\n  });\n\n  this.captionPackets_.forEach(function(packet) {\n    if (packet.type < 2) {\n      // Dispatch packet to the right Cea608Stream\n      this.dispatchCea608Packet(packet);\n    }\n    // this is where an 'else' would go for a dispatching packets\n    // to a theoretical Cea708Stream that handles SERVICEn data\n  }, this);\n\n  this.captionPackets_.length = 0;\n  this.flushCCStreams(flushType);\n};\n\nCaptionStream.prototype.flush = function() {\n  return this.flushStream('flush');\n};\n\n// Only called if handling partial data\nCaptionStream.prototype.partialFlush = function() {\n  return this.flushStream('partialFlush');\n};\n\nCaptionStream.prototype.reset = function() {\n  this.latestDts_ = null;\n  this.ignoreNextEqualDts_ = false;\n  this.numSameDts_ = 0;\n  this.activeCea608Channel_ = [null, null];\n  this.ccStreams_.forEach(function(ccStream) {\n    ccStream.reset();\n  });\n};\n\n// From the CEA-608 spec:\n/*\n * When XDS sub-packets are interleaved with other services, the end of each sub-packet shall be followed\n * by a control pair to change to a different service. When any of the control codes from 0x10 to 0x1F is\n * used to begin a control code pair, it indicates the return to captioning or Text data. The control code pair\n * and subsequent data should then be processed according to the FCC rules. It may be necessary for the\n * line 21 data encoder to automatically insert a control code pair (i.e. RCL, RU2, RU3, RU4, RDC, or RTD)\n * to switch to captioning or Text.\n*/\n// With that in mind, we ignore any data between an XDS control code and a\n// subsequent closed-captioning control code.\nCaptionStream.prototype.dispatchCea608Packet = function(packet) {\n  // NOTE: packet.type is the CEA608 field\n  if (this.setsTextOrXDSActive(packet)) {\n    this.activeCea608Channel_[packet.type] = null;\n  } else if (this.setsChannel1Active(packet)) {\n    this.activeCea608Channel_[packet.type] = 0;\n  } else if (this.setsChannel2Active(packet)) {\n    this.activeCea608Channel_[packet.type] = 1;\n  }\n  if (this.activeCea608Channel_[packet.type] === null) {\n    // If we haven't received anything to set the active channel, or the\n    // packets are Text/XDS data, discard the data; we don't want jumbled\n    // captions\n    return;\n  }\n  this.ccStreams_[(packet.type << 1) + this.activeCea608Channel_[packet.type]].push(packet);\n};\n\nCaptionStream.prototype.setsChannel1Active = function(packet) {\n  return ((packet.ccData & 0x7800) === 0x1000);\n};\nCaptionStream.prototype.setsChannel2Active = function(packet) {\n  return ((packet.ccData & 0x7800) === 0x1800);\n};\nCaptionStream.prototype.setsTextOrXDSActive = function(packet) {\n  return ((packet.ccData & 0x7100) === 0x0100) ||\n    ((packet.ccData & 0x78fe) === 0x102a) ||\n    ((packet.ccData & 0x78fe) === 0x182a);\n};\n\n// ----------------------\n// Session to Application\n// ----------------------\n\n// This hash maps non-ASCII, special, and extended character codes to their\n// proper Unicode equivalent. The first keys that are only a single byte\n// are the non-standard ASCII characters, which simply map the CEA608 byte\n// to the standard ASCII/Unicode. The two-byte keys that follow are the CEA608\n// character codes, but have their MSB bitmasked with 0x03 so that a lookup\n// can be performed regardless of the field and data channel on which the\n// character code was received.\nvar CHARACTER_TRANSLATION = {\n  0x2a: 0xe1,     // á\n  0x5c: 0xe9,     // é\n  0x5e: 0xed,     // í\n  0x5f: 0xf3,     // ó\n  0x60: 0xfa,     // ú\n  0x7b: 0xe7,     // ç\n  0x7c: 0xf7,     // ÷\n  0x7d: 0xd1,     // Ñ\n  0x7e: 0xf1,     // ñ\n  0x7f: 0x2588,   // █\n  0x0130: 0xae,   // ®\n  0x0131: 0xb0,   // °\n  0x0132: 0xbd,   // ½\n  0x0133: 0xbf,   // ¿\n  0x0134: 0x2122, // ™\n  0x0135: 0xa2,   // ¢\n  0x0136: 0xa3,   // £\n  0x0137: 0x266a, // ♪\n  0x0138: 0xe0,   // à\n  0x0139: 0xa0,   //\n  0x013a: 0xe8,   // è\n  0x013b: 0xe2,   // â\n  0x013c: 0xea,   // ê\n  0x013d: 0xee,   // î\n  0x013e: 0xf4,   // ô\n  0x013f: 0xfb,   // û\n  0x0220: 0xc1,   // Á\n  0x0221: 0xc9,   // É\n  0x0222: 0xd3,   // Ó\n  0x0223: 0xda,   // Ú\n  0x0224: 0xdc,   // Ü\n  0x0225: 0xfc,   // ü\n  0x0226: 0x2018, // ‘\n  0x0227: 0xa1,   // ¡\n  0x0228: 0x2a,   // *\n  0x0229: 0x27,   // '\n  0x022a: 0x2014, // —\n  0x022b: 0xa9,   // ©\n  0x022c: 0x2120, // ℠\n  0x022d: 0x2022, // •\n  0x022e: 0x201c, // “\n  0x022f: 0x201d, // ”\n  0x0230: 0xc0,   // À\n  0x0231: 0xc2,   // Â\n  0x0232: 0xc7,   // Ç\n  0x0233: 0xc8,   // È\n  0x0234: 0xca,   // Ê\n  0x0235: 0xcb,   // Ë\n  0x0236: 0xeb,   // ë\n  0x0237: 0xce,   // Î\n  0x0238: 0xcf,   // Ï\n  0x0239: 0xef,   // ï\n  0x023a: 0xd4,   // Ô\n  0x023b: 0xd9,   // Ù\n  0x023c: 0xf9,   // ù\n  0x023d: 0xdb,   // Û\n  0x023e: 0xab,   // «\n  0x023f: 0xbb,   // »\n  0x0320: 0xc3,   // Ã\n  0x0321: 0xe3,   // ã\n  0x0322: 0xcd,   // Í\n  0x0323: 0xcc,   // Ì\n  0x0324: 0xec,   // ì\n  0x0325: 0xd2,   // Ò\n  0x0326: 0xf2,   // ò\n  0x0327: 0xd5,   // Õ\n  0x0328: 0xf5,   // õ\n  0x0329: 0x7b,   // {\n  0x032a: 0x7d,   // }\n  0x032b: 0x5c,   // \\\n  0x032c: 0x5e,   // ^\n  0x032d: 0x5f,   // _\n  0x032e: 0x7c,   // |\n  0x032f: 0x7e,   // ~\n  0x0330: 0xc4,   // Ä\n  0x0331: 0xe4,   // ä\n  0x0332: 0xd6,   // Ö\n  0x0333: 0xf6,   // ö\n  0x0334: 0xdf,   // ß\n  0x0335: 0xa5,   // ¥\n  0x0336: 0xa4,   // ¤\n  0x0337: 0x2502, // │\n  0x0338: 0xc5,   // Å\n  0x0339: 0xe5,   // å\n  0x033a: 0xd8,   // Ø\n  0x033b: 0xf8,   // ø\n  0x033c: 0x250c, // ┌\n  0x033d: 0x2510, // ┐\n  0x033e: 0x2514, // └\n  0x033f: 0x2518  // ┘\n};\n\nvar getCharFromCode = function(code) {\n  if (code === null) {\n    return '';\n  }\n  code = CHARACTER_TRANSLATION[code] || code;\n  return String.fromCharCode(code);\n};\n\n// the index of the last row in a CEA-608 display buffer\nvar BOTTOM_ROW = 14;\n\n// This array is used for mapping PACs -> row #, since there's no way of\n// getting it through bit logic.\nvar ROWS = [0x1100, 0x1120, 0x1200, 0x1220, 0x1500, 0x1520, 0x1600, 0x1620,\n            0x1700, 0x1720, 0x1000, 0x1300, 0x1320, 0x1400, 0x1420];\n\n// CEA-608 captions are rendered onto a 34x15 matrix of character\n// cells. The \"bottom\" row is the last element in the outer array.\nvar createDisplayBuffer = function() {\n  var result = [], i = BOTTOM_ROW + 1;\n  while (i--) {\n    result.push('');\n  }\n  return result;\n};\n\nvar Cea608Stream = function(field, dataChannel) {\n  Cea608Stream.prototype.init.call(this);\n\n  this.field_ = field || 0;\n  this.dataChannel_ = dataChannel || 0;\n\n  this.name_ = 'CC' + (((this.field_ << 1) | this.dataChannel_) + 1);\n\n  this.setConstants();\n  this.reset();\n\n  this.push = function(packet) {\n    var data, swap, char0, char1, text;\n    // remove the parity bits\n    data = packet.ccData & 0x7f7f;\n\n    // ignore duplicate control codes; the spec demands they're sent twice\n    if (data === this.lastControlCode_) {\n      this.lastControlCode_ = null;\n      return;\n    }\n\n    // Store control codes\n    if ((data & 0xf000) === 0x1000) {\n      this.lastControlCode_ = data;\n    } else if (data !== this.PADDING_) {\n      this.lastControlCode_ = null;\n    }\n\n    char0 = data >>> 8;\n    char1 = data & 0xff;\n\n    if (data === this.PADDING_) {\n      return;\n\n    } else if (data === this.RESUME_CAPTION_LOADING_) {\n      this.mode_ = 'popOn';\n\n    } else if (data === this.END_OF_CAPTION_) {\n      // If an EOC is received while in paint-on mode, the displayed caption\n      // text should be swapped to non-displayed memory as if it was a pop-on\n      // caption. Because of that, we should explicitly switch back to pop-on\n      // mode\n      this.mode_ = 'popOn';\n      this.clearFormatting(packet.pts);\n      // if a caption was being displayed, it's gone now\n      this.flushDisplayed(packet.pts);\n\n      // flip memory\n      swap = this.displayed_;\n      this.displayed_ = this.nonDisplayed_;\n      this.nonDisplayed_ = swap;\n\n      // start measuring the time to display the caption\n      this.startPts_ = packet.pts;\n\n    } else if (data === this.ROLL_UP_2_ROWS_) {\n      this.rollUpRows_ = 2;\n      this.setRollUp(packet.pts);\n    } else if (data === this.ROLL_UP_3_ROWS_) {\n      this.rollUpRows_ = 3;\n      this.setRollUp(packet.pts);\n    } else if (data === this.ROLL_UP_4_ROWS_) {\n      this.rollUpRows_ = 4;\n      this.setRollUp(packet.pts);\n    } else if (data === this.CARRIAGE_RETURN_) {\n      this.clearFormatting(packet.pts);\n      this.flushDisplayed(packet.pts);\n      this.shiftRowsUp_();\n      this.startPts_ = packet.pts;\n\n    } else if (data === this.BACKSPACE_) {\n      if (this.mode_ === 'popOn') {\n        this.nonDisplayed_[this.row_] = this.nonDisplayed_[this.row_].slice(0, -1);\n      } else {\n        this.displayed_[this.row_] = this.displayed_[this.row_].slice(0, -1);\n      }\n    } else if (data === this.ERASE_DISPLAYED_MEMORY_) {\n      this.flushDisplayed(packet.pts);\n      this.displayed_ = createDisplayBuffer();\n    } else if (data === this.ERASE_NON_DISPLAYED_MEMORY_) {\n      this.nonDisplayed_ = createDisplayBuffer();\n\n    } else if (data === this.RESUME_DIRECT_CAPTIONING_) {\n      if (this.mode_ !== 'paintOn') {\n        // NOTE: This should be removed when proper caption positioning is\n        // implemented\n        this.flushDisplayed(packet.pts);\n        this.displayed_ = createDisplayBuffer();\n      }\n      this.mode_ = 'paintOn';\n      this.startPts_ = packet.pts;\n\n    // Append special characters to caption text\n    } else if (this.isSpecialCharacter(char0, char1)) {\n      // Bitmask char0 so that we can apply character transformations\n      // regardless of field and data channel.\n      // Then byte-shift to the left and OR with char1 so we can pass the\n      // entire character code to `getCharFromCode`.\n      char0 = (char0 & 0x03) << 8;\n      text = getCharFromCode(char0 | char1);\n      this[this.mode_](packet.pts, text);\n      this.column_++;\n\n    // Append extended characters to caption text\n    } else if (this.isExtCharacter(char0, char1)) {\n      // Extended characters always follow their \"non-extended\" equivalents.\n      // IE if a \"è\" is desired, you'll always receive \"eè\"; non-compliant\n      // decoders are supposed to drop the \"è\", while compliant decoders\n      // backspace the \"e\" and insert \"è\".\n\n      // Delete the previous character\n      if (this.mode_ === 'popOn') {\n        this.nonDisplayed_[this.row_] = this.nonDisplayed_[this.row_].slice(0, -1);\n      } else {\n        this.displayed_[this.row_] = this.displayed_[this.row_].slice(0, -1);\n      }\n\n      // Bitmask char0 so that we can apply character transformations\n      // regardless of field and data channel.\n      // Then byte-shift to the left and OR with char1 so we can pass the\n      // entire character code to `getCharFromCode`.\n      char0 = (char0 & 0x03) << 8;\n      text = getCharFromCode(char0 | char1);\n      this[this.mode_](packet.pts, text);\n      this.column_++;\n\n    // Process mid-row codes\n    } else if (this.isMidRowCode(char0, char1)) {\n      // Attributes are not additive, so clear all formatting\n      this.clearFormatting(packet.pts);\n\n      // According to the standard, mid-row codes\n      // should be replaced with spaces, so add one now\n      this[this.mode_](packet.pts, ' ');\n      this.column_++;\n\n      if ((char1 & 0xe) === 0xe) {\n        this.addFormatting(packet.pts, ['i']);\n      }\n\n      if ((char1 & 0x1) === 0x1) {\n        this.addFormatting(packet.pts, ['u']);\n      }\n\n    // Detect offset control codes and adjust cursor\n    } else if (this.isOffsetControlCode(char0, char1)) {\n      // Cursor position is set by indent PAC (see below) in 4-column\n      // increments, with an additional offset code of 1-3 to reach any\n      // of the 32 columns specified by CEA-608. So all we need to do\n      // here is increment the column cursor by the given offset.\n      this.column_ += (char1 & 0x03);\n\n    // Detect PACs (Preamble Address Codes)\n    } else if (this.isPAC(char0, char1)) {\n\n      // There's no logic for PAC -> row mapping, so we have to just\n      // find the row code in an array and use its index :(\n      var row = ROWS.indexOf(data & 0x1f20);\n\n      // Configure the caption window if we're in roll-up mode\n      if (this.mode_ === 'rollUp') {\n        // This implies that the base row is incorrectly set.\n        // As per the recommendation in CEA-608(Base Row Implementation), defer to the number\n        // of roll-up rows set.\n        if (row - this.rollUpRows_ + 1 < 0) {\n          row = this.rollUpRows_ - 1;\n        }\n\n        this.setRollUp(packet.pts, row);\n      }\n\n      if (row !== this.row_) {\n        // formatting is only persistent for current row\n        this.clearFormatting(packet.pts);\n        this.row_ = row;\n      }\n      // All PACs can apply underline, so detect and apply\n      // (All odd-numbered second bytes set underline)\n      if ((char1 & 0x1) && (this.formatting_.indexOf('u') === -1)) {\n          this.addFormatting(packet.pts, ['u']);\n      }\n\n      if ((data & 0x10) === 0x10) {\n        // We've got an indent level code. Each successive even number\n        // increments the column cursor by 4, so we can get the desired\n        // column position by bit-shifting to the right (to get n/2)\n        // and multiplying by 4.\n        this.column_ = ((data & 0xe) >> 1) * 4;\n      }\n\n      if (this.isColorPAC(char1)) {\n        // it's a color code, though we only support white, which\n        // can be either normal or italicized. white italics can be\n        // either 0x4e or 0x6e depending on the row, so we just\n        // bitwise-and with 0xe to see if italics should be turned on\n        if ((char1 & 0xe) === 0xe) {\n          this.addFormatting(packet.pts, ['i']);\n        }\n      }\n\n    // We have a normal character in char0, and possibly one in char1\n    } else if (this.isNormalChar(char0)) {\n      if (char1 === 0x00) {\n        char1 = null;\n      }\n      text = getCharFromCode(char0);\n      text += getCharFromCode(char1);\n      this[this.mode_](packet.pts, text);\n      this.column_ += text.length;\n\n    } // finish data processing\n\n  };\n};\nCea608Stream.prototype = new Stream();\n// Trigger a cue point that captures the current state of the\n// display buffer\nCea608Stream.prototype.flushDisplayed = function(pts) {\n  var content = this.displayed_\n    // remove spaces from the start and end of the string\n    .map(function(row) {\n      try {\n        return row.trim();\n      } catch (e) {\n        // Ordinarily, this shouldn't happen. However, caption\n        // parsing errors should not throw exceptions and\n        // break playback.\n        // eslint-disable-next-line no-console\n        console.error('Skipping malformed caption.');\n        return '';\n      }\n    })\n    // combine all text rows to display in one cue\n    .join('\\n')\n    // and remove blank rows from the start and end, but not the middle\n    .replace(/^\\n+|\\n+$/g, '');\n\n  if (content.length) {\n    this.trigger('data', {\n      startPts: this.startPts_,\n      endPts: pts,\n      text: content,\n      stream: this.name_\n    });\n  }\n};\n\n/**\n * Zero out the data, used for startup and on seek\n */\nCea608Stream.prototype.reset = function() {\n  this.mode_ = 'popOn';\n  // When in roll-up mode, the index of the last row that will\n  // actually display captions. If a caption is shifted to a row\n  // with a lower index than this, it is cleared from the display\n  // buffer\n  this.topRow_ = 0;\n  this.startPts_ = 0;\n  this.displayed_ = createDisplayBuffer();\n  this.nonDisplayed_ = createDisplayBuffer();\n  this.lastControlCode_ = null;\n\n  // Track row and column for proper line-breaking and spacing\n  this.column_ = 0;\n  this.row_ = BOTTOM_ROW;\n  this.rollUpRows_ = 2;\n\n  // This variable holds currently-applied formatting\n  this.formatting_ = [];\n};\n\n/**\n * Sets up control code and related constants for this instance\n */\nCea608Stream.prototype.setConstants = function() {\n  // The following attributes have these uses:\n  // ext_ :    char0 for mid-row codes, and the base for extended\n  //           chars (ext_+0, ext_+1, and ext_+2 are char0s for\n  //           extended codes)\n  // control_: char0 for control codes, except byte-shifted to the\n  //           left so that we can do this.control_ | CONTROL_CODE\n  // offset_:  char0 for tab offset codes\n  //\n  // It's also worth noting that control codes, and _only_ control codes,\n  // differ between field 1 and field2. Field 2 control codes are always\n  // their field 1 value plus 1. That's why there's the \"| field\" on the\n  // control value.\n  if (this.dataChannel_ === 0) {\n    this.BASE_     = 0x10;\n    this.EXT_      = 0x11;\n    this.CONTROL_  = (0x14 | this.field_) << 8;\n    this.OFFSET_   = 0x17;\n  } else if (this.dataChannel_ === 1) {\n    this.BASE_     = 0x18;\n    this.EXT_      = 0x19;\n    this.CONTROL_  = (0x1c | this.field_) << 8;\n    this.OFFSET_   = 0x1f;\n  }\n\n  // Constants for the LSByte command codes recognized by Cea608Stream. This\n  // list is not exhaustive. For a more comprehensive listing and semantics see\n  // http://www.gpo.gov/fdsys/pkg/CFR-2010-title47-vol1/pdf/CFR-2010-title47-vol1-sec15-119.pdf\n  // Padding\n  this.PADDING_                    = 0x0000;\n  // Pop-on Mode\n  this.RESUME_CAPTION_LOADING_     = this.CONTROL_ | 0x20;\n  this.END_OF_CAPTION_             = this.CONTROL_ | 0x2f;\n  // Roll-up Mode\n  this.ROLL_UP_2_ROWS_             = this.CONTROL_ | 0x25;\n  this.ROLL_UP_3_ROWS_             = this.CONTROL_ | 0x26;\n  this.ROLL_UP_4_ROWS_             = this.CONTROL_ | 0x27;\n  this.CARRIAGE_RETURN_            = this.CONTROL_ | 0x2d;\n  // paint-on mode\n  this.RESUME_DIRECT_CAPTIONING_   = this.CONTROL_ | 0x29;\n  // Erasure\n  this.BACKSPACE_                  = this.CONTROL_ | 0x21;\n  this.ERASE_DISPLAYED_MEMORY_     = this.CONTROL_ | 0x2c;\n  this.ERASE_NON_DISPLAYED_MEMORY_ = this.CONTROL_ | 0x2e;\n};\n\n/**\n * Detects if the 2-byte packet data is a special character\n *\n * Special characters have a second byte in the range 0x30 to 0x3f,\n * with the first byte being 0x11 (for data channel 1) or 0x19 (for\n * data channel 2).\n *\n * @param  {Integer} char0 The first byte\n * @param  {Integer} char1 The second byte\n * @return {Boolean}       Whether the 2 bytes are an special character\n */\nCea608Stream.prototype.isSpecialCharacter = function(char0, char1) {\n  return (char0 === this.EXT_ && char1 >= 0x30 && char1 <= 0x3f);\n};\n\n/**\n * Detects if the 2-byte packet data is an extended character\n *\n * Extended characters have a second byte in the range 0x20 to 0x3f,\n * with the first byte being 0x12 or 0x13 (for data channel 1) or\n * 0x1a or 0x1b (for data channel 2).\n *\n * @param  {Integer} char0 The first byte\n * @param  {Integer} char1 The second byte\n * @return {Boolean}       Whether the 2 bytes are an extended character\n */\nCea608Stream.prototype.isExtCharacter = function(char0, char1) {\n  return ((char0 === (this.EXT_ + 1) || char0 === (this.EXT_ + 2)) &&\n    (char1 >= 0x20 && char1 <= 0x3f));\n};\n\n/**\n * Detects if the 2-byte packet is a mid-row code\n *\n * Mid-row codes have a second byte in the range 0x20 to 0x2f, with\n * the first byte being 0x11 (for data channel 1) or 0x19 (for data\n * channel 2).\n *\n * @param  {Integer} char0 The first byte\n * @param  {Integer} char1 The second byte\n * @return {Boolean}       Whether the 2 bytes are a mid-row code\n */\nCea608Stream.prototype.isMidRowCode = function(char0, char1) {\n  return (char0 === this.EXT_ && (char1 >= 0x20 && char1 <= 0x2f));\n};\n\n/**\n * Detects if the 2-byte packet is an offset control code\n *\n * Offset control codes have a second byte in the range 0x21 to 0x23,\n * with the first byte being 0x17 (for data channel 1) or 0x1f (for\n * data channel 2).\n *\n * @param  {Integer} char0 The first byte\n * @param  {Integer} char1 The second byte\n * @return {Boolean}       Whether the 2 bytes are an offset control code\n */\nCea608Stream.prototype.isOffsetControlCode = function(char0, char1) {\n  return (char0 === this.OFFSET_ && (char1 >= 0x21 && char1 <= 0x23));\n};\n\n/**\n * Detects if the 2-byte packet is a Preamble Address Code\n *\n * PACs have a first byte in the range 0x10 to 0x17 (for data channel 1)\n * or 0x18 to 0x1f (for data channel 2), with the second byte in the\n * range 0x40 to 0x7f.\n *\n * @param  {Integer} char0 The first byte\n * @param  {Integer} char1 The second byte\n * @return {Boolean}       Whether the 2 bytes are a PAC\n */\nCea608Stream.prototype.isPAC = function(char0, char1) {\n  return (char0 >= this.BASE_ && char0 < (this.BASE_ + 8) &&\n    (char1 >= 0x40 && char1 <= 0x7f));\n};\n\n/**\n * Detects if a packet's second byte is in the range of a PAC color code\n *\n * PAC color codes have the second byte be in the range 0x40 to 0x4f, or\n * 0x60 to 0x6f.\n *\n * @param  {Integer} char1 The second byte\n * @return {Boolean}       Whether the byte is a color PAC\n */\nCea608Stream.prototype.isColorPAC = function(char1) {\n  return ((char1 >= 0x40 && char1 <= 0x4f) || (char1 >= 0x60 && char1 <= 0x7f));\n};\n\n/**\n * Detects if a single byte is in the range of a normal character\n *\n * Normal text bytes are in the range 0x20 to 0x7f.\n *\n * @param  {Integer} char  The byte\n * @return {Boolean}       Whether the byte is a normal character\n */\nCea608Stream.prototype.isNormalChar = function(char) {\n  return (char >= 0x20 && char <= 0x7f);\n};\n\n/**\n * Configures roll-up\n *\n * @param  {Integer} pts         Current PTS\n * @param  {Integer} newBaseRow  Used by PACs to slide the current window to\n *                               a new position\n */\nCea608Stream.prototype.setRollUp = function(pts, newBaseRow) {\n  // Reset the base row to the bottom row when switching modes\n  if (this.mode_ !== 'rollUp') {\n    this.row_ = BOTTOM_ROW;\n    this.mode_ = 'rollUp';\n    // Spec says to wipe memories when switching to roll-up\n    this.flushDisplayed(pts);\n    this.nonDisplayed_ = createDisplayBuffer();\n    this.displayed_ = createDisplayBuffer();\n  }\n\n  if (newBaseRow !== undefined && newBaseRow !== this.row_) {\n    // move currently displayed captions (up or down) to the new base row\n    for (var i = 0; i < this.rollUpRows_; i++) {\n      this.displayed_[newBaseRow - i] = this.displayed_[this.row_ - i];\n      this.displayed_[this.row_ - i] = '';\n    }\n  }\n\n  if (newBaseRow === undefined) {\n    newBaseRow = this.row_;\n  }\n\n  this.topRow_ = newBaseRow - this.rollUpRows_ + 1;\n};\n\n// Adds the opening HTML tag for the passed character to the caption text,\n// and keeps track of it for later closing\nCea608Stream.prototype.addFormatting = function(pts, format) {\n  this.formatting_ = this.formatting_.concat(format);\n  var text = format.reduce(function(text, format) {\n    return text + '<' + format + '>';\n  }, '');\n  this[this.mode_](pts, text);\n};\n\n// Adds HTML closing tags for current formatting to caption text and\n// clears remembered formatting\nCea608Stream.prototype.clearFormatting = function(pts) {\n  if (!this.formatting_.length) {\n    return;\n  }\n  var text = this.formatting_.reverse().reduce(function(text, format) {\n    return text + '</' + format + '>';\n  }, '');\n  this.formatting_ = [];\n  this[this.mode_](pts, text);\n};\n\n// Mode Implementations\nCea608Stream.prototype.popOn = function(pts, text) {\n  var baseRow = this.nonDisplayed_[this.row_];\n\n  // buffer characters\n  baseRow += text;\n  this.nonDisplayed_[this.row_] = baseRow;\n};\n\nCea608Stream.prototype.rollUp = function(pts, text) {\n  var baseRow = this.displayed_[this.row_];\n\n  baseRow += text;\n  this.displayed_[this.row_] = baseRow;\n\n};\n\nCea608Stream.prototype.shiftRowsUp_ = function() {\n  var i;\n  // clear out inactive rows\n  for (i = 0; i < this.topRow_; i++) {\n    this.displayed_[i] = '';\n  }\n  for (i = this.row_ + 1; i < BOTTOM_ROW + 1; i++) {\n    this.displayed_[i] = '';\n  }\n  // shift displayed rows up\n  for (i = this.topRow_; i < this.row_; i++) {\n    this.displayed_[i] = this.displayed_[i + 1];\n  }\n  // clear out the bottom row\n  this.displayed_[this.row_] = '';\n};\n\nCea608Stream.prototype.paintOn = function(pts, text) {\n  var baseRow = this.displayed_[this.row_];\n\n  baseRow += text;\n  this.displayed_[this.row_] = baseRow;\n};\n\n// exports\nmodule.exports = {\n  CaptionStream: CaptionStream,\n  Cea608Stream: Cea608Stream\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\nmodule.exports = require('./m2ts');\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * A stream-based mp2t to mp4 converter. This utility can be used to\n * deliver mp4s to a SourceBuffer on platforms that support native\n * Media Source Extensions.\n */\n'use strict';\nvar Stream = require('../utils/stream.js'),\n  CaptionStream = require('./caption-stream'),\n  StreamTypes = require('./stream-types'),\n  TimestampRolloverStream = require('./timestamp-rollover-stream').TimestampRolloverStream;\n\n// object types\nvar TransportPacketStream, TransportParseStream, ElementaryStream;\n\n// constants\nvar\n  MP2T_PACKET_LENGTH = 188, // bytes\n  SYNC_BYTE = 0x47;\n\n/**\n * Splits an incoming stream of binary data into MPEG-2 Transport\n * Stream packets.\n */\nTransportPacketStream = function() {\n  var\n    buffer = new Uint8Array(MP2T_PACKET_LENGTH),\n    bytesInBuffer = 0;\n\n  TransportPacketStream.prototype.init.call(this);\n\n   // Deliver new bytes to the stream.\n\n  /**\n   * Split a stream of data into M2TS packets\n  **/\n  this.push = function(bytes) {\n    var\n      startIndex = 0,\n      endIndex = MP2T_PACKET_LENGTH,\n      everything;\n\n    // If there are bytes remaining from the last segment, prepend them to the\n    // bytes that were pushed in\n    if (bytesInBuffer) {\n      everything = new Uint8Array(bytes.byteLength + bytesInBuffer);\n      everything.set(buffer.subarray(0, bytesInBuffer));\n      everything.set(bytes, bytesInBuffer);\n      bytesInBuffer = 0;\n    } else {\n      everything = bytes;\n    }\n\n    // While we have enough data for a packet\n    while (endIndex < everything.byteLength) {\n      // Look for a pair of start and end sync bytes in the data..\n      if (everything[startIndex] === SYNC_BYTE && everything[endIndex] === SYNC_BYTE) {\n        // We found a packet so emit it and jump one whole packet forward in\n        // the stream\n        this.trigger('data', everything.subarray(startIndex, endIndex));\n        startIndex += MP2T_PACKET_LENGTH;\n        endIndex += MP2T_PACKET_LENGTH;\n        continue;\n      }\n      // If we get here, we have somehow become de-synchronized and we need to step\n      // forward one byte at a time until we find a pair of sync bytes that denote\n      // a packet\n      startIndex++;\n      endIndex++;\n    }\n\n    // If there was some data left over at the end of the segment that couldn't\n    // possibly be a whole packet, keep it because it might be the start of a packet\n    // that continues in the next segment\n    if (startIndex < everything.byteLength) {\n      buffer.set(everything.subarray(startIndex), 0);\n      bytesInBuffer = everything.byteLength - startIndex;\n    }\n  };\n\n  /**\n   * Passes identified M2TS packets to the TransportParseStream to be parsed\n  **/\n  this.flush = function() {\n    // If the buffer contains a whole packet when we are being flushed, emit it\n    // and empty the buffer. Otherwise hold onto the data because it may be\n    // important for decoding the next segment\n    if (bytesInBuffer === MP2T_PACKET_LENGTH && buffer[0] === SYNC_BYTE) {\n      this.trigger('data', buffer);\n      bytesInBuffer = 0;\n    }\n    this.trigger('done');\n  };\n\n  this.endTimeline = function() {\n    this.flush();\n    this.trigger('endedtimeline');\n  };\n\n  this.reset = function() {\n    bytesInBuffer = 0;\n    this.trigger('reset');\n  };\n};\nTransportPacketStream.prototype = new Stream();\n\n/**\n * Accepts an MP2T TransportPacketStream and emits data events with parsed\n * forms of the individual transport stream packets.\n */\nTransportParseStream = function() {\n  var parsePsi, parsePat, parsePmt, self;\n  TransportParseStream.prototype.init.call(this);\n  self = this;\n\n  this.packetsWaitingForPmt = [];\n  this.programMapTable = undefined;\n\n  parsePsi = function(payload, psi) {\n    var offset = 0;\n\n    // PSI packets may be split into multiple sections and those\n    // sections may be split into multiple packets. If a PSI\n    // section starts in this packet, the payload_unit_start_indicator\n    // will be true and the first byte of the payload will indicate\n    // the offset from the current position to the start of the\n    // section.\n    if (psi.payloadUnitStartIndicator) {\n      offset += payload[offset] + 1;\n    }\n\n    if (psi.type === 'pat') {\n      parsePat(payload.subarray(offset), psi);\n    } else {\n      parsePmt(payload.subarray(offset), psi);\n    }\n  };\n\n  parsePat = function(payload, pat) {\n    pat.section_number = payload[7]; // eslint-disable-line camelcase\n    pat.last_section_number = payload[8]; // eslint-disable-line camelcase\n\n    // skip the PSI header and parse the first PMT entry\n    self.pmtPid = (payload[10] & 0x1F) << 8 | payload[11];\n    pat.pmtPid = self.pmtPid;\n  };\n\n  /**\n   * Parse out the relevant fields of a Program Map Table (PMT).\n   * @param payload {Uint8Array} the PMT-specific portion of an MP2T\n   * packet. The first byte in this array should be the table_id\n   * field.\n   * @param pmt {object} the object that should be decorated with\n   * fields parsed from the PMT.\n   */\n  parsePmt = function(payload, pmt) {\n    var sectionLength, tableEnd, programInfoLength, offset;\n\n    // PMTs can be sent ahead of the time when they should actually\n    // take effect. We don't believe this should ever be the case\n    // for HLS but we'll ignore \"forward\" PMT declarations if we see\n    // them. Future PMT declarations have the current_next_indicator\n    // set to zero.\n    if (!(payload[5] & 0x01)) {\n      return;\n    }\n\n    // overwrite any existing program map table\n    self.programMapTable = {\n      video: null,\n      audio: null,\n      'timed-metadata': {}\n    };\n\n    // the mapping table ends at the end of the current section\n    sectionLength = (payload[1] & 0x0f) << 8 | payload[2];\n    tableEnd = 3 + sectionLength - 4;\n\n    // to determine where the table is, we have to figure out how\n    // long the program info descriptors are\n    programInfoLength = (payload[10] & 0x0f) << 8 | payload[11];\n\n    // advance the offset to the first entry in the mapping table\n    offset = 12 + programInfoLength;\n    while (offset < tableEnd) {\n      var streamType = payload[offset];\n      var pid = (payload[offset + 1] & 0x1F) << 8 | payload[offset + 2];\n\n      // only map a single elementary_pid for audio and video stream types\n      // TODO: should this be done for metadata too? for now maintain behavior of\n      //       multiple metadata streams\n      if (streamType === StreamTypes.H264_STREAM_TYPE &&\n          self.programMapTable.video === null) {\n        self.programMapTable.video = pid;\n      } else if (streamType === StreamTypes.ADTS_STREAM_TYPE &&\n                 self.programMapTable.audio === null) {\n        self.programMapTable.audio = pid;\n      } else if (streamType === StreamTypes.METADATA_STREAM_TYPE) {\n        // map pid to stream type for metadata streams\n        self.programMapTable['timed-metadata'][pid] = streamType;\n      }\n\n      // move to the next table entry\n      // skip past the elementary stream descriptors, if present\n      offset += ((payload[offset + 3] & 0x0F) << 8 | payload[offset + 4]) + 5;\n    }\n\n    // record the map on the packet as well\n    pmt.programMapTable = self.programMapTable;\n  };\n\n  /**\n   * Deliver a new MP2T packet to the next stream in the pipeline.\n   */\n  this.push = function(packet) {\n    var\n      result = {},\n      offset = 4;\n\n    result.payloadUnitStartIndicator = !!(packet[1] & 0x40);\n\n    // pid is a 13-bit field starting at the last bit of packet[1]\n    result.pid = packet[1] & 0x1f;\n    result.pid <<= 8;\n    result.pid |= packet[2];\n\n    // if an adaption field is present, its length is specified by the\n    // fifth byte of the TS packet header. The adaptation field is\n    // used to add stuffing to PES packets that don't fill a complete\n    // TS packet, and to specify some forms of timing and control data\n    // that we do not currently use.\n    if (((packet[3] & 0x30) >>> 4) > 0x01) {\n      offset += packet[offset] + 1;\n    }\n\n    // parse the rest of the packet based on the type\n    if (result.pid === 0) {\n      result.type = 'pat';\n      parsePsi(packet.subarray(offset), result);\n      this.trigger('data', result);\n    } else if (result.pid === this.pmtPid) {\n      result.type = 'pmt';\n      parsePsi(packet.subarray(offset), result);\n      this.trigger('data', result);\n\n      // if there are any packets waiting for a PMT to be found, process them now\n      while (this.packetsWaitingForPmt.length) {\n        this.processPes_.apply(this, this.packetsWaitingForPmt.shift());\n      }\n    } else if (this.programMapTable === undefined) {\n      // When we have not seen a PMT yet, defer further processing of\n      // PES packets until one has been parsed\n      this.packetsWaitingForPmt.push([packet, offset, result]);\n    } else {\n      this.processPes_(packet, offset, result);\n    }\n  };\n\n  this.processPes_ = function(packet, offset, result) {\n    // set the appropriate stream type\n    if (result.pid === this.programMapTable.video) {\n      result.streamType = StreamTypes.H264_STREAM_TYPE;\n    } else if (result.pid === this.programMapTable.audio) {\n      result.streamType = StreamTypes.ADTS_STREAM_TYPE;\n    } else {\n      // if not video or audio, it is timed-metadata or unknown\n      // if unknown, streamType will be undefined\n      result.streamType = this.programMapTable['timed-metadata'][result.pid];\n    }\n\n    result.type = 'pes';\n    result.data = packet.subarray(offset);\n    this.trigger('data', result);\n  };\n};\nTransportParseStream.prototype = new Stream();\nTransportParseStream.STREAM_TYPES  = {\n  h264: 0x1b,\n  adts: 0x0f\n};\n\n/**\n * Reconsistutes program elementary stream (PES) packets from parsed\n * transport stream packets. That is, if you pipe an\n * mp2t.TransportParseStream into a mp2t.ElementaryStream, the output\n * events will be events which capture the bytes for individual PES\n * packets plus relevant metadata that has been extracted from the\n * container.\n */\nElementaryStream = function() {\n  var\n    self = this,\n    // PES packet fragments\n    video = {\n      data: [],\n      size: 0\n    },\n    audio = {\n      data: [],\n      size: 0\n    },\n    timedMetadata = {\n      data: [],\n      size: 0\n    },\n    programMapTable,\n    parsePes = function(payload, pes) {\n      var ptsDtsFlags;\n\n      // get the packet length, this will be 0 for video\n      pes.packetLength = 6 + ((payload[4] << 8) | payload[5]);\n\n      // find out if this packets starts a new keyframe\n      pes.dataAlignmentIndicator = (payload[6] & 0x04) !== 0;\n      // PES packets may be annotated with a PTS value, or a PTS value\n      // and a DTS value. Determine what combination of values is\n      // available to work with.\n      ptsDtsFlags = payload[7];\n\n      // PTS and DTS are normally stored as a 33-bit number.  Javascript\n      // performs all bitwise operations on 32-bit integers but javascript\n      // supports a much greater range (52-bits) of integer using standard\n      // mathematical operations.\n      // We construct a 31-bit value using bitwise operators over the 31\n      // most significant bits and then multiply by 4 (equal to a left-shift\n      // of 2) before we add the final 2 least significant bits of the\n      // timestamp (equal to an OR.)\n      if (ptsDtsFlags & 0xC0) {\n        // the PTS and DTS are not written out directly. For information\n        // on how they are encoded, see\n        // http://dvd.sourceforge.net/dvdinfo/pes-hdr.html\n        pes.pts = (payload[9] & 0x0E) << 27 |\n          (payload[10] & 0xFF) << 20 |\n          (payload[11] & 0xFE) << 12 |\n          (payload[12] & 0xFF) <<  5 |\n          (payload[13] & 0xFE) >>>  3;\n        pes.pts *= 4; // Left shift by 2\n        pes.pts += (payload[13] & 0x06) >>> 1; // OR by the two LSBs\n        pes.dts = pes.pts;\n        if (ptsDtsFlags & 0x40) {\n          pes.dts = (payload[14] & 0x0E) << 27 |\n            (payload[15] & 0xFF) << 20 |\n            (payload[16] & 0xFE) << 12 |\n            (payload[17] & 0xFF) << 5 |\n            (payload[18] & 0xFE) >>> 3;\n          pes.dts *= 4; // Left shift by 2\n          pes.dts += (payload[18] & 0x06) >>> 1; // OR by the two LSBs\n        }\n      }\n      // the data section starts immediately after the PES header.\n      // pes_header_data_length specifies the number of header bytes\n      // that follow the last byte of the field.\n      pes.data = payload.subarray(9 + payload[8]);\n    },\n    /**\n      * Pass completely parsed PES packets to the next stream in the pipeline\n     **/\n    flushStream = function(stream, type, forceFlush) {\n      var\n        packetData = new Uint8Array(stream.size),\n        event = {\n          type: type\n        },\n        i = 0,\n        offset = 0,\n        packetFlushable = false,\n        fragment;\n\n      // do nothing if there is not enough buffered data for a complete\n      // PES header\n      if (!stream.data.length || stream.size < 9) {\n        return;\n      }\n      event.trackId = stream.data[0].pid;\n\n      // reassemble the packet\n      for (i = 0; i < stream.data.length; i++) {\n        fragment = stream.data[i];\n\n        packetData.set(fragment.data, offset);\n        offset += fragment.data.byteLength;\n      }\n\n      // parse assembled packet's PES header\n      parsePes(packetData, event);\n\n      // non-video PES packets MUST have a non-zero PES_packet_length\n      // check that there is enough stream data to fill the packet\n      packetFlushable = type === 'video' || event.packetLength <= stream.size;\n\n      // flush pending packets if the conditions are right\n      if (forceFlush || packetFlushable) {\n        stream.size = 0;\n        stream.data.length = 0;\n      }\n\n      // only emit packets that are complete. this is to avoid assembling\n      // incomplete PES packets due to poor segmentation\n      if (packetFlushable) {\n        self.trigger('data', event);\n      }\n    };\n\n  ElementaryStream.prototype.init.call(this);\n\n  /**\n   * Identifies M2TS packet types and parses PES packets using metadata\n   * parsed from the PMT\n   **/\n  this.push = function(data) {\n    ({\n      pat: function() {\n        // we have to wait for the PMT to arrive as well before we\n        // have any meaningful metadata\n      },\n      pes: function() {\n        var stream, streamType;\n\n        switch (data.streamType) {\n        case StreamTypes.H264_STREAM_TYPE:\n          stream = video;\n          streamType = 'video';\n          break;\n        case StreamTypes.ADTS_STREAM_TYPE:\n          stream = audio;\n          streamType = 'audio';\n          break;\n        case StreamTypes.METADATA_STREAM_TYPE:\n          stream = timedMetadata;\n          streamType = 'timed-metadata';\n          break;\n        default:\n          // ignore unknown stream types\n          return;\n        }\n\n        // if a new packet is starting, we can flush the completed\n        // packet\n        if (data.payloadUnitStartIndicator) {\n          flushStream(stream, streamType, true);\n        }\n\n        // buffer this fragment until we are sure we've received the\n        // complete payload\n        stream.data.push(data);\n        stream.size += data.data.byteLength;\n      },\n      pmt: function() {\n        var\n          event = {\n            type: 'metadata',\n            tracks: []\n          };\n\n        programMapTable = data.programMapTable;\n\n        // translate audio and video streams to tracks\n        if (programMapTable.video !== null) {\n          event.tracks.push({\n            timelineStartInfo: {\n              baseMediaDecodeTime: 0\n            },\n            id: +programMapTable.video,\n            codec: 'avc',\n            type: 'video'\n          });\n        }\n        if (programMapTable.audio !== null) {\n          event.tracks.push({\n            timelineStartInfo: {\n              baseMediaDecodeTime: 0\n            },\n            id: +programMapTable.audio,\n            codec: 'adts',\n            type: 'audio'\n          });\n        }\n\n        self.trigger('data', event);\n      }\n    })[data.type]();\n  };\n\n  this.reset = function() {\n    video.size = 0;\n    video.data.length = 0;\n    audio.size = 0;\n    audio.data.length = 0;\n    this.trigger('reset');\n  };\n\n  /**\n   * Flush any remaining input. Video PES packets may be of variable\n   * length. Normally, the start of a new video packet can trigger the\n   * finalization of the previous packet. That is not possible if no\n   * more video is forthcoming, however. In that case, some other\n   * mechanism (like the end of the file) has to be employed. When it is\n   * clear that no additional data is forthcoming, calling this method\n   * will flush the buffered packets.\n   */\n  this.flushStreams_ = function() {\n    // !!THIS ORDER IS IMPORTANT!!\n    // video first then audio\n    flushStream(video, 'video');\n    flushStream(audio, 'audio');\n    flushStream(timedMetadata, 'timed-metadata');\n  };\n\n  this.flush = function() {\n    this.flushStreams_();\n    this.trigger('done');\n  };\n};\nElementaryStream.prototype = new Stream();\n\nvar m2ts = {\n  PAT_PID: 0x0000,\n  MP2T_PACKET_LENGTH: MP2T_PACKET_LENGTH,\n  TransportPacketStream: TransportPacketStream,\n  TransportParseStream: TransportParseStream,\n  ElementaryStream: ElementaryStream,\n  TimestampRolloverStream: TimestampRolloverStream,\n  CaptionStream: CaptionStream.CaptionStream,\n  Cea608Stream: CaptionStream.Cea608Stream,\n  MetadataStream: require('./metadata-stream')\n};\n\nfor (var type in StreamTypes) {\n  if (StreamTypes.hasOwnProperty(type)) {\n    m2ts[type] = StreamTypes[type];\n  }\n}\n\nmodule.exports = m2ts;\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * Accepts program elementary stream (PES) data events and parses out\n * ID3 metadata from them, if present.\n * @see http://id3.org/id3v2.3.0\n */\n'use strict';\nvar\n  Stream = require('../utils/stream'),\n  StreamTypes = require('./stream-types'),\n  // return a percent-encoded representation of the specified byte range\n  // @see http://en.wikipedia.org/wiki/Percent-encoding\n  percentEncode = function(bytes, start, end) {\n    var i, result = '';\n    for (i = start; i < end; i++) {\n      result += '%' + ('00' + bytes[i].toString(16)).slice(-2);\n    }\n    return result;\n  },\n  // return the string representation of the specified byte range,\n  // interpreted as UTf-8.\n  parseUtf8 = function(bytes, start, end) {\n    return decodeURIComponent(percentEncode(bytes, start, end));\n  },\n  // return the string representation of the specified byte range,\n  // interpreted as ISO-8859-1.\n  parseIso88591 = function(bytes, start, end) {\n    return unescape(percentEncode(bytes, start, end)); // jshint ignore:line\n  },\n  parseSyncSafeInteger = function(data) {\n    return (data[0] << 21) |\n            (data[1] << 14) |\n            (data[2] << 7) |\n            (data[3]);\n  },\n  tagParsers = {\n    TXXX: function(tag) {\n      var i;\n      if (tag.data[0] !== 3) {\n        // ignore frames with unrecognized character encodings\n        return;\n      }\n\n      for (i = 1; i < tag.data.length; i++) {\n        if (tag.data[i] === 0) {\n          // parse the text fields\n          tag.description = parseUtf8(tag.data, 1, i);\n          // do not include the null terminator in the tag value\n          tag.value = parseUtf8(tag.data, i + 1, tag.data.length).replace(/\\0*$/, '');\n          break;\n        }\n      }\n      tag.data = tag.value;\n    },\n    WXXX: function(tag) {\n      var i;\n      if (tag.data[0] !== 3) {\n        // ignore frames with unrecognized character encodings\n        return;\n      }\n\n      for (i = 1; i < tag.data.length; i++) {\n        if (tag.data[i] === 0) {\n          // parse the description and URL fields\n          tag.description = parseUtf8(tag.data, 1, i);\n          tag.url = parseUtf8(tag.data, i + 1, tag.data.length);\n          break;\n        }\n      }\n    },\n    PRIV: function(tag) {\n      var i;\n\n      for (i = 0; i < tag.data.length; i++) {\n        if (tag.data[i] === 0) {\n          // parse the description and URL fields\n          tag.owner = parseIso88591(tag.data, 0, i);\n          break;\n        }\n      }\n      tag.privateData = tag.data.subarray(i + 1);\n      tag.data = tag.privateData;\n    }\n  },\n  MetadataStream;\n\nMetadataStream = function(options) {\n  var\n    settings = {\n      debug: !!(options && options.debug),\n\n      // the bytes of the program-level descriptor field in MP2T\n      // see ISO/IEC 13818-1:2013 (E), section 2.6 \"Program and\n      // program element descriptors\"\n      descriptor: options && options.descriptor\n    },\n    // the total size in bytes of the ID3 tag being parsed\n    tagSize = 0,\n    // tag data that is not complete enough to be parsed\n    buffer = [],\n    // the total number of bytes currently in the buffer\n    bufferSize = 0,\n    i;\n\n  MetadataStream.prototype.init.call(this);\n\n  // calculate the text track in-band metadata track dispatch type\n  // https://html.spec.whatwg.org/multipage/embedded-content.html#steps-to-expose-a-media-resource-specific-text-track\n  this.dispatchType = StreamTypes.METADATA_STREAM_TYPE.toString(16);\n  if (settings.descriptor) {\n    for (i = 0; i < settings.descriptor.length; i++) {\n      this.dispatchType += ('00' + settings.descriptor[i].toString(16)).slice(-2);\n    }\n  }\n\n  this.push = function(chunk) {\n    var tag, frameStart, frameSize, frame, i, frameHeader;\n    if (chunk.type !== 'timed-metadata') {\n      return;\n    }\n\n    // if data_alignment_indicator is set in the PES header,\n    // we must have the start of a new ID3 tag. Assume anything\n    // remaining in the buffer was malformed and throw it out\n    if (chunk.dataAlignmentIndicator) {\n      bufferSize = 0;\n      buffer.length = 0;\n    }\n\n    // ignore events that don't look like ID3 data\n    if (buffer.length === 0 &&\n        (chunk.data.length < 10 ||\n          chunk.data[0] !== 'I'.charCodeAt(0) ||\n          chunk.data[1] !== 'D'.charCodeAt(0) ||\n          chunk.data[2] !== '3'.charCodeAt(0))) {\n      if (settings.debug) {\n        // eslint-disable-next-line no-console\n        console.log('Skipping unrecognized metadata packet');\n      }\n      return;\n    }\n\n    // add this chunk to the data we've collected so far\n\n    buffer.push(chunk);\n    bufferSize += chunk.data.byteLength;\n\n    // grab the size of the entire frame from the ID3 header\n    if (buffer.length === 1) {\n      // the frame size is transmitted as a 28-bit integer in the\n      // last four bytes of the ID3 header.\n      // The most significant bit of each byte is dropped and the\n      // results concatenated to recover the actual value.\n      tagSize = parseSyncSafeInteger(chunk.data.subarray(6, 10));\n\n      // ID3 reports the tag size excluding the header but it's more\n      // convenient for our comparisons to include it\n      tagSize += 10;\n    }\n\n    // if the entire frame has not arrived, wait for more data\n    if (bufferSize < tagSize) {\n      return;\n    }\n\n    // collect the entire frame so it can be parsed\n    tag = {\n      data: new Uint8Array(tagSize),\n      frames: [],\n      pts: buffer[0].pts,\n      dts: buffer[0].dts\n    };\n    for (i = 0; i < tagSize;) {\n      tag.data.set(buffer[0].data.subarray(0, tagSize - i), i);\n      i += buffer[0].data.byteLength;\n      bufferSize -= buffer[0].data.byteLength;\n      buffer.shift();\n    }\n\n    // find the start of the first frame and the end of the tag\n    frameStart = 10;\n    if (tag.data[5] & 0x40) {\n      // advance the frame start past the extended header\n      frameStart += 4; // header size field\n      frameStart += parseSyncSafeInteger(tag.data.subarray(10, 14));\n\n      // clip any padding off the end\n      tagSize -= parseSyncSafeInteger(tag.data.subarray(16, 20));\n    }\n\n    // parse one or more ID3 frames\n    // http://id3.org/id3v2.3.0#ID3v2_frame_overview\n    do {\n      // determine the number of bytes in this frame\n      frameSize = parseSyncSafeInteger(tag.data.subarray(frameStart + 4, frameStart + 8));\n      if (frameSize < 1) {\n         // eslint-disable-next-line no-console\n        return console.log('Malformed ID3 frame encountered. Skipping metadata parsing.');\n      }\n      frameHeader = String.fromCharCode(tag.data[frameStart],\n                                        tag.data[frameStart + 1],\n                                        tag.data[frameStart + 2],\n                                        tag.data[frameStart + 3]);\n\n\n      frame = {\n        id: frameHeader,\n        data: tag.data.subarray(frameStart + 10, frameStart + frameSize + 10)\n      };\n      frame.key = frame.id;\n      if (tagParsers[frame.id]) {\n        tagParsers[frame.id](frame);\n\n        // handle the special PRIV frame used to indicate the start\n        // time for raw AAC data\n        if (frame.owner === 'com.apple.streaming.transportStreamTimestamp') {\n          var\n            d = frame.data,\n            size = ((d[3] & 0x01)  << 30) |\n                   (d[4]  << 22) |\n                   (d[5] << 14) |\n                   (d[6] << 6) |\n                   (d[7] >>> 2);\n\n          size *= 4;\n          size += d[7] & 0x03;\n          frame.timeStamp = size;\n          // in raw AAC, all subsequent data will be timestamped based\n          // on the value of this frame\n          // we couldn't have known the appropriate pts and dts before\n          // parsing this ID3 tag so set those values now\n          if (tag.pts === undefined && tag.dts === undefined) {\n            tag.pts = frame.timeStamp;\n            tag.dts = frame.timeStamp;\n          }\n          this.trigger('timestamp', frame);\n        }\n      }\n      tag.frames.push(frame);\n\n      frameStart += 10; // advance past the frame header\n      frameStart += frameSize; // advance past the frame body\n    } while (frameStart < tagSize);\n    this.trigger('data', tag);\n  };\n};\nMetadataStream.prototype = new Stream();\n\nmodule.exports = MetadataStream;\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * Utilities to detect basic properties and metadata about TS Segments.\n */\n'use strict';\n\nvar StreamTypes = require('./stream-types.js');\n\nvar parsePid = function(packet) {\n  var pid = packet[1] & 0x1f;\n  pid <<= 8;\n  pid |= packet[2];\n  return pid;\n};\n\nvar parsePayloadUnitStartIndicator = function(packet) {\n  return !!(packet[1] & 0x40);\n};\n\nvar parseAdaptionField = function(packet) {\n  var offset = 0;\n  // if an adaption field is present, its length is specified by the\n  // fifth byte of the TS packet header. The adaptation field is\n  // used to add stuffing to PES packets that don't fill a complete\n  // TS packet, and to specify some forms of timing and control data\n  // that we do not currently use.\n  if (((packet[3] & 0x30) >>> 4) > 0x01) {\n    offset += packet[4] + 1;\n  }\n  return offset;\n};\n\nvar parseType = function(packet, pmtPid) {\n  var pid = parsePid(packet);\n  if (pid === 0) {\n    return 'pat';\n  } else if (pid === pmtPid) {\n    return 'pmt';\n  } else if (pmtPid) {\n    return 'pes';\n  }\n  return null;\n};\n\nvar parsePat = function(packet) {\n  var pusi = parsePayloadUnitStartIndicator(packet);\n  var offset = 4 + parseAdaptionField(packet);\n\n  if (pusi) {\n    offset += packet[offset] + 1;\n  }\n\n  return (packet[offset + 10] & 0x1f) << 8 | packet[offset + 11];\n};\n\nvar parsePmt = function(packet) {\n  var programMapTable = {};\n  var pusi = parsePayloadUnitStartIndicator(packet);\n  var payloadOffset = 4 + parseAdaptionField(packet);\n\n  if (pusi) {\n    payloadOffset += packet[payloadOffset] + 1;\n  }\n\n  // PMTs can be sent ahead of the time when they should actually\n  // take effect. We don't believe this should ever be the case\n  // for HLS but we'll ignore \"forward\" PMT declarations if we see\n  // them. Future PMT declarations have the current_next_indicator\n  // set to zero.\n  if (!(packet[payloadOffset + 5] & 0x01)) {\n    return;\n  }\n\n  var sectionLength, tableEnd, programInfoLength;\n  // the mapping table ends at the end of the current section\n  sectionLength = (packet[payloadOffset + 1] & 0x0f) << 8 | packet[payloadOffset + 2];\n  tableEnd = 3 + sectionLength - 4;\n\n  // to determine where the table is, we have to figure out how\n  // long the program info descriptors are\n  programInfoLength = (packet[payloadOffset + 10] & 0x0f) << 8 | packet[payloadOffset + 11];\n\n  // advance the offset to the first entry in the mapping table\n  var offset = 12 + programInfoLength;\n  while (offset < tableEnd) {\n    var i = payloadOffset + offset;\n    // add an entry that maps the elementary_pid to the stream_type\n    programMapTable[(packet[i + 1] & 0x1F) << 8 | packet[i + 2]] = packet[i];\n\n    // move to the next table entry\n    // skip past the elementary stream descriptors, if present\n    offset += ((packet[i + 3] & 0x0F) << 8 | packet[i + 4]) + 5;\n  }\n  return programMapTable;\n};\n\nvar parsePesType = function(packet, programMapTable) {\n  var pid = parsePid(packet);\n  var type = programMapTable[pid];\n  switch (type) {\n    case StreamTypes.H264_STREAM_TYPE:\n      return 'video';\n    case StreamTypes.ADTS_STREAM_TYPE:\n      return 'audio';\n    case StreamTypes.METADATA_STREAM_TYPE:\n      return 'timed-metadata';\n    default:\n      return null;\n  }\n};\n\nvar parsePesTime = function(packet) {\n  var pusi = parsePayloadUnitStartIndicator(packet);\n  if (!pusi) {\n    return null;\n  }\n\n  var offset = 4 + parseAdaptionField(packet);\n\n  if (offset >= packet.byteLength) {\n    // From the H 222.0 MPEG-TS spec\n    // \"For transport stream packets carrying PES packets, stuffing is needed when there\n    //  is insufficient PES packet data to completely fill the transport stream packet\n    //  payload bytes. Stuffing is accomplished by defining an adaptation field longer than\n    //  the sum of the lengths of the data elements in it, so that the payload bytes\n    //  remaining after the adaptation field exactly accommodates the available PES packet\n    //  data.\"\n    //\n    // If the offset is >= the length of the packet, then the packet contains no data\n    // and instead is just adaption field stuffing bytes\n    return null;\n  }\n\n  var pes = null;\n  var ptsDtsFlags;\n\n  // PES packets may be annotated with a PTS value, or a PTS value\n  // and a DTS value. Determine what combination of values is\n  // available to work with.\n  ptsDtsFlags = packet[offset + 7];\n\n  // PTS and DTS are normally stored as a 33-bit number.  Javascript\n  // performs all bitwise operations on 32-bit integers but javascript\n  // supports a much greater range (52-bits) of integer using standard\n  // mathematical operations.\n  // We construct a 31-bit value using bitwise operators over the 31\n  // most significant bits and then multiply by 4 (equal to a left-shift\n  // of 2) before we add the final 2 least significant bits of the\n  // timestamp (equal to an OR.)\n  if (ptsDtsFlags & 0xC0) {\n    pes = {};\n    // the PTS and DTS are not written out directly. For information\n    // on how they are encoded, see\n    // http://dvd.sourceforge.net/dvdinfo/pes-hdr.html\n    pes.pts = (packet[offset + 9] & 0x0E) << 27 |\n      (packet[offset + 10] & 0xFF) << 20 |\n      (packet[offset + 11] & 0xFE) << 12 |\n      (packet[offset + 12] & 0xFF) <<  5 |\n      (packet[offset + 13] & 0xFE) >>>  3;\n    pes.pts *= 4; // Left shift by 2\n    pes.pts += (packet[offset + 13] & 0x06) >>> 1; // OR by the two LSBs\n    pes.dts = pes.pts;\n    if (ptsDtsFlags & 0x40) {\n      pes.dts = (packet[offset + 14] & 0x0E) << 27 |\n        (packet[offset + 15] & 0xFF) << 20 |\n        (packet[offset + 16] & 0xFE) << 12 |\n        (packet[offset + 17] & 0xFF) << 5 |\n        (packet[offset + 18] & 0xFE) >>> 3;\n      pes.dts *= 4; // Left shift by 2\n      pes.dts += (packet[offset + 18] & 0x06) >>> 1; // OR by the two LSBs\n    }\n  }\n  return pes;\n};\n\nvar parseNalUnitType = function(type) {\n  switch (type) {\n    case 0x05:\n      return 'slice_layer_without_partitioning_rbsp_idr';\n    case 0x06:\n      return 'sei_rbsp';\n    case 0x07:\n      return 'seq_parameter_set_rbsp';\n    case 0x08:\n      return 'pic_parameter_set_rbsp';\n    case 0x09:\n      return 'access_unit_delimiter_rbsp';\n    default:\n      return null;\n  }\n};\n\nvar videoPacketContainsKeyFrame = function(packet) {\n  var offset = 4 + parseAdaptionField(packet);\n  var frameBuffer = packet.subarray(offset);\n  var frameI = 0;\n  var frameSyncPoint = 0;\n  var foundKeyFrame = false;\n  var nalType;\n\n  // advance the sync point to a NAL start, if necessary\n  for (; frameSyncPoint < frameBuffer.byteLength - 3; frameSyncPoint++) {\n    if (frameBuffer[frameSyncPoint + 2] === 1) {\n      // the sync point is properly aligned\n      frameI = frameSyncPoint + 5;\n      break;\n    }\n  }\n\n  while (frameI < frameBuffer.byteLength) {\n    // look at the current byte to determine if we've hit the end of\n    // a NAL unit boundary\n    switch (frameBuffer[frameI]) {\n    case 0:\n      // skip past non-sync sequences\n      if (frameBuffer[frameI - 1] !== 0) {\n        frameI += 2;\n        break;\n      } else if (frameBuffer[frameI - 2] !== 0) {\n        frameI++;\n        break;\n      }\n\n      if (frameSyncPoint + 3 !== frameI - 2) {\n        nalType = parseNalUnitType(frameBuffer[frameSyncPoint + 3] & 0x1f);\n        if (nalType === 'slice_layer_without_partitioning_rbsp_idr') {\n          foundKeyFrame = true;\n        }\n      }\n\n      // drop trailing zeroes\n      do {\n        frameI++;\n      } while (frameBuffer[frameI] !== 1 && frameI < frameBuffer.length);\n      frameSyncPoint = frameI - 2;\n      frameI += 3;\n      break;\n    case 1:\n      // skip past non-sync sequences\n      if (frameBuffer[frameI - 1] !== 0 ||\n          frameBuffer[frameI - 2] !== 0) {\n        frameI += 3;\n        break;\n      }\n\n      nalType = parseNalUnitType(frameBuffer[frameSyncPoint + 3] & 0x1f);\n      if (nalType === 'slice_layer_without_partitioning_rbsp_idr') {\n        foundKeyFrame = true;\n      }\n      frameSyncPoint = frameI - 2;\n      frameI += 3;\n      break;\n    default:\n      // the current byte isn't a one or zero, so it cannot be part\n      // of a sync sequence\n      frameI += 3;\n      break;\n    }\n  }\n  frameBuffer = frameBuffer.subarray(frameSyncPoint);\n  frameI -= frameSyncPoint;\n  frameSyncPoint = 0;\n  // parse the final nal\n  if (frameBuffer && frameBuffer.byteLength > 3) {\n    nalType = parseNalUnitType(frameBuffer[frameSyncPoint + 3] & 0x1f);\n    if (nalType === 'slice_layer_without_partitioning_rbsp_idr') {\n      foundKeyFrame = true;\n    }\n  }\n\n  return foundKeyFrame;\n};\n\n\nmodule.exports = {\n  parseType: parseType,\n  parsePat: parsePat,\n  parsePmt: parsePmt,\n  parsePayloadUnitStartIndicator: parsePayloadUnitStartIndicator,\n  parsePesType: parsePesType,\n  parsePesTime: parsePesTime,\n  videoPacketContainsKeyFrame: videoPacketContainsKeyFrame\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\n'use strict';\n\nmodule.exports = {\n  H264_STREAM_TYPE: 0x1B,\n  ADTS_STREAM_TYPE: 0x0F,\n  METADATA_STREAM_TYPE: 0x15\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * Accepts program elementary stream (PES) data events and corrects\n * decode and presentation time stamps to account for a rollover\n * of the 33 bit value.\n */\n\n'use strict';\n\nvar Stream = require('../utils/stream');\n\nvar MAX_TS = 8589934592;\n\nvar RO_THRESH = 4294967296;\n\nvar TYPE_SHARED = 'shared';\n\nvar handleRollover = function(value, reference) {\n  var direction = 1;\n\n  if (value > reference) {\n    // If the current timestamp value is greater than our reference timestamp and we detect a\n    // timestamp rollover, this means the roll over is happening in the opposite direction.\n    // Example scenario: Enter a long stream/video just after a rollover occurred. The reference\n    // point will be set to a small number, e.g. 1. The user then seeks backwards over the\n    // rollover point. In loading this segment, the timestamp values will be very large,\n    // e.g. 2^33 - 1. Since this comes before the data we loaded previously, we want to adjust\n    // the time stamp to be `value - 2^33`.\n    direction = -1;\n  }\n\n  // Note: A seek forwards or back that is greater than the RO_THRESH (2^32, ~13 hours) will\n  // cause an incorrect adjustment.\n  while (Math.abs(reference - value) > RO_THRESH) {\n    value += (direction * MAX_TS);\n  }\n\n  return value;\n};\n\nvar TimestampRolloverStream = function(type) {\n  var lastDTS, referenceDTS;\n\n  TimestampRolloverStream.prototype.init.call(this);\n\n  // The \"shared\" type is used in cases where a stream will contain muxed\n  // video and audio. We could use `undefined` here, but having a string\n  // makes debugging a little clearer.\n  this.type_ = type || TYPE_SHARED;\n\n  this.push = function(data) {\n\n    // Any \"shared\" rollover streams will accept _all_ data. Otherwise,\n    // streams will only accept data that matches their type.\n    if (this.type_ !== TYPE_SHARED && data.type !== this.type_) {\n      return;\n    }\n\n    if (referenceDTS === undefined) {\n      referenceDTS = data.dts;\n    }\n\n    data.dts = handleRollover(data.dts, referenceDTS);\n    data.pts = handleRollover(data.pts, referenceDTS);\n\n    lastDTS = data.dts;\n\n    this.trigger('data', data);\n  };\n\n  this.flush = function() {\n    referenceDTS = lastDTS;\n    this.trigger('done');\n  };\n\n  this.endTimeline = function() {\n    this.flush();\n    this.trigger('endedtimeline');\n  };\n\n  this.discontinuity = function() {\n    referenceDTS = void 0;\n    lastDTS = void 0;\n  };\n\n  this.reset = function() {\n    this.discontinuity();\n    this.trigger('reset');\n  };\n};\n\nTimestampRolloverStream.prototype = new Stream();\n\nmodule.exports = {\n  TimestampRolloverStream: TimestampRolloverStream,\n  handleRollover: handleRollover\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\nvar coneOfSilence = require('../data/silence');\nvar clock = require('../utils/clock');\n\n/**\n * Sum the `byteLength` properties of the data in each AAC frame\n */\nvar sumFrameByteLengths = function(array) {\n  var\n    i,\n    currentObj,\n    sum = 0;\n\n  // sum the byteLength's all each nal unit in the frame\n  for (i = 0; i < array.length; i++) {\n    currentObj = array[i];\n    sum += currentObj.data.byteLength;\n  }\n\n  return sum;\n};\n\n// Possibly pad (prefix) the audio track with silence if appending this track\n// would lead to the introduction of a gap in the audio buffer\nvar prefixWithSilence = function(\n  track,\n  frames,\n  audioAppendStartTs,\n  videoBaseMediaDecodeTime\n) {\n  var\n    baseMediaDecodeTimeTs,\n    frameDuration = 0,\n    audioGapDuration = 0,\n    audioFillFrameCount = 0,\n    audioFillDuration = 0,\n    silentFrame,\n    i,\n    firstFrame;\n\n  if (!frames.length) {\n    return;\n  }\n\n  baseMediaDecodeTimeTs =\n    clock.audioTsToVideoTs(track.baseMediaDecodeTime, track.samplerate);\n  // determine frame clock duration based on sample rate, round up to avoid overfills\n  frameDuration = Math.ceil(clock.ONE_SECOND_IN_TS / (track.samplerate / 1024));\n\n  if (audioAppendStartTs && videoBaseMediaDecodeTime) {\n    // insert the shortest possible amount (audio gap or audio to video gap)\n    audioGapDuration =\n      baseMediaDecodeTimeTs - Math.max(audioAppendStartTs, videoBaseMediaDecodeTime);\n    // number of full frames in the audio gap\n    audioFillFrameCount = Math.floor(audioGapDuration / frameDuration);\n    audioFillDuration = audioFillFrameCount * frameDuration;\n  }\n\n  // don't attempt to fill gaps smaller than a single frame or larger\n  // than a half second\n  if (audioFillFrameCount < 1 || audioFillDuration > clock.ONE_SECOND_IN_TS / 2) {\n    return;\n  }\n\n  silentFrame = coneOfSilence()[track.samplerate];\n\n  if (!silentFrame) {\n    // we don't have a silent frame pregenerated for the sample rate, so use a frame\n    // from the content instead\n    silentFrame = frames[0].data;\n  }\n\n  for (i = 0; i < audioFillFrameCount; i++) {\n    firstFrame = frames[0];\n\n    frames.splice(0, 0, {\n      data: silentFrame,\n      dts: firstFrame.dts - frameDuration,\n      pts: firstFrame.pts - frameDuration\n    });\n  }\n\n  track.baseMediaDecodeTime -=\n    Math.floor(clock.videoTsToAudioTs(audioFillDuration, track.samplerate));\n};\n\n// If the audio segment extends before the earliest allowed dts\n// value, remove AAC frames until starts at or after the earliest\n// allowed DTS so that we don't end up with a negative baseMedia-\n// DecodeTime for the audio track\nvar trimAdtsFramesByEarliestDts = function(adtsFrames, track, earliestAllowedDts) {\n  if (track.minSegmentDts >= earliestAllowedDts) {\n    return adtsFrames;\n  }\n\n  // We will need to recalculate the earliest segment Dts\n  track.minSegmentDts = Infinity;\n\n  return adtsFrames.filter(function(currentFrame) {\n    // If this is an allowed frame, keep it and record it's Dts\n    if (currentFrame.dts >= earliestAllowedDts) {\n      track.minSegmentDts = Math.min(track.minSegmentDts, currentFrame.dts);\n      track.minSegmentPts = track.minSegmentDts;\n      return true;\n    }\n    // Otherwise, discard it\n    return false;\n  });\n};\n\n// generate the track's raw mdat data from an array of frames\nvar generateSampleTable = function(frames) {\n  var\n    i,\n    currentFrame,\n    samples = [];\n\n  for (i = 0; i < frames.length; i++) {\n    currentFrame = frames[i];\n    samples.push({\n      size: currentFrame.data.byteLength,\n      duration: 1024 // For AAC audio, all samples contain 1024 samples\n    });\n  }\n  return samples;\n};\n\n// generate the track's sample table from an array of frames\nvar concatenateFrameData = function(frames) {\n  var\n    i,\n    currentFrame,\n    dataOffset = 0,\n    data = new Uint8Array(sumFrameByteLengths(frames));\n\n  for (i = 0; i < frames.length; i++) {\n    currentFrame = frames[i];\n\n    data.set(currentFrame.data, dataOffset);\n    dataOffset += currentFrame.data.byteLength;\n  }\n  return data;\n};\n\nmodule.exports = {\n  prefixWithSilence: prefixWithSilence,\n  trimAdtsFramesByEarliestDts: trimAdtsFramesByEarliestDts,\n  generateSampleTable: generateSampleTable,\n  concatenateFrameData: concatenateFrameData\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * Reads in-band CEA-708 captions out of FMP4 segments.\n * @see https://en.wikipedia.org/wiki/CEA-708\n */\n'use strict';\n\nvar discardEmulationPreventionBytes = require('../tools/caption-packet-parser').discardEmulationPreventionBytes;\nvar CaptionStream = require('../m2ts/caption-stream').CaptionStream;\nvar findBox = require('../mp4/find-box.js');\nvar parseTfdt = require('../tools/parse-tfdt.js');\nvar parseTrun = require('../tools/parse-trun.js');\nvar parseTfhd = require('../tools/parse-tfhd.js');\n\n/**\n  * Maps an offset in the mdat to a sample based on the the size of the samples.\n  * Assumes that `parseSamples` has been called first.\n  *\n  * @param {Number} offset - The offset into the mdat\n  * @param {Object[]} samples - An array of samples, parsed using `parseSamples`\n  * @return {?Object} The matching sample, or null if no match was found.\n  *\n  * @see ISO-BMFF-12/2015, Section 8.8.8\n **/\nvar mapToSample = function(offset, samples) {\n  var approximateOffset = offset;\n\n  for (var i = 0; i < samples.length; i++) {\n    var sample = samples[i];\n\n    if (approximateOffset < sample.size) {\n      return sample;\n    }\n\n    approximateOffset -= sample.size;\n  }\n\n  return null;\n};\n\n/**\n  * Finds SEI nal units contained in a Media Data Box.\n  * Assumes that `parseSamples` has been called first.\n  *\n  * @param {Uint8Array} avcStream - The bytes of the mdat\n  * @param {Object[]} samples - The samples parsed out by `parseSamples`\n  * @param {Number} trackId - The trackId of this video track\n  * @return {Object[]} seiNals - the parsed SEI NALUs found.\n  *   The contents of the seiNal should match what is expected by\n  *   CaptionStream.push (nalUnitType, size, data, escapedRBSP, pts, dts)\n  *\n  * @see ISO-BMFF-12/2015, Section 8.1.1\n  * @see Rec. ITU-T H.264, 7.3.2.3.1\n **/\nvar findSeiNals = function(avcStream, samples, trackId) {\n  var\n    avcView = new DataView(avcStream.buffer, avcStream.byteOffset, avcStream.byteLength),\n    result = [],\n    seiNal,\n    i,\n    length,\n    lastMatchedSample;\n\n  for (i = 0; i + 4 < avcStream.length; i += length) {\n    length = avcView.getUint32(i);\n    i += 4;\n\n    // Bail if this doesn't appear to be an H264 stream\n    if (length <= 0) {\n      continue;\n    }\n\n    switch (avcStream[i] & 0x1F) {\n    case 0x06:\n      var data = avcStream.subarray(i + 1, i + 1 + length);\n      var matchingSample = mapToSample(i, samples);\n\n      seiNal = {\n        nalUnitType: 'sei_rbsp',\n        size: length,\n        data: data,\n        escapedRBSP: discardEmulationPreventionBytes(data),\n        trackId: trackId\n      };\n\n      if (matchingSample) {\n        seiNal.pts = matchingSample.pts;\n        seiNal.dts = matchingSample.dts;\n        lastMatchedSample = matchingSample;\n      } else if (lastMatchedSample) {\n        // If a matching sample cannot be found, use the last\n        // sample's values as they should be as close as possible\n        seiNal.pts = lastMatchedSample.pts;\n        seiNal.dts = lastMatchedSample.dts;\n      } else {\n        // eslint-disable-next-line no-console\n        console.log(\"We've encountered a nal unit without data. See mux.js#233.\");\n        break;\n      }\n\n      result.push(seiNal);\n      break;\n    default:\n      break;\n    }\n  }\n\n  return result;\n};\n\n/**\n  * Parses sample information out of Track Run Boxes and calculates\n  * the absolute presentation and decode timestamps of each sample.\n  *\n  * @param {Array<Uint8Array>} truns - The Trun Run boxes to be parsed\n  * @param {Number} baseMediaDecodeTime - base media decode time from tfdt\n      @see ISO-BMFF-12/2015, Section 8.8.12\n  * @param {Object} tfhd - The parsed Track Fragment Header\n  *   @see inspect.parseTfhd\n  * @return {Object[]} the parsed samples\n  *\n  * @see ISO-BMFF-12/2015, Section 8.8.8\n **/\nvar parseSamples = function(truns, baseMediaDecodeTime, tfhd) {\n  var currentDts = baseMediaDecodeTime;\n  var defaultSampleDuration = tfhd.defaultSampleDuration || 0;\n  var defaultSampleSize = tfhd.defaultSampleSize || 0;\n  var trackId = tfhd.trackId;\n  var allSamples = [];\n\n  truns.forEach(function(trun) {\n    // Note: We currently do not parse the sample table as well\n    // as the trun. It's possible some sources will require this.\n    // moov > trak > mdia > minf > stbl\n    var trackRun = parseTrun(trun);\n    var samples = trackRun.samples;\n\n    samples.forEach(function(sample) {\n      if (sample.duration === undefined) {\n        sample.duration = defaultSampleDuration;\n      }\n      if (sample.size === undefined) {\n        sample.size = defaultSampleSize;\n      }\n      sample.trackId = trackId;\n      sample.dts = currentDts;\n      if (sample.compositionTimeOffset === undefined) {\n        sample.compositionTimeOffset = 0;\n      }\n      sample.pts = currentDts + sample.compositionTimeOffset;\n\n      currentDts += sample.duration;\n    });\n\n    allSamples = allSamples.concat(samples);\n  });\n\n  return allSamples;\n};\n\n/**\n  * Parses out caption nals from an FMP4 segment's video tracks.\n  *\n  * @param {Uint8Array} segment - The bytes of a single segment\n  * @param {Number} videoTrackId - The trackId of a video track in the segment\n  * @return {Object.<Number, Object[]>} A mapping of video trackId to\n  *   a list of seiNals found in that track\n **/\nvar parseCaptionNals = function(segment, videoTrackId) {\n  // To get the samples\n  var trafs = findBox(segment, ['moof', 'traf']);\n  // To get SEI NAL units\n  var mdats = findBox(segment, ['mdat']);\n  var captionNals = {};\n  var mdatTrafPairs = [];\n\n  // Pair up each traf with a mdat as moofs and mdats are in pairs\n  mdats.forEach(function(mdat, index) {\n    var matchingTraf = trafs[index];\n    mdatTrafPairs.push({\n      mdat: mdat,\n      traf: matchingTraf\n    });\n  });\n\n  mdatTrafPairs.forEach(function(pair) {\n    var mdat = pair.mdat;\n    var traf = pair.traf;\n    var tfhd = findBox(traf, ['tfhd']);\n    // Exactly 1 tfhd per traf\n    var headerInfo = parseTfhd(tfhd[0]);\n    var trackId = headerInfo.trackId;\n    var tfdt = findBox(traf, ['tfdt']);\n    // Either 0 or 1 tfdt per traf\n    var baseMediaDecodeTime = (tfdt.length > 0) ? parseTfdt(tfdt[0]).baseMediaDecodeTime : 0;\n    var truns = findBox(traf, ['trun']);\n    var samples;\n    var seiNals;\n\n    // Only parse video data for the chosen video track\n    if (videoTrackId === trackId && truns.length > 0) {\n      samples = parseSamples(truns, baseMediaDecodeTime, headerInfo);\n\n      seiNals = findSeiNals(mdat, samples, trackId);\n\n      if (!captionNals[trackId]) {\n        captionNals[trackId] = [];\n      }\n\n      captionNals[trackId] = captionNals[trackId].concat(seiNals);\n    }\n  });\n\n  return captionNals;\n};\n\n/**\n  * Parses out inband captions from an MP4 container and returns\n  * caption objects that can be used by WebVTT and the TextTrack API.\n  * @see https://developer.mozilla.org/en-US/docs/Web/API/VTTCue\n  * @see https://developer.mozilla.org/en-US/docs/Web/API/TextTrack\n  * Assumes that `probe.getVideoTrackIds` and `probe.timescale` have been called first\n  *\n  * @param {Uint8Array} segment - The fmp4 segment containing embedded captions\n  * @param {Number} trackId - The id of the video track to parse\n  * @param {Number} timescale - The timescale for the video track from the init segment\n  *\n  * @return {?Object[]} parsedCaptions - A list of captions or null if no video tracks\n  * @return {Number} parsedCaptions[].startTime - The time to show the caption in seconds\n  * @return {Number} parsedCaptions[].endTime - The time to stop showing the caption in seconds\n  * @return {String} parsedCaptions[].text - The visible content of the caption\n **/\nvar parseEmbeddedCaptions = function(segment, trackId, timescale) {\n  var seiNals;\n\n  // the ISO-BMFF spec says that trackId can't be zero, but there's some broken content out there\n  if (trackId === null) {\n    return null;\n  }\n\n  seiNals = parseCaptionNals(segment, trackId);\n\n  return {\n    seiNals: seiNals[trackId],\n    timescale: timescale\n  };\n};\n\n/**\n  * Converts SEI NALUs into captions that can be used by video.js\n **/\nvar CaptionParser = function() {\n  var isInitialized = false;\n  var captionStream;\n\n  // Stores segments seen before trackId and timescale are set\n  var segmentCache;\n  // Stores video track ID of the track being parsed\n  var trackId;\n  // Stores the timescale of the track being parsed\n  var timescale;\n  // Stores captions parsed so far\n  var parsedCaptions;\n  // Stores whether we are receiving partial data or not\n  var parsingPartial;\n\n  /**\n    * A method to indicate whether a CaptionParser has been initalized\n    * @returns {Boolean}\n   **/\n  this.isInitialized = function() {\n    return isInitialized;\n  };\n\n  /**\n    * Initializes the underlying CaptionStream, SEI NAL parsing\n    * and management, and caption collection\n   **/\n  this.init = function(options) {\n    captionStream = new CaptionStream();\n    isInitialized = true;\n    parsingPartial = options ? options.isPartial : false;\n\n    // Collect dispatched captions\n    captionStream.on('data', function(event) {\n      // Convert to seconds in the source's timescale\n      event.startTime = event.startPts / timescale;\n      event.endTime = event.endPts / timescale;\n\n      parsedCaptions.captions.push(event);\n      parsedCaptions.captionStreams[event.stream] = true;\n    });\n  };\n\n  /**\n    * Determines if a new video track will be selected\n    * or if the timescale changed\n    * @return {Boolean}\n   **/\n  this.isNewInit = function(videoTrackIds, timescales) {\n    if ((videoTrackIds && videoTrackIds.length === 0) ||\n        (timescales && typeof timescales === 'object' &&\n          Object.keys(timescales).length === 0)) {\n      return false;\n    }\n\n    return trackId !== videoTrackIds[0] ||\n      timescale !== timescales[trackId];\n  };\n\n  /**\n    * Parses out SEI captions and interacts with underlying\n    * CaptionStream to return dispatched captions\n    *\n    * @param {Uint8Array} segment - The fmp4 segment containing embedded captions\n    * @param {Number[]} videoTrackIds - A list of video tracks found in the init segment\n    * @param {Object.<Number, Number>} timescales - The timescales found in the init segment\n    * @see parseEmbeddedCaptions\n    * @see m2ts/caption-stream.js\n   **/\n  this.parse = function(segment, videoTrackIds, timescales) {\n    var parsedData;\n\n    if (!this.isInitialized()) {\n      return null;\n\n    // This is not likely to be a video segment\n    } else if (!videoTrackIds || !timescales) {\n      return null;\n\n    } else if (this.isNewInit(videoTrackIds, timescales)) {\n      // Use the first video track only as there is no\n      // mechanism to switch to other video tracks\n      trackId = videoTrackIds[0];\n      timescale = timescales[trackId];\n\n    // If an init segment has not been seen yet, hold onto segment\n    // data until we have one.\n    // the ISO-BMFF spec says that trackId can't be zero, but there's some broken content out there\n    } else if (trackId === null || !timescale) {\n      segmentCache.push(segment);\n      return null;\n    }\n\n    // Now that a timescale and trackId is set, parse cached segments\n    while (segmentCache.length > 0) {\n      var cachedSegment = segmentCache.shift();\n\n      this.parse(cachedSegment, videoTrackIds, timescales);\n    }\n\n    parsedData = parseEmbeddedCaptions(segment, trackId, timescale);\n\n    if (parsedData === null || !parsedData.seiNals) {\n      return null;\n    }\n\n    this.pushNals(parsedData.seiNals);\n    // Force the parsed captions to be dispatched\n    this.flushStream();\n\n    return parsedCaptions;\n  };\n\n  /**\n    * Pushes SEI NALUs onto CaptionStream\n    * @param {Object[]} nals - A list of SEI nals parsed using `parseCaptionNals`\n    * Assumes that `parseCaptionNals` has been called first\n    * @see m2ts/caption-stream.js\n    **/\n  this.pushNals = function(nals) {\n    if (!this.isInitialized() || !nals || nals.length === 0) {\n      return null;\n    }\n\n    nals.forEach(function(nal) {\n      captionStream.push(nal);\n    });\n  };\n\n  /**\n    * Flushes underlying CaptionStream to dispatch processed, displayable captions\n    * @see m2ts/caption-stream.js\n   **/\n  this.flushStream = function() {\n    if (!this.isInitialized()) {\n      return null;\n    }\n\n    if (!parsingPartial) {\n      captionStream.flush();\n    } else {\n      captionStream.partialFlush();\n    }\n  };\n\n  /**\n    * Reset caption buckets for new data\n   **/\n  this.clearParsedCaptions = function() {\n    parsedCaptions.captions = [];\n    parsedCaptions.captionStreams = {};\n  };\n\n  /**\n    * Resets underlying CaptionStream\n    * @see m2ts/caption-stream.js\n   **/\n  this.resetCaptionStream = function() {\n    if (!this.isInitialized()) {\n      return null;\n    }\n\n    captionStream.reset();\n  };\n\n  /**\n    * Convenience method to clear all captions flushed from the\n    * CaptionStream and still being parsed\n    * @see m2ts/caption-stream.js\n   **/\n  this.clearAllCaptions = function() {\n    this.clearParsedCaptions();\n    this.resetCaptionStream();\n  };\n\n  /**\n    * Reset caption parser\n   **/\n  this.reset = function() {\n    segmentCache = [];\n    trackId = null;\n    timescale = null;\n\n    if (!parsedCaptions) {\n      parsedCaptions = {\n        captions: [],\n        // CC1, CC2, CC3, CC4\n        captionStreams: {}\n      };\n    } else {\n      this.clearParsedCaptions();\n    }\n\n    this.resetCaptionStream();\n  };\n\n  this.reset();\n};\n\nmodule.exports = CaptionParser;\n",
    "var toUnsigned = require('../utils/bin').toUnsigned;\nvar parseType = require('./parse-type.js');\n\nvar findBox = function(data, path) {\n  var results = [],\n    i, size, type, end, subresults;\n\n  if (!path.length) {\n    // short-circuit the search for empty paths\n    return null;\n  }\n\n  for (i = 0; i < data.byteLength;) {\n    size = toUnsigned(data[i]     << 24 |\n      data[i + 1] << 16 |\n      data[i + 2] <<  8 |\n      data[i + 3]);\n\n    type = parseType(data.subarray(i + 4, i + 8));\n\n    end = size > 1 ? i + size : data.byteLength;\n\n    if (type === path[0]) {\n      if (path.length === 1) {\n        // this is the end of the path and we've found the box we were\n        // looking for\n        results.push(data.subarray(i + 8, end));\n      } else {\n        // recursively search for the next box along the path\n        subresults = findBox(data.subarray(i + 8, end), path.slice(1));\n        if (subresults.length) {\n          results = results.concat(subresults);\n        }\n      }\n    }\n    i = end;\n  }\n\n  // we've finished searching all of data\n  return results;\n};\n\nmodule.exports = findBox;\n\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\n// Convert an array of nal units into an array of frames with each frame being\n// composed of the nal units that make up that frame\n// Also keep track of cummulative data about the frame from the nal units such\n// as the frame duration, starting pts, etc.\nvar groupNalsIntoFrames = function(nalUnits) {\n  var\n    i,\n    currentNal,\n    currentFrame = [],\n    frames = [];\n\n  // TODO added for LHLS, make sure this is OK\n  frames.byteLength = 0;\n  frames.nalCount = 0;\n  frames.duration = 0;\n\n  currentFrame.byteLength = 0;\n\n  for (i = 0; i < nalUnits.length; i++) {\n    currentNal = nalUnits[i];\n\n    // Split on 'aud'-type nal units\n    if (currentNal.nalUnitType === 'access_unit_delimiter_rbsp') {\n      // Since the very first nal unit is expected to be an AUD\n      // only push to the frames array when currentFrame is not empty\n      if (currentFrame.length) {\n        currentFrame.duration = currentNal.dts - currentFrame.dts;\n        // TODO added for LHLS, make sure this is OK\n        frames.byteLength += currentFrame.byteLength;\n        frames.nalCount += currentFrame.length;\n        frames.duration += currentFrame.duration;\n        frames.push(currentFrame);\n      }\n      currentFrame = [currentNal];\n      currentFrame.byteLength = currentNal.data.byteLength;\n      currentFrame.pts = currentNal.pts;\n      currentFrame.dts = currentNal.dts;\n    } else {\n      // Specifically flag key frames for ease of use later\n      if (currentNal.nalUnitType === 'slice_layer_without_partitioning_rbsp_idr') {\n        currentFrame.keyFrame = true;\n      }\n      currentFrame.duration = currentNal.dts - currentFrame.dts;\n      currentFrame.byteLength += currentNal.data.byteLength;\n      currentFrame.push(currentNal);\n    }\n  }\n\n  // For the last frame, use the duration of the previous frame if we\n  // have nothing better to go on\n  if (frames.length &&\n      (!currentFrame.duration ||\n       currentFrame.duration <= 0)) {\n    currentFrame.duration = frames[frames.length - 1].duration;\n  }\n\n  // Push the final frame\n  // TODO added for LHLS, make sure this is OK\n  frames.byteLength += currentFrame.byteLength;\n  frames.nalCount += currentFrame.length;\n  frames.duration += currentFrame.duration;\n\n  frames.push(currentFrame);\n  return frames;\n};\n\n// Convert an array of frames into an array of Gop with each Gop being composed\n// of the frames that make up that Gop\n// Also keep track of cummulative data about the Gop from the frames such as the\n// Gop duration, starting pts, etc.\nvar groupFramesIntoGops = function(frames) {\n  var\n    i,\n    currentFrame,\n    currentGop = [],\n    gops = [];\n\n  // We must pre-set some of the values on the Gop since we\n  // keep running totals of these values\n  currentGop.byteLength = 0;\n  currentGop.nalCount = 0;\n  currentGop.duration = 0;\n  currentGop.pts = frames[0].pts;\n  currentGop.dts = frames[0].dts;\n\n  // store some metadata about all the Gops\n  gops.byteLength = 0;\n  gops.nalCount = 0;\n  gops.duration = 0;\n  gops.pts = frames[0].pts;\n  gops.dts = frames[0].dts;\n\n  for (i = 0; i < frames.length; i++) {\n    currentFrame = frames[i];\n\n    if (currentFrame.keyFrame) {\n      // Since the very first frame is expected to be an keyframe\n      // only push to the gops array when currentGop is not empty\n      if (currentGop.length) {\n        gops.push(currentGop);\n        gops.byteLength += currentGop.byteLength;\n        gops.nalCount += currentGop.nalCount;\n        gops.duration += currentGop.duration;\n      }\n\n      currentGop = [currentFrame];\n      currentGop.nalCount = currentFrame.length;\n      currentGop.byteLength = currentFrame.byteLength;\n      currentGop.pts = currentFrame.pts;\n      currentGop.dts = currentFrame.dts;\n      currentGop.duration = currentFrame.duration;\n    } else {\n      currentGop.duration += currentFrame.duration;\n      currentGop.nalCount += currentFrame.length;\n      currentGop.byteLength += currentFrame.byteLength;\n      currentGop.push(currentFrame);\n    }\n  }\n\n  if (gops.length && currentGop.duration <= 0) {\n    currentGop.duration = gops[gops.length - 1].duration;\n  }\n  gops.byteLength += currentGop.byteLength;\n  gops.nalCount += currentGop.nalCount;\n  gops.duration += currentGop.duration;\n\n  // push the final Gop\n  gops.push(currentGop);\n  return gops;\n};\n\n/*\n * Search for the first keyframe in the GOPs and throw away all frames\n * until that keyframe. Then extend the duration of the pulled keyframe\n * and pull the PTS and DTS of the keyframe so that it covers the time\n * range of the frames that were disposed.\n *\n * @param {Array} gops video GOPs\n * @returns {Array} modified video GOPs\n */\nvar extendFirstKeyFrame = function(gops) {\n  var currentGop;\n\n  if (!gops[0][0].keyFrame && gops.length > 1) {\n    // Remove the first GOP\n    currentGop = gops.shift();\n\n    gops.byteLength -= currentGop.byteLength;\n    gops.nalCount -= currentGop.nalCount;\n\n    // Extend the first frame of what is now the\n    // first gop to cover the time period of the\n    // frames we just removed\n    gops[0][0].dts = currentGop.dts;\n    gops[0][0].pts = currentGop.pts;\n    gops[0][0].duration += currentGop.duration;\n  }\n\n  return gops;\n};\n\n/**\n * Default sample object\n * see ISO/IEC 14496-12:2012, section 8.6.4.3\n */\nvar createDefaultSample = function() {\n  return {\n    size: 0,\n    flags: {\n      isLeading: 0,\n      dependsOn: 1,\n      isDependedOn: 0,\n      hasRedundancy: 0,\n      degradationPriority: 0,\n      isNonSyncSample: 1\n    }\n  };\n};\n\n/*\n * Collates information from a video frame into an object for eventual\n * entry into an MP4 sample table.\n *\n * @param {Object} frame the video frame\n * @param {Number} dataOffset the byte offset to position the sample\n * @return {Object} object containing sample table info for a frame\n */\nvar sampleForFrame = function(frame, dataOffset) {\n  var sample = createDefaultSample();\n\n  sample.dataOffset = dataOffset;\n  sample.compositionTimeOffset = frame.pts - frame.dts;\n  sample.duration = frame.duration;\n  sample.size = 4 * frame.length; // Space for nal unit size\n  sample.size += frame.byteLength;\n\n  if (frame.keyFrame) {\n    sample.flags.dependsOn = 2;\n    sample.flags.isNonSyncSample = 0;\n  }\n\n  return sample;\n};\n\n// generate the track's sample table from an array of gops\nvar generateSampleTable = function(gops, baseDataOffset) {\n  var\n    h, i,\n    sample,\n    currentGop,\n    currentFrame,\n    dataOffset = baseDataOffset || 0,\n    samples = [];\n\n  for (h = 0; h < gops.length; h++) {\n    currentGop = gops[h];\n\n    for (i = 0; i < currentGop.length; i++) {\n      currentFrame = currentGop[i];\n\n      sample = sampleForFrame(currentFrame, dataOffset);\n\n      dataOffset += sample.size;\n\n      samples.push(sample);\n    }\n  }\n  return samples;\n};\n\n// generate the track's raw mdat data from an array of gops\nvar concatenateNalData = function(gops) {\n  var\n    h, i, j,\n    currentGop,\n    currentFrame,\n    currentNal,\n    dataOffset = 0,\n    nalsByteLength = gops.byteLength,\n    numberOfNals = gops.nalCount,\n    totalByteLength = nalsByteLength + 4 * numberOfNals,\n    data = new Uint8Array(totalByteLength),\n    view = new DataView(data.buffer);\n\n  // For each Gop..\n  for (h = 0; h < gops.length; h++) {\n    currentGop = gops[h];\n\n    // For each Frame..\n    for (i = 0; i < currentGop.length; i++) {\n      currentFrame = currentGop[i];\n\n      // For each NAL..\n      for (j = 0; j < currentFrame.length; j++) {\n        currentNal = currentFrame[j];\n\n        view.setUint32(dataOffset, currentNal.data.byteLength);\n        dataOffset += 4;\n        data.set(currentNal.data, dataOffset);\n        dataOffset += currentNal.data.byteLength;\n      }\n    }\n  }\n  return data;\n};\n\n// generate the track's sample table from a frame\nvar generateSampleTableForFrame = function(frame, baseDataOffset) {\n  var\n    sample,\n    dataOffset = baseDataOffset || 0,\n    samples = [];\n\n  sample = sampleForFrame(frame, dataOffset);\n  samples.push(sample);\n\n  return samples;\n};\n\n// generate the track's raw mdat data from a frame\nvar concatenateNalDataForFrame = function(frame) {\n  var\n    i,\n    currentNal,\n    dataOffset = 0,\n    nalsByteLength = frame.byteLength,\n    numberOfNals = frame.length,\n    totalByteLength = nalsByteLength + 4 * numberOfNals,\n    data = new Uint8Array(totalByteLength),\n    view = new DataView(data.buffer);\n\n  // For each NAL..\n  for (i = 0; i < frame.length; i++) {\n    currentNal = frame[i];\n\n    view.setUint32(dataOffset, currentNal.data.byteLength);\n    dataOffset += 4;\n    data.set(currentNal.data, dataOffset);\n    dataOffset += currentNal.data.byteLength;\n  }\n\n  return data;\n};\n\nmodule.exports = {\n  groupNalsIntoFrames: groupNalsIntoFrames,\n  groupFramesIntoGops: groupFramesIntoGops,\n  extendFirstKeyFrame: extendFirstKeyFrame,\n  generateSampleTable: generateSampleTable,\n  concatenateNalData: concatenateNalData,\n  generateSampleTableForFrame: generateSampleTableForFrame,\n  concatenateNalDataForFrame: concatenateNalDataForFrame\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\nmodule.exports = {\n  generator: require('./mp4-generator'),\n  probe: require('./probe'),\n  Transmuxer: require('./transmuxer').Transmuxer,\n  AudioSegmentStream: require('./transmuxer').AudioSegmentStream,\n  VideoSegmentStream: require('./transmuxer').VideoSegmentStream,\n  CaptionParser: require('./caption-parser')\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * Functions that generate fragmented MP4s suitable for use with Media\n * Source Extensions.\n */\n'use strict';\n\nvar UINT32_MAX = Math.pow(2, 32) - 1;\n\nvar box, dinf, esds, ftyp, mdat, mfhd, minf, moof, moov, mvex, mvhd,\n    trak, tkhd, mdia, mdhd, hdlr, sdtp, stbl, stsd, traf, trex,\n    trun, types, MAJOR_BRAND, MINOR_VERSION, AVC1_BRAND, VIDEO_HDLR,\n    AUDIO_HDLR, HDLR_TYPES, VMHD, SMHD, DREF, STCO, STSC, STSZ, STTS;\n\n// pre-calculate constants\n(function() {\n  var i;\n  types = {\n    avc1: [], // codingname\n    avcC: [],\n    btrt: [],\n    dinf: [],\n    dref: [],\n    esds: [],\n    ftyp: [],\n    hdlr: [],\n    mdat: [],\n    mdhd: [],\n    mdia: [],\n    mfhd: [],\n    minf: [],\n    moof: [],\n    moov: [],\n    mp4a: [], // codingname\n    mvex: [],\n    mvhd: [],\n    pasp: [],\n    sdtp: [],\n    smhd: [],\n    stbl: [],\n    stco: [],\n    stsc: [],\n    stsd: [],\n    stsz: [],\n    stts: [],\n    styp: [],\n    tfdt: [],\n    tfhd: [],\n    traf: [],\n    trak: [],\n    trun: [],\n    trex: [],\n    tkhd: [],\n    vmhd: []\n  };\n\n  // In environments where Uint8Array is undefined (e.g., IE8), skip set up so that we\n  // don't throw an error\n  if (typeof Uint8Array === 'undefined') {\n    return;\n  }\n\n  for (i in types) {\n    if (types.hasOwnProperty(i)) {\n      types[i] = [\n        i.charCodeAt(0),\n        i.charCodeAt(1),\n        i.charCodeAt(2),\n        i.charCodeAt(3)\n      ];\n    }\n  }\n\n  MAJOR_BRAND = new Uint8Array([\n    'i'.charCodeAt(0),\n    's'.charCodeAt(0),\n    'o'.charCodeAt(0),\n    'm'.charCodeAt(0)\n  ]);\n  AVC1_BRAND = new Uint8Array([\n    'a'.charCodeAt(0),\n    'v'.charCodeAt(0),\n    'c'.charCodeAt(0),\n    '1'.charCodeAt(0)\n  ]);\n  MINOR_VERSION = new Uint8Array([0, 0, 0, 1]);\n  VIDEO_HDLR = new Uint8Array([\n    0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00, // pre_defined\n    0x76, 0x69, 0x64, 0x65, // handler_type: 'vide'\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x56, 0x69, 0x64, 0x65,\n    0x6f, 0x48, 0x61, 0x6e,\n    0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'VideoHandler'\n  ]);\n  AUDIO_HDLR = new Uint8Array([\n    0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00, // pre_defined\n    0x73, 0x6f, 0x75, 0x6e, // handler_type: 'soun'\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x53, 0x6f, 0x75, 0x6e,\n    0x64, 0x48, 0x61, 0x6e,\n    0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'SoundHandler'\n  ]);\n  HDLR_TYPES = {\n    video: VIDEO_HDLR,\n    audio: AUDIO_HDLR\n  };\n  DREF = new Uint8Array([\n    0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x01, // entry_count\n    0x00, 0x00, 0x00, 0x0c, // entry_size\n    0x75, 0x72, 0x6c, 0x20, // 'url' type\n    0x00, // version 0\n    0x00, 0x00, 0x01 // entry_flags\n  ]);\n  SMHD = new Uint8Array([\n    0x00,             // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00,       // balance, 0 means centered\n    0x00, 0x00        // reserved\n  ]);\n  STCO = new Uint8Array([\n    0x00, // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00 // entry_count\n  ]);\n  STSC = STCO;\n  STSZ = new Uint8Array([\n    0x00, // version\n    0x00, 0x00, 0x00, // flags\n    0x00, 0x00, 0x00, 0x00, // sample_size\n    0x00, 0x00, 0x00, 0x00 // sample_count\n  ]);\n  STTS = STCO;\n  VMHD = new Uint8Array([\n    0x00, // version\n    0x00, 0x00, 0x01, // flags\n    0x00, 0x00, // graphicsmode\n    0x00, 0x00,\n    0x00, 0x00,\n    0x00, 0x00 // opcolor\n  ]);\n}());\n\nbox = function(type) {\n  var\n    payload = [],\n    size = 0,\n    i,\n    result,\n    view;\n\n  for (i = 1; i < arguments.length; i++) {\n    payload.push(arguments[i]);\n  }\n\n  i = payload.length;\n\n  // calculate the total size we need to allocate\n  while (i--) {\n    size += payload[i].byteLength;\n  }\n  result = new Uint8Array(size + 8);\n  view = new DataView(result.buffer, result.byteOffset, result.byteLength);\n  view.setUint32(0, result.byteLength);\n  result.set(type, 4);\n\n  // copy the payload into the result\n  for (i = 0, size = 8; i < payload.length; i++) {\n    result.set(payload[i], size);\n    size += payload[i].byteLength;\n  }\n  return result;\n};\n\ndinf = function() {\n  return box(types.dinf, box(types.dref, DREF));\n};\n\nesds = function(track) {\n  return box(types.esds, new Uint8Array([\n    0x00, // version\n    0x00, 0x00, 0x00, // flags\n\n    // ES_Descriptor\n    0x03, // tag, ES_DescrTag\n    0x19, // length\n    0x00, 0x00, // ES_ID\n    0x00, // streamDependenceFlag, URL_flag, reserved, streamPriority\n\n    // DecoderConfigDescriptor\n    0x04, // tag, DecoderConfigDescrTag\n    0x11, // length\n    0x40, // object type\n    0x15,  // streamType\n    0x00, 0x06, 0x00, // bufferSizeDB\n    0x00, 0x00, 0xda, 0xc0, // maxBitrate\n    0x00, 0x00, 0xda, 0xc0, // avgBitrate\n\n    // DecoderSpecificInfo\n    0x05, // tag, DecoderSpecificInfoTag\n    0x02, // length\n    // ISO/IEC 14496-3, AudioSpecificConfig\n    // for samplingFrequencyIndex see ISO/IEC 13818-7:2006, 8.1.3.2.2, Table 35\n    (track.audioobjecttype << 3) | (track.samplingfrequencyindex >>> 1),\n    (track.samplingfrequencyindex << 7) | (track.channelcount << 3),\n    0x06, 0x01, 0x02 // GASpecificConfig\n  ]));\n};\n\nftyp = function() {\n  return box(types.ftyp, MAJOR_BRAND, MINOR_VERSION, MAJOR_BRAND, AVC1_BRAND);\n};\n\nhdlr = function(type) {\n  return box(types.hdlr, HDLR_TYPES[type]);\n};\nmdat = function(data) {\n  return box(types.mdat, data);\n};\nmdhd = function(track) {\n  var result = new Uint8Array([\n    0x00,                   // version 0\n    0x00, 0x00, 0x00,       // flags\n    0x00, 0x00, 0x00, 0x02, // creation_time\n    0x00, 0x00, 0x00, 0x03, // modification_time\n    0x00, 0x01, 0x5f, 0x90, // timescale, 90,000 \"ticks\" per second\n\n    (track.duration >>> 24) & 0xFF,\n    (track.duration >>> 16) & 0xFF,\n    (track.duration >>>  8) & 0xFF,\n    track.duration & 0xFF,  // duration\n    0x55, 0xc4,             // 'und' language (undetermined)\n    0x00, 0x00\n  ]);\n\n  // Use the sample rate from the track metadata, when it is\n  // defined. The sample rate can be parsed out of an ADTS header, for\n  // instance.\n  if (track.samplerate) {\n    result[12] = (track.samplerate >>> 24) & 0xFF;\n    result[13] = (track.samplerate >>> 16) & 0xFF;\n    result[14] = (track.samplerate >>>  8) & 0xFF;\n    result[15] = (track.samplerate)        & 0xFF;\n  }\n\n  return box(types.mdhd, result);\n};\nmdia = function(track) {\n  return box(types.mdia, mdhd(track), hdlr(track.type), minf(track));\n};\nmfhd = function(sequenceNumber) {\n  return box(types.mfhd, new Uint8Array([\n    0x00,\n    0x00, 0x00, 0x00, // flags\n    (sequenceNumber & 0xFF000000) >> 24,\n    (sequenceNumber & 0xFF0000) >> 16,\n    (sequenceNumber & 0xFF00) >> 8,\n    sequenceNumber & 0xFF // sequence_number\n  ]));\n};\nminf = function(track) {\n  return box(types.minf,\n             track.type === 'video' ? box(types.vmhd, VMHD) : box(types.smhd, SMHD),\n             dinf(),\n             stbl(track));\n};\nmoof = function(sequenceNumber, tracks) {\n  var\n    trackFragments = [],\n    i = tracks.length;\n  // build traf boxes for each track fragment\n  while (i--) {\n    trackFragments[i] = traf(tracks[i]);\n  }\n  return box.apply(null, [\n    types.moof,\n    mfhd(sequenceNumber)\n  ].concat(trackFragments));\n};\n/**\n * Returns a movie box.\n * @param tracks {array} the tracks associated with this movie\n * @see ISO/IEC 14496-12:2012(E), section 8.2.1\n */\nmoov = function(tracks) {\n  var\n    i = tracks.length,\n    boxes = [];\n\n  while (i--) {\n    boxes[i] = trak(tracks[i]);\n  }\n\n  return box.apply(null, [types.moov, mvhd(0xffffffff)].concat(boxes).concat(mvex(tracks)));\n};\nmvex = function(tracks) {\n  var\n    i = tracks.length,\n    boxes = [];\n\n  while (i--) {\n    boxes[i] = trex(tracks[i]);\n  }\n  return box.apply(null, [types.mvex].concat(boxes));\n};\nmvhd = function(duration) {\n  var\n    bytes = new Uint8Array([\n      0x00, // version 0\n      0x00, 0x00, 0x00, // flags\n      0x00, 0x00, 0x00, 0x01, // creation_time\n      0x00, 0x00, 0x00, 0x02, // modification_time\n      0x00, 0x01, 0x5f, 0x90, // timescale, 90,000 \"ticks\" per second\n      (duration & 0xFF000000) >> 24,\n      (duration & 0xFF0000) >> 16,\n      (duration & 0xFF00) >> 8,\n      duration & 0xFF, // duration\n      0x00, 0x01, 0x00, 0x00, // 1.0 rate\n      0x01, 0x00, // 1.0 volume\n      0x00, 0x00, // reserved\n      0x00, 0x00, 0x00, 0x00, // reserved\n      0x00, 0x00, 0x00, 0x00, // reserved\n      0x00, 0x01, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x01, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x40, 0x00, 0x00, 0x00, // transformation: unity matrix\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, 0x00, // pre_defined\n      0xff, 0xff, 0xff, 0xff // next_track_ID\n    ]);\n  return box(types.mvhd, bytes);\n};\n\nsdtp = function(track) {\n  var\n    samples = track.samples || [],\n    bytes = new Uint8Array(4 + samples.length),\n    flags,\n    i;\n\n  // leave the full box header (4 bytes) all zero\n\n  // write the sample table\n  for (i = 0; i < samples.length; i++) {\n    flags = samples[i].flags;\n\n    bytes[i + 4] = (flags.dependsOn << 4) |\n      (flags.isDependedOn << 2) |\n      (flags.hasRedundancy);\n  }\n\n  return box(types.sdtp,\n             bytes);\n};\n\nstbl = function(track) {\n  return box(types.stbl,\n             stsd(track),\n             box(types.stts, STTS),\n             box(types.stsc, STSC),\n             box(types.stsz, STSZ),\n             box(types.stco, STCO));\n};\n\n(function() {\n  var videoSample, audioSample;\n\n  stsd = function(track) {\n\n    return box(types.stsd, new Uint8Array([\n      0x00, // version 0\n      0x00, 0x00, 0x00, // flags\n      0x00, 0x00, 0x00, 0x01\n    ]), track.type === 'video' ? videoSample(track) : audioSample(track));\n  };\n\n  videoSample = function(track) {\n    var\n      sps = track.sps || [],\n      pps = track.pps || [],\n      sequenceParameterSets = [],\n      pictureParameterSets = [],\n      i,\n      avc1Box;\n\n    // assemble the SPSs\n    for (i = 0; i < sps.length; i++) {\n      sequenceParameterSets.push((sps[i].byteLength & 0xFF00) >>> 8);\n      sequenceParameterSets.push((sps[i].byteLength & 0xFF)); // sequenceParameterSetLength\n      sequenceParameterSets = sequenceParameterSets.concat(Array.prototype.slice.call(sps[i])); // SPS\n    }\n\n    // assemble the PPSs\n    for (i = 0; i < pps.length; i++) {\n      pictureParameterSets.push((pps[i].byteLength & 0xFF00) >>> 8);\n      pictureParameterSets.push((pps[i].byteLength & 0xFF));\n      pictureParameterSets = pictureParameterSets.concat(Array.prototype.slice.call(pps[i]));\n    }\n\n    avc1Box = [\n      types.avc1, new Uint8Array([\n        0x00, 0x00, 0x00,\n        0x00, 0x00, 0x00, // reserved\n        0x00, 0x01, // data_reference_index\n        0x00, 0x00, // pre_defined\n        0x00, 0x00, // reserved\n        0x00, 0x00, 0x00, 0x00,\n        0x00, 0x00, 0x00, 0x00,\n        0x00, 0x00, 0x00, 0x00, // pre_defined\n        (track.width & 0xff00) >> 8,\n        track.width & 0xff, // width\n        (track.height & 0xff00) >> 8,\n        track.height & 0xff, // height\n        0x00, 0x48, 0x00, 0x00, // horizresolution\n        0x00, 0x48, 0x00, 0x00, // vertresolution\n        0x00, 0x00, 0x00, 0x00, // reserved\n        0x00, 0x01, // frame_count\n        0x13,\n        0x76, 0x69, 0x64, 0x65,\n        0x6f, 0x6a, 0x73, 0x2d,\n        0x63, 0x6f, 0x6e, 0x74,\n        0x72, 0x69, 0x62, 0x2d,\n        0x68, 0x6c, 0x73, 0x00,\n        0x00, 0x00, 0x00, 0x00,\n        0x00, 0x00, 0x00, 0x00,\n        0x00, 0x00, 0x00, // compressorname\n        0x00, 0x18, // depth = 24\n        0x11, 0x11 // pre_defined = -1\n      ]),\n      box(types.avcC, new Uint8Array([\n        0x01, // configurationVersion\n        track.profileIdc, // AVCProfileIndication\n        track.profileCompatibility, // profile_compatibility\n        track.levelIdc, // AVCLevelIndication\n        0xff // lengthSizeMinusOne, hard-coded to 4 bytes\n      ].concat(\n        [sps.length], // numOfSequenceParameterSets\n        sequenceParameterSets, // \"SPS\"\n        [pps.length], // numOfPictureParameterSets\n        pictureParameterSets // \"PPS\"\n      ))),\n      box(types.btrt, new Uint8Array([\n        0x00, 0x1c, 0x9c, 0x80, // bufferSizeDB\n        0x00, 0x2d, 0xc6, 0xc0, // maxBitrate\n        0x00, 0x2d, 0xc6, 0xc0 // avgBitrate\n      ]))\n    ];\n\n    if (track.sarRatio) {\n      var\n        hSpacing = track.sarRatio[0],\n        vSpacing = track.sarRatio[1];\n\n        avc1Box.push(\n          box(types.pasp, new Uint8Array([\n            (hSpacing & 0xFF000000) >> 24,\n            (hSpacing & 0xFF0000) >> 16,\n            (hSpacing & 0xFF00) >> 8,\n            hSpacing & 0xFF,\n            (vSpacing & 0xFF000000) >> 24,\n            (vSpacing & 0xFF0000) >> 16,\n            (vSpacing & 0xFF00) >> 8,\n            vSpacing & 0xFF\n          ]))\n        );\n    }\n\n    return box.apply(null, avc1Box);\n  };\n\n  audioSample = function(track) {\n    return box(types.mp4a, new Uint8Array([\n\n      // SampleEntry, ISO/IEC 14496-12\n      0x00, 0x00, 0x00,\n      0x00, 0x00, 0x00, // reserved\n      0x00, 0x01, // data_reference_index\n\n      // AudioSampleEntry, ISO/IEC 14496-12\n      0x00, 0x00, 0x00, 0x00, // reserved\n      0x00, 0x00, 0x00, 0x00, // reserved\n      (track.channelcount & 0xff00) >> 8,\n      (track.channelcount & 0xff), // channelcount\n\n      (track.samplesize & 0xff00) >> 8,\n      (track.samplesize & 0xff), // samplesize\n      0x00, 0x00, // pre_defined\n      0x00, 0x00, // reserved\n\n      (track.samplerate & 0xff00) >> 8,\n      (track.samplerate & 0xff),\n      0x00, 0x00 // samplerate, 16.16\n\n      // MP4AudioSampleEntry, ISO/IEC 14496-14\n    ]), esds(track));\n  };\n}());\n\ntkhd = function(track) {\n  var result = new Uint8Array([\n    0x00, // version 0\n    0x00, 0x00, 0x07, // flags\n    0x00, 0x00, 0x00, 0x00, // creation_time\n    0x00, 0x00, 0x00, 0x00, // modification_time\n    (track.id & 0xFF000000) >> 24,\n    (track.id & 0xFF0000) >> 16,\n    (track.id & 0xFF00) >> 8,\n    track.id & 0xFF, // track_ID\n    0x00, 0x00, 0x00, 0x00, // reserved\n    (track.duration & 0xFF000000) >> 24,\n    (track.duration & 0xFF0000) >> 16,\n    (track.duration & 0xFF00) >> 8,\n    track.duration & 0xFF, // duration\n    0x00, 0x00, 0x00, 0x00,\n    0x00, 0x00, 0x00, 0x00, // reserved\n    0x00, 0x00, // layer\n    0x00, 0x00, // alternate_group\n    0x01, 0x00, // non-audio track volume\n    0x00, 0x00, // reserved\n    0x00, 0x01, 0x00, 0x00,\n    0x00, 0x00, 0x00, 0x00,\n    0x00, 0x00, 0x00, 0x00,\n    0x00, 0x00, 0x00, 0x00,\n    0x00, 0x01, 0x00, 0x00,\n    0x00, 0x00, 0x00, 0x00,\n    0x00, 0x00, 0x00, 0x00,\n    0x00, 0x00, 0x00, 0x00,\n    0x40, 0x00, 0x00, 0x00, // transformation: unity matrix\n    (track.width & 0xFF00) >> 8,\n    track.width & 0xFF,\n    0x00, 0x00, // width\n    (track.height & 0xFF00) >> 8,\n    track.height & 0xFF,\n    0x00, 0x00 // height\n  ]);\n\n  return box(types.tkhd, result);\n};\n\n/**\n * Generate a track fragment (traf) box. A traf box collects metadata\n * about tracks in a movie fragment (moof) box.\n */\ntraf = function(track) {\n  var trackFragmentHeader, trackFragmentDecodeTime, trackFragmentRun,\n      sampleDependencyTable, dataOffset,\n      upperWordBaseMediaDecodeTime, lowerWordBaseMediaDecodeTime;\n\n  trackFragmentHeader = box(types.tfhd, new Uint8Array([\n    0x00, // version 0\n    0x00, 0x00, 0x3a, // flags\n    (track.id & 0xFF000000) >> 24,\n    (track.id & 0xFF0000) >> 16,\n    (track.id & 0xFF00) >> 8,\n    (track.id & 0xFF), // track_ID\n    0x00, 0x00, 0x00, 0x01, // sample_description_index\n    0x00, 0x00, 0x00, 0x00, // default_sample_duration\n    0x00, 0x00, 0x00, 0x00, // default_sample_size\n    0x00, 0x00, 0x00, 0x00  // default_sample_flags\n  ]));\n\n  upperWordBaseMediaDecodeTime = Math.floor(track.baseMediaDecodeTime / (UINT32_MAX + 1));\n  lowerWordBaseMediaDecodeTime = Math.floor(track.baseMediaDecodeTime % (UINT32_MAX + 1));\n\n  trackFragmentDecodeTime = box(types.tfdt, new Uint8Array([\n    0x01, // version 1\n    0x00, 0x00, 0x00, // flags\n    // baseMediaDecodeTime\n    (upperWordBaseMediaDecodeTime >>> 24) & 0xFF,\n    (upperWordBaseMediaDecodeTime >>> 16) & 0xFF,\n    (upperWordBaseMediaDecodeTime >>>  8) & 0xFF,\n    upperWordBaseMediaDecodeTime & 0xFF,\n    (lowerWordBaseMediaDecodeTime >>> 24) & 0xFF,\n    (lowerWordBaseMediaDecodeTime >>> 16) & 0xFF,\n    (lowerWordBaseMediaDecodeTime >>>  8) & 0xFF,\n    lowerWordBaseMediaDecodeTime & 0xFF\n  ]));\n\n  // the data offset specifies the number of bytes from the start of\n  // the containing moof to the first payload byte of the associated\n  // mdat\n  dataOffset = (32 + // tfhd\n                20 + // tfdt\n                8 +  // traf header\n                16 + // mfhd\n                8 +  // moof header\n                8);  // mdat header\n\n  // audio tracks require less metadata\n  if (track.type === 'audio') {\n    trackFragmentRun = trun(track, dataOffset);\n    return box(types.traf,\n               trackFragmentHeader,\n               trackFragmentDecodeTime,\n               trackFragmentRun);\n  }\n\n  // video tracks should contain an independent and disposable samples\n  // box (sdtp)\n  // generate one and adjust offsets to match\n  sampleDependencyTable = sdtp(track);\n  trackFragmentRun = trun(track,\n                          sampleDependencyTable.length + dataOffset);\n  return box(types.traf,\n             trackFragmentHeader,\n             trackFragmentDecodeTime,\n             trackFragmentRun,\n             sampleDependencyTable);\n};\n\n/**\n * Generate a track box.\n * @param track {object} a track definition\n * @return {Uint8Array} the track box\n */\ntrak = function(track) {\n  track.duration = track.duration || 0xffffffff;\n  return box(types.trak,\n             tkhd(track),\n             mdia(track));\n};\n\ntrex = function(track) {\n  var result = new Uint8Array([\n    0x00, // version 0\n    0x00, 0x00, 0x00, // flags\n    (track.id & 0xFF000000) >> 24,\n    (track.id & 0xFF0000) >> 16,\n    (track.id & 0xFF00) >> 8,\n    (track.id & 0xFF), // track_ID\n    0x00, 0x00, 0x00, 0x01, // default_sample_description_index\n    0x00, 0x00, 0x00, 0x00, // default_sample_duration\n    0x00, 0x00, 0x00, 0x00, // default_sample_size\n    0x00, 0x01, 0x00, 0x01 // default_sample_flags\n  ]);\n  // the last two bytes of default_sample_flags is the sample\n  // degradation priority, a hint about the importance of this sample\n  // relative to others. Lower the degradation priority for all sample\n  // types other than video.\n  if (track.type !== 'video') {\n    result[result.length - 1] = 0x00;\n  }\n\n  return box(types.trex, result);\n};\n\n(function() {\n  var audioTrun, videoTrun, trunHeader;\n\n  // This method assumes all samples are uniform. That is, if a\n  // duration is present for the first sample, it will be present for\n  // all subsequent samples.\n  // see ISO/IEC 14496-12:2012, Section 8.8.8.1\n  trunHeader = function(samples, offset) {\n    var durationPresent = 0, sizePresent = 0,\n        flagsPresent = 0, compositionTimeOffset = 0;\n\n    // trun flag constants\n    if (samples.length) {\n      if (samples[0].duration !== undefined) {\n        durationPresent = 0x1;\n      }\n      if (samples[0].size !== undefined) {\n        sizePresent = 0x2;\n      }\n      if (samples[0].flags !== undefined) {\n        flagsPresent = 0x4;\n      }\n      if (samples[0].compositionTimeOffset !== undefined) {\n        compositionTimeOffset = 0x8;\n      }\n    }\n\n    return [\n      0x00, // version 0\n      0x00,\n      durationPresent | sizePresent | flagsPresent | compositionTimeOffset,\n      0x01, // flags\n      (samples.length & 0xFF000000) >>> 24,\n      (samples.length & 0xFF0000) >>> 16,\n      (samples.length & 0xFF00) >>> 8,\n      samples.length & 0xFF, // sample_count\n      (offset & 0xFF000000) >>> 24,\n      (offset & 0xFF0000) >>> 16,\n      (offset & 0xFF00) >>> 8,\n      offset & 0xFF // data_offset\n    ];\n  };\n\n  videoTrun = function(track, offset) {\n    var bytesOffest, bytes, header, samples, sample, i;\n\n    samples = track.samples || [];\n    offset += 8 + 12 + (16 * samples.length);\n    header = trunHeader(samples, offset);\n    bytes = new Uint8Array(header.length + samples.length * 16);\n    bytes.set(header);\n    bytesOffest = header.length;\n\n    for (i = 0; i < samples.length; i++) {\n      sample = samples[i];\n\n      bytes[bytesOffest++] = (sample.duration & 0xFF000000) >>> 24;\n      bytes[bytesOffest++] = (sample.duration & 0xFF0000) >>> 16;\n      bytes[bytesOffest++] = (sample.duration & 0xFF00) >>> 8;\n      bytes[bytesOffest++] = sample.duration & 0xFF; // sample_duration\n      bytes[bytesOffest++] = (sample.size & 0xFF000000) >>> 24;\n      bytes[bytesOffest++] = (sample.size & 0xFF0000) >>> 16;\n      bytes[bytesOffest++] = (sample.size & 0xFF00) >>> 8;\n      bytes[bytesOffest++] = sample.size & 0xFF; // sample_size\n      bytes[bytesOffest++] = (sample.flags.isLeading << 2) | sample.flags.dependsOn;\n      bytes[bytesOffest++] = (sample.flags.isDependedOn << 6) |\n          (sample.flags.hasRedundancy << 4) |\n          (sample.flags.paddingValue << 1) |\n          sample.flags.isNonSyncSample;\n      bytes[bytesOffest++] = sample.flags.degradationPriority & 0xF0 << 8;\n      bytes[bytesOffest++] = sample.flags.degradationPriority & 0x0F; // sample_flags\n      bytes[bytesOffest++] = (sample.compositionTimeOffset & 0xFF000000) >>> 24;\n      bytes[bytesOffest++] = (sample.compositionTimeOffset & 0xFF0000) >>> 16;\n      bytes[bytesOffest++] = (sample.compositionTimeOffset & 0xFF00) >>> 8;\n      bytes[bytesOffest++] = sample.compositionTimeOffset & 0xFF; // sample_composition_time_offset\n    }\n    return box(types.trun, bytes);\n  };\n\n  audioTrun = function(track, offset) {\n    var bytes, bytesOffest, header, samples, sample, i;\n\n    samples = track.samples || [];\n    offset += 8 + 12 + (8 * samples.length);\n\n    header = trunHeader(samples, offset);\n    bytes = new Uint8Array(header.length + samples.length * 8);\n    bytes.set(header);\n    bytesOffest = header.length;\n\n    for (i = 0; i < samples.length; i++) {\n      sample = samples[i];\n      bytes[bytesOffest++] = (sample.duration & 0xFF000000) >>> 24;\n      bytes[bytesOffest++] = (sample.duration & 0xFF0000) >>> 16;\n      bytes[bytesOffest++] = (sample.duration & 0xFF00) >>> 8;\n      bytes[bytesOffest++] = sample.duration & 0xFF; // sample_duration\n      bytes[bytesOffest++] = (sample.size & 0xFF000000) >>> 24;\n      bytes[bytesOffest++] = (sample.size & 0xFF0000) >>> 16;\n      bytes[bytesOffest++] = (sample.size & 0xFF00) >>> 8;\n      bytes[bytesOffest++] = sample.size & 0xFF; // sample_size\n    }\n\n    return box(types.trun, bytes);\n  };\n\n  trun = function(track, offset) {\n    if (track.type === 'audio') {\n      return audioTrun(track, offset);\n    }\n\n    return videoTrun(track, offset);\n  };\n}());\n\nmodule.exports = {\n  ftyp: ftyp,\n  mdat: mdat,\n  moof: moof,\n  moov: moov,\n  initSegment: function(tracks) {\n    var\n      fileType = ftyp(),\n      movie = moov(tracks),\n      result;\n\n    result = new Uint8Array(fileType.byteLength + movie.byteLength);\n    result.set(fileType);\n    result.set(movie, fileType.byteLength);\n    return result;\n  }\n};\n",
    "var parseType = function(buffer) {\n  var result = '';\n  result += String.fromCharCode(buffer[0]);\n  result += String.fromCharCode(buffer[1]);\n  result += String.fromCharCode(buffer[2]);\n  result += String.fromCharCode(buffer[3]);\n  return result;\n};\n\n\nmodule.exports = parseType;\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * Utilities to detect basic properties and metadata about MP4s.\n */\n'use strict';\n\nvar toUnsigned = require('../utils/bin').toUnsigned;\nvar toHexString = require('../utils/bin').toHexString;\nvar findBox = require('../mp4/find-box.js');\nvar parseType = require('../mp4/parse-type.js');\nvar parseTfhd = require('../tools/parse-tfhd.js');\nvar parseTrun = require('../tools/parse-trun.js');\nvar parseTfdt = require('../tools/parse-tfdt.js');\nvar timescale, startTime, compositionStartTime, getVideoTrackIds, getTracks,\n  getTimescaleFromMediaHeader;\n\n/**\n * Parses an MP4 initialization segment and extracts the timescale\n * values for any declared tracks. Timescale values indicate the\n * number of clock ticks per second to assume for time-based values\n * elsewhere in the MP4.\n *\n * To determine the start time of an MP4, you need two pieces of\n * information: the timescale unit and the earliest base media decode\n * time. Multiple timescales can be specified within an MP4 but the\n * base media decode time is always expressed in the timescale from\n * the media header box for the track:\n * ```\n * moov > trak > mdia > mdhd.timescale\n * ```\n * @param init {Uint8Array} the bytes of the init segment\n * @return {object} a hash of track ids to timescale values or null if\n * the init segment is malformed.\n */\ntimescale = function(init) {\n  var\n    result = {},\n    traks = findBox(init, ['moov', 'trak']);\n\n  // mdhd timescale\n  return traks.reduce(function(result, trak) {\n    var tkhd, version, index, id, mdhd;\n\n    tkhd = findBox(trak, ['tkhd'])[0];\n    if (!tkhd) {\n      return null;\n    }\n    version = tkhd[0];\n    index = version === 0 ? 12 : 20;\n    id = toUnsigned(tkhd[index]     << 24 |\n                    tkhd[index + 1] << 16 |\n                    tkhd[index + 2] <<  8 |\n                    tkhd[index + 3]);\n\n    mdhd = findBox(trak, ['mdia', 'mdhd'])[0];\n    if (!mdhd) {\n      return null;\n    }\n    version = mdhd[0];\n    index = version === 0 ? 12 : 20;\n    result[id] = toUnsigned(mdhd[index]     << 24 |\n                            mdhd[index + 1] << 16 |\n                            mdhd[index + 2] <<  8 |\n                            mdhd[index + 3]);\n    return result;\n  }, result);\n};\n\n/**\n * Determine the base media decode start time, in seconds, for an MP4\n * fragment. If multiple fragments are specified, the earliest time is\n * returned.\n *\n * The base media decode time can be parsed from track fragment\n * metadata:\n * ```\n * moof > traf > tfdt.baseMediaDecodeTime\n * ```\n * It requires the timescale value from the mdhd to interpret.\n *\n * @param timescale {object} a hash of track ids to timescale values.\n * @return {number} the earliest base media decode start time for the\n * fragment, in seconds\n */\nstartTime = function(timescale, fragment) {\n  var trafs, baseTimes, result;\n\n  // we need info from two childrend of each track fragment box\n  trafs = findBox(fragment, ['moof', 'traf']);\n\n  // determine the start times for each track\n  baseTimes = [].concat.apply([], trafs.map(function(traf) {\n    return findBox(traf, ['tfhd']).map(function(tfhd) {\n      var id, scale, baseTime;\n\n      // get the track id from the tfhd\n      id = toUnsigned(tfhd[4] << 24 |\n                      tfhd[5] << 16 |\n                      tfhd[6] <<  8 |\n                      tfhd[7]);\n      // assume a 90kHz clock if no timescale was specified\n      scale = timescale[id] || 90e3;\n\n      // get the base media decode time from the tfdt\n      baseTime = findBox(traf, ['tfdt']).map(function(tfdt) {\n        var version, result;\n\n        version = tfdt[0];\n        result = toUnsigned(tfdt[4] << 24 |\n                            tfdt[5] << 16 |\n                            tfdt[6] <<  8 |\n                            tfdt[7]);\n        if (version ===  1) {\n          result *= Math.pow(2, 32);\n          result += toUnsigned(tfdt[8]  << 24 |\n                               tfdt[9]  << 16 |\n                               tfdt[10] <<  8 |\n                               tfdt[11]);\n        }\n        return result;\n      })[0];\n      baseTime = baseTime || Infinity;\n\n      // convert base time to seconds\n      return baseTime / scale;\n    });\n  }));\n\n  // return the minimum\n  result = Math.min.apply(null, baseTimes);\n  return isFinite(result) ? result : 0;\n};\n\n/**\n * Determine the composition start, in seconds, for an MP4\n * fragment.\n *\n * The composition start time of a fragment can be calculated using the base\n * media decode time, composition time offset, and timescale, as follows:\n *\n * compositionStartTime = (baseMediaDecodeTime + compositionTimeOffset) / timescale\n *\n * All of the aforementioned information is contained within a media fragment's\n * `traf` box, except for timescale info, which comes from the initialization\n * segment, so a track id (also contained within a `traf`) is also necessary to\n * associate it with a timescale\n *\n *\n * @param timescales {object} - a hash of track ids to timescale values.\n * @param fragment {Unit8Array} - the bytes of a media segment\n * @return {number} the composition start time for the fragment, in seconds\n **/\ncompositionStartTime = function(timescales, fragment) {\n  var trafBoxes = findBox(fragment, ['moof', 'traf']);\n  var baseMediaDecodeTime = 0;\n  var compositionTimeOffset = 0;\n  var trackId;\n\n  if (trafBoxes && trafBoxes.length) {\n    // The spec states that track run samples contained within a `traf` box are contiguous, but\n    // it does not explicitly state whether the `traf` boxes themselves are contiguous.\n    // We will assume that they are, so we only need the first to calculate start time.\n    var tfhd = findBox(trafBoxes[0], ['tfhd'])[0];\n    var trun = findBox(trafBoxes[0], ['trun'])[0];\n    var tfdt = findBox(trafBoxes[0], ['tfdt'])[0];\n\n    if (tfhd) {\n      var parsedTfhd = parseTfhd(tfhd);\n\n      trackId = parsedTfhd.trackId;\n    }\n\n    if (tfdt) {\n      var parsedTfdt = parseTfdt(tfdt);\n\n      baseMediaDecodeTime = parsedTfdt.baseMediaDecodeTime;\n    }\n\n    if (trun) {\n      var parsedTrun = parseTrun(trun);\n\n      if (parsedTrun.samples && parsedTrun.samples.length) {\n        compositionTimeOffset = parsedTrun.samples[0].compositionTimeOffset || 0;\n      }\n    }\n  }\n\n  // Get timescale for this specific track. Assume a 90kHz clock if no timescale was\n  // specified.\n  var timescale = timescales[trackId] || 90e3;\n\n  // return the composition start time, in seconds\n  return (baseMediaDecodeTime + compositionTimeOffset) / timescale;\n};\n\n/**\n  * Find the trackIds of the video tracks in this source.\n  * Found by parsing the Handler Reference and Track Header Boxes:\n  *   moov > trak > mdia > hdlr\n  *   moov > trak > tkhd\n  *\n  * @param {Uint8Array} init - The bytes of the init segment for this source\n  * @return {Number[]} A list of trackIds\n  *\n  * @see ISO-BMFF-12/2015, Section 8.4.3\n **/\ngetVideoTrackIds = function(init) {\n  var traks = findBox(init, ['moov', 'trak']);\n  var videoTrackIds = [];\n\n  traks.forEach(function(trak) {\n    var hdlrs = findBox(trak, ['mdia', 'hdlr']);\n    var tkhds = findBox(trak, ['tkhd']);\n\n    hdlrs.forEach(function(hdlr, index) {\n      var handlerType = parseType(hdlr.subarray(8, 12));\n      var tkhd = tkhds[index];\n      var view;\n      var version;\n      var trackId;\n\n      if (handlerType === 'vide') {\n        view = new DataView(tkhd.buffer, tkhd.byteOffset, tkhd.byteLength);\n        version = view.getUint8(0);\n        trackId = (version === 0) ? view.getUint32(12) : view.getUint32(20);\n\n        videoTrackIds.push(trackId);\n      }\n    });\n  });\n\n  return videoTrackIds;\n};\n\ngetTimescaleFromMediaHeader = function(mdhd) {\n  // mdhd is a FullBox, meaning it will have its own version as the first byte\n  var version = mdhd[0];\n  var index = version === 0 ? 12 : 20;\n\n  return toUnsigned(\n    mdhd[index]     << 24 |\n    mdhd[index + 1] << 16 |\n    mdhd[index + 2] <<  8 |\n    mdhd[index + 3]\n  );\n};\n\n/**\n * Get all the video, audio, and hint tracks from a non fragmented\n * mp4 segment\n */\ngetTracks = function(init) {\n  var traks = findBox(init, ['moov', 'trak']);\n  var tracks = [];\n\n  traks.forEach(function(trak) {\n    var track = {};\n    var tkhd = findBox(trak, ['tkhd'])[0];\n    var view, tkhdVersion;\n\n    // id\n    if (tkhd) {\n      view = new DataView(tkhd.buffer, tkhd.byteOffset, tkhd.byteLength);\n      tkhdVersion = view.getUint8(0);\n\n      track.id = (tkhdVersion === 0) ? view.getUint32(12) : view.getUint32(20);\n    }\n\n    var hdlr = findBox(trak, ['mdia', 'hdlr'])[0];\n\n    // type\n    if (hdlr) {\n      var type = parseType(hdlr.subarray(8, 12));\n\n      if (type === 'vide') {\n        track.type = 'video';\n      } else if (type === 'soun') {\n        track.type = 'audio';\n      } else {\n        track.type = type;\n      }\n    }\n\n\n    // codec\n    var stsd = findBox(trak, ['mdia', 'minf', 'stbl', 'stsd'])[0];\n\n    if (stsd) {\n      var sampleDescriptions = stsd.subarray(8);\n      // gives the codec type string\n      track.codec = parseType(sampleDescriptions.subarray(4, 8));\n\n      var codecBox = findBox(sampleDescriptions, [track.codec])[0];\n      var codecConfig, codecConfigType;\n\n      if (codecBox) {\n        // https://tools.ietf.org/html/rfc6381#section-3.3\n        if ((/^[a-z]vc[1-9]$/i).test(track.codec)) {\n          // we don't need anything but the \"config\" parameter of the\n          // avc1 codecBox\n          codecConfig = codecBox.subarray(78);\n          codecConfigType = parseType(codecConfig.subarray(4, 8));\n\n          if (codecConfigType === 'avcC' && codecConfig.length > 11) {\n            track.codec += '.';\n\n            // left padded with zeroes for single digit hex\n            // profile idc\n            track.codec +=  toHexString(codecConfig[9]);\n            // the byte containing the constraint_set flags\n            track.codec += toHexString(codecConfig[10]);\n            // level idc\n            track.codec += toHexString(codecConfig[11]);\n          } else {\n            // TODO: show a warning that we couldn't parse the codec\n            // and are using the default\n            track.codec = 'avc1.4d400d';\n          }\n        } else if ((/^mp4[a,v]$/i).test(track.codec)) {\n          // we do not need anything but the streamDescriptor of the mp4a codecBox\n          codecConfig = codecBox.subarray(28);\n          codecConfigType = parseType(codecConfig.subarray(4, 8));\n\n          if (codecConfigType === 'esds' && codecConfig.length > 20 && codecConfig[19] !== 0) {\n            track.codec += '.' + toHexString(codecConfig[19]);\n            // this value is only a single digit\n            track.codec += '.' + toHexString((codecConfig[20] >>> 2) & 0x3f).replace(/^0/, '');\n          } else {\n            // TODO: show a warning that we couldn't parse the codec\n            // and are using the default\n            track.codec = 'mp4a.40.2';\n          }\n        } else {\n          // TODO: show a warning? for unknown codec type\n        }\n      }\n    }\n\n    var mdhd = findBox(trak, ['mdia', 'mdhd'])[0];\n\n    if (mdhd) {\n      track.timescale = getTimescaleFromMediaHeader(mdhd);\n    }\n\n    tracks.push(track);\n  });\n\n  return tracks;\n};\n\nmodule.exports = {\n  // export mp4 inspector's findBox and parseType for backwards compatibility\n  findBox: findBox,\n  parseType: parseType,\n  timescale: timescale,\n  startTime: startTime,\n  compositionStartTime: compositionStartTime,\n  videoTrackIds: getVideoTrackIds,\n  tracks: getTracks,\n  getTimescaleFromMediaHeader: getTimescaleFromMediaHeader\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\nvar ONE_SECOND_IN_TS = require('../utils/clock').ONE_SECOND_IN_TS;\n\n/**\n * Store information about the start and end of the track and the\n * duration for each frame/sample we process in order to calculate\n * the baseMediaDecodeTime\n */\nvar collectDtsInfo = function(track, data) {\n  if (typeof data.pts === 'number') {\n    if (track.timelineStartInfo.pts === undefined) {\n      track.timelineStartInfo.pts = data.pts;\n    }\n\n    if (track.minSegmentPts === undefined) {\n      track.minSegmentPts = data.pts;\n    } else {\n      track.minSegmentPts = Math.min(track.minSegmentPts, data.pts);\n    }\n\n    if (track.maxSegmentPts === undefined) {\n      track.maxSegmentPts = data.pts;\n    } else {\n      track.maxSegmentPts = Math.max(track.maxSegmentPts, data.pts);\n    }\n  }\n\n  if (typeof data.dts === 'number') {\n    if (track.timelineStartInfo.dts === undefined) {\n      track.timelineStartInfo.dts = data.dts;\n    }\n\n    if (track.minSegmentDts === undefined) {\n      track.minSegmentDts = data.dts;\n    } else {\n      track.minSegmentDts = Math.min(track.minSegmentDts, data.dts);\n    }\n\n    if (track.maxSegmentDts === undefined) {\n      track.maxSegmentDts = data.dts;\n    } else {\n      track.maxSegmentDts = Math.max(track.maxSegmentDts, data.dts);\n    }\n  }\n};\n\n/**\n * Clear values used to calculate the baseMediaDecodeTime between\n * tracks\n */\nvar clearDtsInfo = function(track) {\n  delete track.minSegmentDts;\n  delete track.maxSegmentDts;\n  delete track.minSegmentPts;\n  delete track.maxSegmentPts;\n};\n\n/**\n * Calculate the track's baseMediaDecodeTime based on the earliest\n * DTS the transmuxer has ever seen and the minimum DTS for the\n * current track\n * @param track {object} track metadata configuration\n * @param keepOriginalTimestamps {boolean} If true, keep the timestamps\n *        in the source; false to adjust the first segment to start at 0.\n */\nvar calculateTrackBaseMediaDecodeTime = function(track, keepOriginalTimestamps) {\n  var\n    baseMediaDecodeTime,\n    scale,\n    minSegmentDts = track.minSegmentDts;\n\n  // Optionally adjust the time so the first segment starts at zero.\n  if (!keepOriginalTimestamps) {\n    minSegmentDts -= track.timelineStartInfo.dts;\n  }\n\n  // track.timelineStartInfo.baseMediaDecodeTime is the location, in time, where\n  // we want the start of the first segment to be placed\n  baseMediaDecodeTime = track.timelineStartInfo.baseMediaDecodeTime;\n\n  // Add to that the distance this segment is from the very first\n  baseMediaDecodeTime += minSegmentDts;\n\n  // baseMediaDecodeTime must not become negative\n  baseMediaDecodeTime = Math.max(0, baseMediaDecodeTime);\n\n  if (track.type === 'audio') {\n    // Audio has a different clock equal to the sampling_rate so we need to\n    // scale the PTS values into the clock rate of the track\n    scale = track.samplerate / ONE_SECOND_IN_TS;\n    baseMediaDecodeTime *= scale;\n    baseMediaDecodeTime = Math.floor(baseMediaDecodeTime);\n  }\n\n  return baseMediaDecodeTime;\n};\n\nmodule.exports = {\n  clearDtsInfo: clearDtsInfo,\n  calculateTrackBaseMediaDecodeTime: calculateTrackBaseMediaDecodeTime,\n  collectDtsInfo: collectDtsInfo\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * A stream-based mp2t to mp4 converter. This utility can be used to\n * deliver mp4s to a SourceBuffer on platforms that support native\n * Media Source Extensions.\n */\n'use strict';\n\nvar Stream = require('../utils/stream.js');\nvar mp4 = require('./mp4-generator.js');\nvar frameUtils = require('./frame-utils');\nvar audioFrameUtils = require('./audio-frame-utils');\nvar trackDecodeInfo = require('./track-decode-info');\nvar m2ts = require('../m2ts/m2ts.js');\nvar clock = require('../utils/clock');\nvar AdtsStream = require('../codecs/adts.js');\nvar H264Stream = require('../codecs/h264').H264Stream;\nvar AacStream = require('../aac');\nvar isLikelyAacData = require('../aac/utils').isLikelyAacData;\nvar ONE_SECOND_IN_TS = require('../utils/clock').ONE_SECOND_IN_TS;\nvar AUDIO_PROPERTIES = require('../constants/audio-properties.js');\nvar VIDEO_PROPERTIES = require('../constants/video-properties.js');\n\n// object types\nvar VideoSegmentStream, AudioSegmentStream, Transmuxer, CoalesceStream;\n\n/**\n * Compare two arrays (even typed) for same-ness\n */\nvar arrayEquals = function(a, b) {\n  var\n    i;\n\n  if (a.length !== b.length) {\n    return false;\n  }\n\n  // compare the value of each element in the array\n  for (i = 0; i < a.length; i++) {\n    if (a[i] !== b[i]) {\n      return false;\n    }\n  }\n\n  return true;\n};\n\nvar generateVideoSegmentTimingInfo = function(\n  baseMediaDecodeTime,\n  startDts,\n  startPts,\n  endDts,\n  endPts,\n  prependedContentDuration\n) {\n  var\n    ptsOffsetFromDts = startPts - startDts,\n    decodeDuration = endDts - startDts,\n    presentationDuration = endPts - startPts;\n\n  // The PTS and DTS values are based on the actual stream times from the segment,\n  // however, the player time values will reflect a start from the baseMediaDecodeTime.\n  // In order to provide relevant values for the player times, base timing info on the\n  // baseMediaDecodeTime and the DTS and PTS durations of the segment.\n  return {\n    start: {\n      dts: baseMediaDecodeTime,\n      pts: baseMediaDecodeTime + ptsOffsetFromDts\n    },\n    end: {\n      dts: baseMediaDecodeTime + decodeDuration,\n      pts: baseMediaDecodeTime + presentationDuration\n    },\n    prependedContentDuration: prependedContentDuration,\n    baseMediaDecodeTime: baseMediaDecodeTime\n  };\n};\n\n/**\n * Constructs a single-track, ISO BMFF media segment from AAC data\n * events. The output of this stream can be fed to a SourceBuffer\n * configured with a suitable initialization segment.\n * @param track {object} track metadata configuration\n * @param options {object} transmuxer options object\n * @param options.keepOriginalTimestamps {boolean} If true, keep the timestamps\n *        in the source; false to adjust the first segment to start at 0.\n */\nAudioSegmentStream = function(track, options) {\n  var\n    adtsFrames = [],\n    sequenceNumber = 0,\n    earliestAllowedDts = 0,\n    audioAppendStartTs = 0,\n    videoBaseMediaDecodeTime = Infinity;\n\n  options = options || {};\n\n  AudioSegmentStream.prototype.init.call(this);\n\n  this.push = function(data) {\n    trackDecodeInfo.collectDtsInfo(track, data);\n\n    if (track) {\n      AUDIO_PROPERTIES.forEach(function(prop) {\n        track[prop] = data[prop];\n      });\n    }\n\n    // buffer audio data until end() is called\n    adtsFrames.push(data);\n  };\n\n  this.setEarliestDts = function(earliestDts) {\n    earliestAllowedDts = earliestDts;\n  };\n\n  this.setVideoBaseMediaDecodeTime = function(baseMediaDecodeTime) {\n    videoBaseMediaDecodeTime = baseMediaDecodeTime;\n  };\n\n  this.setAudioAppendStart = function(timestamp) {\n    audioAppendStartTs = timestamp;\n  };\n\n  this.flush = function() {\n    var\n      frames,\n      moof,\n      mdat,\n      boxes,\n      frameDuration;\n\n    // return early if no audio data has been observed\n    if (adtsFrames.length === 0) {\n      this.trigger('done', 'AudioSegmentStream');\n      return;\n    }\n\n    frames = audioFrameUtils.trimAdtsFramesByEarliestDts(\n      adtsFrames, track, earliestAllowedDts);\n    track.baseMediaDecodeTime = trackDecodeInfo.calculateTrackBaseMediaDecodeTime(\n      track, options.keepOriginalTimestamps);\n\n    audioFrameUtils.prefixWithSilence(\n      track, frames, audioAppendStartTs, videoBaseMediaDecodeTime);\n\n    // we have to build the index from byte locations to\n    // samples (that is, adts frames) in the audio data\n    track.samples = audioFrameUtils.generateSampleTable(frames);\n\n    // concatenate the audio data to constuct the mdat\n    mdat = mp4.mdat(audioFrameUtils.concatenateFrameData(frames));\n\n    adtsFrames = [];\n\n    moof = mp4.moof(sequenceNumber, [track]);\n    boxes = new Uint8Array(moof.byteLength + mdat.byteLength);\n\n    // bump the sequence number for next time\n    sequenceNumber++;\n\n    boxes.set(moof);\n    boxes.set(mdat, moof.byteLength);\n\n    trackDecodeInfo.clearDtsInfo(track);\n\n    frameDuration = Math.ceil(ONE_SECOND_IN_TS * 1024 / track.samplerate);\n\n    // TODO this check was added to maintain backwards compatibility (particularly with\n    // tests) on adding the timingInfo event. However, it seems unlikely that there's a\n    // valid use-case where an init segment/data should be triggered without associated\n    // frames. Leaving for now, but should be looked into.\n    if (frames.length) {\n      this.trigger('timingInfo', {\n        start: frames[0].pts,\n        end: frames[0].pts + (frames.length * frameDuration)\n      });\n    }\n    this.trigger('data', {track: track, boxes: boxes});\n    this.trigger('done', 'AudioSegmentStream');\n  };\n\n  this.reset = function() {\n    trackDecodeInfo.clearDtsInfo(track);\n    adtsFrames = [];\n    this.trigger('reset');\n  };\n};\n\nAudioSegmentStream.prototype = new Stream();\n\n/**\n * Constructs a single-track, ISO BMFF media segment from H264 data\n * events. The output of this stream can be fed to a SourceBuffer\n * configured with a suitable initialization segment.\n * @param track {object} track metadata configuration\n * @param options {object} transmuxer options object\n * @param options.alignGopsAtEnd {boolean} If true, start from the end of the\n *        gopsToAlignWith list when attempting to align gop pts\n * @param options.keepOriginalTimestamps {boolean} If true, keep the timestamps\n *        in the source; false to adjust the first segment to start at 0.\n */\nVideoSegmentStream = function(track, options) {\n  var\n    sequenceNumber = 0,\n    nalUnits = [],\n    gopsToAlignWith = [],\n    config,\n    pps;\n\n  options = options || {};\n\n  VideoSegmentStream.prototype.init.call(this);\n\n  delete track.minPTS;\n\n  this.gopCache_ = [];\n\n  /**\n    * Constructs a ISO BMFF segment given H264 nalUnits\n    * @param {Object} nalUnit A data event representing a nalUnit\n    * @param {String} nalUnit.nalUnitType\n    * @param {Object} nalUnit.config Properties for a mp4 track\n    * @param {Uint8Array} nalUnit.data The nalUnit bytes\n    * @see lib/codecs/h264.js\n   **/\n  this.push = function(nalUnit) {\n    trackDecodeInfo.collectDtsInfo(track, nalUnit);\n\n    // record the track config\n    if (nalUnit.nalUnitType === 'seq_parameter_set_rbsp' && !config) {\n      config = nalUnit.config;\n      track.sps = [nalUnit.data];\n\n      VIDEO_PROPERTIES.forEach(function(prop) {\n        track[prop] = config[prop];\n      }, this);\n    }\n\n    if (nalUnit.nalUnitType === 'pic_parameter_set_rbsp' &&\n        !pps) {\n      pps = nalUnit.data;\n      track.pps = [nalUnit.data];\n    }\n\n    // buffer video until flush() is called\n    nalUnits.push(nalUnit);\n  };\n\n  /**\n    * Pass constructed ISO BMFF track and boxes on to the\n    * next stream in the pipeline\n   **/\n  this.flush = function() {\n    var\n      frames,\n      gopForFusion,\n      gops,\n      moof,\n      mdat,\n      boxes,\n      prependedContentDuration = 0,\n      firstGop,\n      lastGop;\n\n    // Throw away nalUnits at the start of the byte stream until\n    // we find the first AUD\n    while (nalUnits.length) {\n      if (nalUnits[0].nalUnitType === 'access_unit_delimiter_rbsp') {\n        break;\n      }\n      nalUnits.shift();\n    }\n\n    // Return early if no video data has been observed\n    if (nalUnits.length === 0) {\n      this.resetStream_();\n      this.trigger('done', 'VideoSegmentStream');\n      return;\n    }\n\n    // Organize the raw nal-units into arrays that represent\n    // higher-level constructs such as frames and gops\n    // (group-of-pictures)\n    frames = frameUtils.groupNalsIntoFrames(nalUnits);\n    gops = frameUtils.groupFramesIntoGops(frames);\n\n    // If the first frame of this fragment is not a keyframe we have\n    // a problem since MSE (on Chrome) requires a leading keyframe.\n    //\n    // We have two approaches to repairing this situation:\n    // 1) GOP-FUSION:\n    //    This is where we keep track of the GOPS (group-of-pictures)\n    //    from previous fragments and attempt to find one that we can\n    //    prepend to the current fragment in order to create a valid\n    //    fragment.\n    // 2) KEYFRAME-PULLING:\n    //    Here we search for the first keyframe in the fragment and\n    //    throw away all the frames between the start of the fragment\n    //    and that keyframe. We then extend the duration and pull the\n    //    PTS of the keyframe forward so that it covers the time range\n    //    of the frames that were disposed of.\n    //\n    // #1 is far prefereable over #2 which can cause \"stuttering\" but\n    // requires more things to be just right.\n    if (!gops[0][0].keyFrame) {\n      // Search for a gop for fusion from our gopCache\n      gopForFusion = this.getGopForFusion_(nalUnits[0], track);\n\n      if (gopForFusion) {\n        // in order to provide more accurate timing information about the segment, save\n        // the number of seconds prepended to the original segment due to GOP fusion\n        prependedContentDuration = gopForFusion.duration;\n\n        gops.unshift(gopForFusion);\n        // Adjust Gops' metadata to account for the inclusion of the\n        // new gop at the beginning\n        gops.byteLength += gopForFusion.byteLength;\n        gops.nalCount += gopForFusion.nalCount;\n        gops.pts = gopForFusion.pts;\n        gops.dts = gopForFusion.dts;\n        gops.duration += gopForFusion.duration;\n      } else {\n        // If we didn't find a candidate gop fall back to keyframe-pulling\n        gops = frameUtils.extendFirstKeyFrame(gops);\n      }\n    }\n\n    // Trim gops to align with gopsToAlignWith\n    if (gopsToAlignWith.length) {\n      var alignedGops;\n\n      if (options.alignGopsAtEnd) {\n        alignedGops = this.alignGopsAtEnd_(gops);\n      } else {\n        alignedGops = this.alignGopsAtStart_(gops);\n      }\n\n      if (!alignedGops) {\n        // save all the nals in the last GOP into the gop cache\n        this.gopCache_.unshift({\n          gop: gops.pop(),\n          pps: track.pps,\n          sps: track.sps\n        });\n\n        // Keep a maximum of 6 GOPs in the cache\n        this.gopCache_.length = Math.min(6, this.gopCache_.length);\n\n        // Clear nalUnits\n        nalUnits = [];\n\n        // return early no gops can be aligned with desired gopsToAlignWith\n        this.resetStream_();\n        this.trigger('done', 'VideoSegmentStream');\n        return;\n      }\n\n      // Some gops were trimmed. clear dts info so minSegmentDts and pts are correct\n      // when recalculated before sending off to CoalesceStream\n      trackDecodeInfo.clearDtsInfo(track);\n\n      gops = alignedGops;\n    }\n\n    trackDecodeInfo.collectDtsInfo(track, gops);\n\n    // First, we have to build the index from byte locations to\n    // samples (that is, frames) in the video data\n    track.samples = frameUtils.generateSampleTable(gops);\n\n    // Concatenate the video data and construct the mdat\n    mdat = mp4.mdat(frameUtils.concatenateNalData(gops));\n\n    track.baseMediaDecodeTime = trackDecodeInfo.calculateTrackBaseMediaDecodeTime(\n      track, options.keepOriginalTimestamps);\n\n    this.trigger('processedGopsInfo', gops.map(function(gop) {\n      return {\n        pts: gop.pts,\n        dts: gop.dts,\n        byteLength: gop.byteLength\n      };\n    }));\n\n    firstGop = gops[0];\n    lastGop = gops[gops.length - 1];\n\n    this.trigger(\n      'segmentTimingInfo',\n      generateVideoSegmentTimingInfo(\n        track.baseMediaDecodeTime,\n        firstGop.dts,\n        firstGop.pts,\n        lastGop.dts + lastGop.duration,\n        lastGop.pts + lastGop.duration,\n        prependedContentDuration));\n\n    this.trigger('timingInfo', {\n      start: gops[0].pts,\n      end: gops[gops.length - 1].pts + gops[gops.length - 1].duration\n    });\n\n    // save all the nals in the last GOP into the gop cache\n    this.gopCache_.unshift({\n      gop: gops.pop(),\n      pps: track.pps,\n      sps: track.sps\n    });\n\n    // Keep a maximum of 6 GOPs in the cache\n    this.gopCache_.length = Math.min(6, this.gopCache_.length);\n\n    // Clear nalUnits\n    nalUnits = [];\n\n    this.trigger('baseMediaDecodeTime', track.baseMediaDecodeTime);\n    this.trigger('timelineStartInfo', track.timelineStartInfo);\n\n    moof = mp4.moof(sequenceNumber, [track]);\n\n    // it would be great to allocate this array up front instead of\n    // throwing away hundreds of media segment fragments\n    boxes = new Uint8Array(moof.byteLength + mdat.byteLength);\n\n    // Bump the sequence number for next time\n    sequenceNumber++;\n\n    boxes.set(moof);\n    boxes.set(mdat, moof.byteLength);\n\n    this.trigger('data', {track: track, boxes: boxes});\n\n    this.resetStream_();\n\n    // Continue with the flush process now\n    this.trigger('done', 'VideoSegmentStream');\n  };\n\n  this.reset = function() {\n    this.resetStream_();\n    nalUnits = [];\n    this.gopCache_.length = 0;\n    gopsToAlignWith.length = 0;\n    this.trigger('reset');\n  };\n\n  this.resetStream_ = function() {\n    trackDecodeInfo.clearDtsInfo(track);\n\n    // reset config and pps because they may differ across segments\n    // for instance, when we are rendition switching\n    config = undefined;\n    pps = undefined;\n  };\n\n  // Search for a candidate Gop for gop-fusion from the gop cache and\n  // return it or return null if no good candidate was found\n  this.getGopForFusion_ = function(nalUnit) {\n    var\n      halfSecond = 45000, // Half-a-second in a 90khz clock\n      allowableOverlap = 10000, // About 3 frames @ 30fps\n      nearestDistance = Infinity,\n      dtsDistance,\n      nearestGopObj,\n      currentGop,\n      currentGopObj,\n      i;\n\n    // Search for the GOP nearest to the beginning of this nal unit\n    for (i = 0; i < this.gopCache_.length; i++) {\n      currentGopObj = this.gopCache_[i];\n      currentGop = currentGopObj.gop;\n\n      // Reject Gops with different SPS or PPS\n      if (!(track.pps && arrayEquals(track.pps[0], currentGopObj.pps[0])) ||\n          !(track.sps && arrayEquals(track.sps[0], currentGopObj.sps[0]))) {\n        continue;\n      }\n\n      // Reject Gops that would require a negative baseMediaDecodeTime\n      if (currentGop.dts < track.timelineStartInfo.dts) {\n        continue;\n      }\n\n      // The distance between the end of the gop and the start of the nalUnit\n      dtsDistance = (nalUnit.dts - currentGop.dts) - currentGop.duration;\n\n      // Only consider GOPS that start before the nal unit and end within\n      // a half-second of the nal unit\n      if (dtsDistance >= -allowableOverlap &&\n          dtsDistance <= halfSecond) {\n\n        // Always use the closest GOP we found if there is more than\n        // one candidate\n        if (!nearestGopObj ||\n            nearestDistance > dtsDistance) {\n          nearestGopObj = currentGopObj;\n          nearestDistance = dtsDistance;\n        }\n      }\n    }\n\n    if (nearestGopObj) {\n      return nearestGopObj.gop;\n    }\n    return null;\n  };\n\n  // trim gop list to the first gop found that has a matching pts with a gop in the list\n  // of gopsToAlignWith starting from the START of the list\n  this.alignGopsAtStart_ = function(gops) {\n    var alignIndex, gopIndex, align, gop, byteLength, nalCount, duration, alignedGops;\n\n    byteLength = gops.byteLength;\n    nalCount = gops.nalCount;\n    duration = gops.duration;\n    alignIndex = gopIndex = 0;\n\n    while (alignIndex < gopsToAlignWith.length && gopIndex < gops.length) {\n      align = gopsToAlignWith[alignIndex];\n      gop = gops[gopIndex];\n\n      if (align.pts === gop.pts) {\n        break;\n      }\n\n      if (gop.pts > align.pts) {\n        // this current gop starts after the current gop we want to align on, so increment\n        // align index\n        alignIndex++;\n        continue;\n      }\n\n      // current gop starts before the current gop we want to align on. so increment gop\n      // index\n      gopIndex++;\n      byteLength -= gop.byteLength;\n      nalCount -= gop.nalCount;\n      duration -= gop.duration;\n    }\n\n    if (gopIndex === 0) {\n      // no gops to trim\n      return gops;\n    }\n\n    if (gopIndex === gops.length) {\n      // all gops trimmed, skip appending all gops\n      return null;\n    }\n\n    alignedGops = gops.slice(gopIndex);\n    alignedGops.byteLength = byteLength;\n    alignedGops.duration = duration;\n    alignedGops.nalCount = nalCount;\n    alignedGops.pts = alignedGops[0].pts;\n    alignedGops.dts = alignedGops[0].dts;\n\n    return alignedGops;\n  };\n\n  // trim gop list to the first gop found that has a matching pts with a gop in the list\n  // of gopsToAlignWith starting from the END of the list\n  this.alignGopsAtEnd_ = function(gops) {\n    var alignIndex, gopIndex, align, gop, alignEndIndex, matchFound;\n\n    alignIndex = gopsToAlignWith.length - 1;\n    gopIndex = gops.length - 1;\n    alignEndIndex = null;\n    matchFound = false;\n\n    while (alignIndex >= 0 && gopIndex >= 0) {\n      align = gopsToAlignWith[alignIndex];\n      gop = gops[gopIndex];\n\n      if (align.pts === gop.pts) {\n        matchFound = true;\n        break;\n      }\n\n      if (align.pts > gop.pts) {\n        alignIndex--;\n        continue;\n      }\n\n      if (alignIndex === gopsToAlignWith.length - 1) {\n        // gop.pts is greater than the last alignment candidate. If no match is found\n        // by the end of this loop, we still want to append gops that come after this\n        // point\n        alignEndIndex = gopIndex;\n      }\n\n      gopIndex--;\n    }\n\n    if (!matchFound && alignEndIndex === null) {\n      return null;\n    }\n\n    var trimIndex;\n\n    if (matchFound) {\n      trimIndex = gopIndex;\n    } else {\n      trimIndex = alignEndIndex;\n    }\n\n    if (trimIndex === 0) {\n      return gops;\n    }\n\n    var alignedGops = gops.slice(trimIndex);\n    var metadata = alignedGops.reduce(function(total, gop) {\n      total.byteLength += gop.byteLength;\n      total.duration += gop.duration;\n      total.nalCount += gop.nalCount;\n      return total;\n    }, { byteLength: 0, duration: 0, nalCount: 0 });\n\n    alignedGops.byteLength = metadata.byteLength;\n    alignedGops.duration = metadata.duration;\n    alignedGops.nalCount = metadata.nalCount;\n    alignedGops.pts = alignedGops[0].pts;\n    alignedGops.dts = alignedGops[0].dts;\n\n    return alignedGops;\n  };\n\n  this.alignGopsWith = function(newGopsToAlignWith) {\n    gopsToAlignWith = newGopsToAlignWith;\n  };\n};\n\nVideoSegmentStream.prototype = new Stream();\n\n/**\n * A Stream that can combine multiple streams (ie. audio & video)\n * into a single output segment for MSE. Also supports audio-only\n * and video-only streams.\n * @param options {object} transmuxer options object\n * @param options.keepOriginalTimestamps {boolean} If true, keep the timestamps\n *        in the source; false to adjust the first segment to start at media timeline start.\n */\nCoalesceStream = function(options, metadataStream) {\n  // Number of Tracks per output segment\n  // If greater than 1, we combine multiple\n  // tracks into a single segment\n  this.numberOfTracks = 0;\n  this.metadataStream = metadataStream;\n\n  options = options || {};\n\n  if (typeof options.remux !== 'undefined') {\n    this.remuxTracks = !!options.remux;\n  } else {\n    this.remuxTracks = true;\n  }\n\n  if (typeof options.keepOriginalTimestamps === 'boolean') {\n    this.keepOriginalTimestamps = options.keepOriginalTimestamps;\n  } else {\n    this.keepOriginalTimestamps = false;\n  }\n\n  this.pendingTracks = [];\n  this.videoTrack = null;\n  this.pendingBoxes = [];\n  this.pendingCaptions = [];\n  this.pendingMetadata = [];\n  this.pendingBytes = 0;\n  this.emittedTracks = 0;\n\n  CoalesceStream.prototype.init.call(this);\n\n  // Take output from multiple\n  this.push = function(output) {\n    // buffer incoming captions until the associated video segment\n    // finishes\n    if (output.text) {\n      return this.pendingCaptions.push(output);\n    }\n    // buffer incoming id3 tags until the final flush\n    if (output.frames) {\n      return this.pendingMetadata.push(output);\n    }\n\n    // Add this track to the list of pending tracks and store\n    // important information required for the construction of\n    // the final segment\n    this.pendingTracks.push(output.track);\n    this.pendingBytes += output.boxes.byteLength;\n\n    // TODO: is there an issue for this against chrome?\n    // We unshift audio and push video because\n    // as of Chrome 75 when switching from\n    // one init segment to another if the video\n    // mdat does not appear after the audio mdat\n    // only audio will play for the duration of our transmux.\n    if (output.track.type === 'video') {\n      this.videoTrack = output.track;\n      this.pendingBoxes.push(output.boxes);\n    }\n    if (output.track.type === 'audio') {\n      this.audioTrack = output.track;\n      this.pendingBoxes.unshift(output.boxes);\n    }\n  };\n};\n\nCoalesceStream.prototype = new Stream();\nCoalesceStream.prototype.flush = function(flushSource) {\n  var\n    offset = 0,\n    event = {\n      captions: [],\n      captionStreams: {},\n      metadata: [],\n      info: {}\n    },\n    caption,\n    id3,\n    initSegment,\n    timelineStartPts = 0,\n    i;\n\n  if (this.pendingTracks.length < this.numberOfTracks) {\n    if (flushSource !== 'VideoSegmentStream' &&\n        flushSource !== 'AudioSegmentStream') {\n      // Return because we haven't received a flush from a data-generating\n      // portion of the segment (meaning that we have only recieved meta-data\n      // or captions.)\n      return;\n    } else if (this.remuxTracks) {\n      // Return until we have enough tracks from the pipeline to remux (if we\n      // are remuxing audio and video into a single MP4)\n      return;\n    } else if (this.pendingTracks.length === 0) {\n      // In the case where we receive a flush without any data having been\n      // received we consider it an emitted track for the purposes of coalescing\n      // `done` events.\n      // We do this for the case where there is an audio and video track in the\n      // segment but no audio data. (seen in several playlists with alternate\n      // audio tracks and no audio present in the main TS segments.)\n      this.emittedTracks++;\n\n      if (this.emittedTracks >= this.numberOfTracks) {\n        this.trigger('done');\n        this.emittedTracks = 0;\n      }\n      return;\n    }\n  }\n\n  if (this.videoTrack) {\n    timelineStartPts = this.videoTrack.timelineStartInfo.pts;\n    VIDEO_PROPERTIES.forEach(function(prop) {\n      event.info[prop] = this.videoTrack[prop];\n    }, this);\n  } else if (this.audioTrack) {\n    timelineStartPts = this.audioTrack.timelineStartInfo.pts;\n    AUDIO_PROPERTIES.forEach(function(prop) {\n      event.info[prop] = this.audioTrack[prop];\n    }, this);\n  }\n\n  if (this.videoTrack || this.audioTrack) {\n    if (this.pendingTracks.length === 1) {\n      event.type = this.pendingTracks[0].type;\n    } else {\n      event.type = 'combined';\n    }\n\n    this.emittedTracks += this.pendingTracks.length;\n\n    initSegment = mp4.initSegment(this.pendingTracks);\n\n    // Create a new typed array to hold the init segment\n    event.initSegment = new Uint8Array(initSegment.byteLength);\n\n    // Create an init segment containing a moov\n    // and track definitions\n    event.initSegment.set(initSegment);\n\n    // Create a new typed array to hold the moof+mdats\n    event.data = new Uint8Array(this.pendingBytes);\n\n    // Append each moof+mdat (one per track) together\n    for (i = 0; i < this.pendingBoxes.length; i++) {\n      event.data.set(this.pendingBoxes[i], offset);\n      offset += this.pendingBoxes[i].byteLength;\n    }\n\n    // Translate caption PTS times into second offsets to match the\n    // video timeline for the segment, and add track info\n    for (i = 0; i < this.pendingCaptions.length; i++) {\n      caption = this.pendingCaptions[i];\n      caption.startTime = clock.metadataTsToSeconds(\n        caption.startPts, timelineStartPts, this.keepOriginalTimestamps);\n      caption.endTime = clock.metadataTsToSeconds(\n        caption.endPts, timelineStartPts, this.keepOriginalTimestamps);\n\n      event.captionStreams[caption.stream] = true;\n      event.captions.push(caption);\n    }\n\n    // Translate ID3 frame PTS times into second offsets to match the\n    // video timeline for the segment\n    for (i = 0; i < this.pendingMetadata.length; i++) {\n      id3 = this.pendingMetadata[i];\n      id3.cueTime = clock.metadataTsToSeconds(\n        id3.pts, timelineStartPts, this.keepOriginalTimestamps);\n\n      event.metadata.push(id3);\n    }\n\n    // We add this to every single emitted segment even though we only need\n    // it for the first\n    event.metadata.dispatchType = this.metadataStream.dispatchType;\n\n    // Reset stream state\n    this.pendingTracks.length = 0;\n    this.videoTrack = null;\n    this.pendingBoxes.length = 0;\n    this.pendingCaptions.length = 0;\n    this.pendingBytes = 0;\n    this.pendingMetadata.length = 0;\n\n    // Emit the built segment\n    // We include captions and ID3 tags for backwards compatibility,\n    // ideally we should send only video and audio in the data event\n    this.trigger('data', event);\n    // Emit each caption to the outside world\n    // Ideally, this would happen immediately on parsing captions,\n    // but we need to ensure that video data is sent back first\n    // so that caption timing can be adjusted to match video timing\n    for (i = 0; i < event.captions.length; i++) {\n      caption = event.captions[i];\n\n      this.trigger('caption', caption);\n    }\n    // Emit each id3 tag to the outside world\n    // Ideally, this would happen immediately on parsing the tag,\n    // but we need to ensure that video data is sent back first\n    // so that ID3 frame timing can be adjusted to match video timing\n    for (i = 0; i < event.metadata.length; i++) {\n      id3 = event.metadata[i];\n\n      this.trigger('id3Frame', id3);\n    }\n  }\n\n  // Only emit `done` if all tracks have been flushed and emitted\n  if (this.emittedTracks >= this.numberOfTracks) {\n    this.trigger('done');\n    this.emittedTracks = 0;\n  }\n};\n\nCoalesceStream.prototype.setRemux = function(val) {\n  this.remuxTracks = val;\n};\n/**\n * A Stream that expects MP2T binary data as input and produces\n * corresponding media segments, suitable for use with Media Source\n * Extension (MSE) implementations that support the ISO BMFF byte\n * stream format, like Chrome.\n */\nTransmuxer = function(options) {\n  var\n    self = this,\n    hasFlushed = true,\n    videoTrack,\n    audioTrack;\n\n  Transmuxer.prototype.init.call(this);\n\n  options = options || {};\n  this.baseMediaDecodeTime = options.baseMediaDecodeTime || 0;\n  this.transmuxPipeline_ = {};\n\n  this.setupAacPipeline = function() {\n    var pipeline = {};\n    this.transmuxPipeline_ = pipeline;\n\n    pipeline.type = 'aac';\n    pipeline.metadataStream = new m2ts.MetadataStream();\n\n    // set up the parsing pipeline\n    pipeline.aacStream = new AacStream();\n    pipeline.audioTimestampRolloverStream = new m2ts.TimestampRolloverStream('audio');\n    pipeline.timedMetadataTimestampRolloverStream = new m2ts.TimestampRolloverStream('timed-metadata');\n    pipeline.adtsStream = new AdtsStream();\n    pipeline.coalesceStream = new CoalesceStream(options, pipeline.metadataStream);\n    pipeline.headOfPipeline = pipeline.aacStream;\n\n    pipeline.aacStream\n      .pipe(pipeline.audioTimestampRolloverStream)\n      .pipe(pipeline.adtsStream);\n    pipeline.aacStream\n      .pipe(pipeline.timedMetadataTimestampRolloverStream)\n      .pipe(pipeline.metadataStream)\n      .pipe(pipeline.coalesceStream);\n\n    pipeline.metadataStream.on('timestamp', function(frame) {\n      pipeline.aacStream.setTimestamp(frame.timeStamp);\n    });\n\n    pipeline.aacStream.on('data', function(data) {\n      if ((data.type !== 'timed-metadata' && data.type !== 'audio') || pipeline.audioSegmentStream) {\n        return;\n      }\n\n      audioTrack = audioTrack || {\n        timelineStartInfo: {\n          baseMediaDecodeTime: self.baseMediaDecodeTime\n        },\n        codec: 'adts',\n        type: 'audio'\n      };\n      // hook up the audio segment stream to the first track with aac data\n      pipeline.coalesceStream.numberOfTracks++;\n      pipeline.audioSegmentStream = new AudioSegmentStream(audioTrack, options);\n\n      pipeline.audioSegmentStream.on('timingInfo',\n        self.trigger.bind(self, 'audioTimingInfo'));\n\n      // Set up the final part of the audio pipeline\n      pipeline.adtsStream\n        .pipe(pipeline.audioSegmentStream)\n        .pipe(pipeline.coalesceStream);\n\n      // emit pmt info\n      self.trigger('trackinfo', {\n        hasAudio: !!audioTrack,\n        hasVideo: !!videoTrack\n      });\n    });\n\n    // Re-emit any data coming from the coalesce stream to the outside world\n    pipeline.coalesceStream.on('data', this.trigger.bind(this, 'data'));\n    // Let the consumer know we have finished flushing the entire pipeline\n    pipeline.coalesceStream.on('done', this.trigger.bind(this, 'done'));\n  };\n\n  this.setupTsPipeline = function() {\n    var pipeline = {};\n    this.transmuxPipeline_ = pipeline;\n\n    pipeline.type = 'ts';\n    pipeline.metadataStream = new m2ts.MetadataStream();\n\n    // set up the parsing pipeline\n    pipeline.packetStream = new m2ts.TransportPacketStream();\n    pipeline.parseStream = new m2ts.TransportParseStream();\n    pipeline.elementaryStream = new m2ts.ElementaryStream();\n    pipeline.timestampRolloverStream = new m2ts.TimestampRolloverStream();\n    pipeline.adtsStream = new AdtsStream();\n    pipeline.h264Stream = new H264Stream();\n    pipeline.captionStream = new m2ts.CaptionStream();\n    pipeline.coalesceStream = new CoalesceStream(options, pipeline.metadataStream);\n    pipeline.headOfPipeline = pipeline.packetStream;\n\n    // disassemble MPEG2-TS packets into elementary streams\n    pipeline.packetStream\n      .pipe(pipeline.parseStream)\n      .pipe(pipeline.elementaryStream)\n      .pipe(pipeline.timestampRolloverStream);\n\n    // !!THIS ORDER IS IMPORTANT!!\n    // demux the streams\n    pipeline.timestampRolloverStream\n      .pipe(pipeline.h264Stream);\n\n    pipeline.timestampRolloverStream\n      .pipe(pipeline.adtsStream);\n\n    pipeline.timestampRolloverStream\n      .pipe(pipeline.metadataStream)\n      .pipe(pipeline.coalesceStream);\n\n    // Hook up CEA-608/708 caption stream\n    pipeline.h264Stream.pipe(pipeline.captionStream)\n      .pipe(pipeline.coalesceStream);\n\n    pipeline.elementaryStream.on('data', function(data) {\n      var i;\n\n      if (data.type === 'metadata') {\n        i = data.tracks.length;\n\n        // scan the tracks listed in the metadata\n        while (i--) {\n          if (!videoTrack && data.tracks[i].type === 'video') {\n            videoTrack = data.tracks[i];\n            videoTrack.timelineStartInfo.baseMediaDecodeTime = self.baseMediaDecodeTime;\n          } else if (!audioTrack && data.tracks[i].type === 'audio') {\n            audioTrack = data.tracks[i];\n            audioTrack.timelineStartInfo.baseMediaDecodeTime = self.baseMediaDecodeTime;\n          }\n        }\n\n        // hook up the video segment stream to the first track with h264 data\n        if (videoTrack && !pipeline.videoSegmentStream) {\n          pipeline.coalesceStream.numberOfTracks++;\n          pipeline.videoSegmentStream = new VideoSegmentStream(videoTrack, options);\n\n          pipeline.videoSegmentStream.on('timelineStartInfo', function(timelineStartInfo) {\n            // When video emits timelineStartInfo data after a flush, we forward that\n            // info to the AudioSegmentStream, if it exists, because video timeline\n            // data takes precedence.  Do not do this if keepOriginalTimestamps is set,\n            // because this is a particularly subtle form of timestamp alteration.\n            if (audioTrack && !options.keepOriginalTimestamps) {\n              audioTrack.timelineStartInfo = timelineStartInfo;\n              // On the first segment we trim AAC frames that exist before the\n              // very earliest DTS we have seen in video because Chrome will\n              // interpret any video track with a baseMediaDecodeTime that is\n              // non-zero as a gap.\n              pipeline.audioSegmentStream.setEarliestDts(timelineStartInfo.dts - self.baseMediaDecodeTime);\n            }\n          });\n\n          pipeline.videoSegmentStream.on('processedGopsInfo',\n            self.trigger.bind(self, 'gopInfo'));\n          pipeline.videoSegmentStream.on('segmentTimingInfo',\n            self.trigger.bind(self, 'videoSegmentTimingInfo'));\n\n          pipeline.videoSegmentStream.on('baseMediaDecodeTime', function(baseMediaDecodeTime) {\n            if (audioTrack) {\n              pipeline.audioSegmentStream.setVideoBaseMediaDecodeTime(baseMediaDecodeTime);\n            }\n          });\n\n          pipeline.videoSegmentStream.on('timingInfo',\n            self.trigger.bind(self, 'videoTimingInfo'));\n\n          // Set up the final part of the video pipeline\n          pipeline.h264Stream\n            .pipe(pipeline.videoSegmentStream)\n            .pipe(pipeline.coalesceStream);\n        }\n\n        if (audioTrack && !pipeline.audioSegmentStream) {\n          // hook up the audio segment stream to the first track with aac data\n          pipeline.coalesceStream.numberOfTracks++;\n          pipeline.audioSegmentStream = new AudioSegmentStream(audioTrack, options);\n\n          pipeline.audioSegmentStream.on('timingInfo',\n            self.trigger.bind(self, 'audioTimingInfo'));\n\n          // Set up the final part of the audio pipeline\n          pipeline.adtsStream\n            .pipe(pipeline.audioSegmentStream)\n            .pipe(pipeline.coalesceStream);\n        }\n\n        // emit pmt info\n        self.trigger('trackinfo', {\n          hasAudio: !!audioTrack,\n          hasVideo: !!videoTrack\n        });\n      }\n    });\n\n    // Re-emit any data coming from the coalesce stream to the outside world\n    pipeline.coalesceStream.on('data', this.trigger.bind(this, 'data'));\n    pipeline.coalesceStream.on('id3Frame', function(id3Frame) {\n      id3Frame.dispatchType = pipeline.metadataStream.dispatchType;\n\n      self.trigger('id3Frame', id3Frame);\n    });\n    pipeline.coalesceStream.on('caption', this.trigger.bind(this, 'caption'));\n    // Let the consumer know we have finished flushing the entire pipeline\n    pipeline.coalesceStream.on('done', this.trigger.bind(this, 'done'));\n  };\n\n  // hook up the segment streams once track metadata is delivered\n  this.setBaseMediaDecodeTime = function(baseMediaDecodeTime) {\n    var pipeline = this.transmuxPipeline_;\n\n    if (!options.keepOriginalTimestamps) {\n      this.baseMediaDecodeTime = baseMediaDecodeTime;\n    }\n\n    if (audioTrack) {\n      audioTrack.timelineStartInfo.dts = undefined;\n      audioTrack.timelineStartInfo.pts = undefined;\n      trackDecodeInfo.clearDtsInfo(audioTrack);\n      if (pipeline.audioTimestampRolloverStream) {\n        pipeline.audioTimestampRolloverStream.discontinuity();\n      }\n    }\n    if (videoTrack) {\n      if (pipeline.videoSegmentStream) {\n        pipeline.videoSegmentStream.gopCache_ = [];\n      }\n      videoTrack.timelineStartInfo.dts = undefined;\n      videoTrack.timelineStartInfo.pts = undefined;\n      trackDecodeInfo.clearDtsInfo(videoTrack);\n      pipeline.captionStream.reset();\n    }\n\n    if (pipeline.timestampRolloverStream) {\n      pipeline.timestampRolloverStream.discontinuity();\n    }\n  };\n\n  this.setAudioAppendStart = function(timestamp) {\n    if (audioTrack) {\n      this.transmuxPipeline_.audioSegmentStream.setAudioAppendStart(timestamp);\n    }\n  };\n\n  this.setRemux = function(val) {\n    var pipeline = this.transmuxPipeline_;\n\n    options.remux = val;\n\n    if (pipeline && pipeline.coalesceStream) {\n      pipeline.coalesceStream.setRemux(val);\n    }\n  };\n\n  this.alignGopsWith = function(gopsToAlignWith) {\n    if (videoTrack && this.transmuxPipeline_.videoSegmentStream) {\n      this.transmuxPipeline_.videoSegmentStream.alignGopsWith(gopsToAlignWith);\n    }\n  };\n\n  // feed incoming data to the front of the parsing pipeline\n  this.push = function(data) {\n    if (hasFlushed) {\n      var isAac = isLikelyAacData(data);\n\n      if (isAac && this.transmuxPipeline_.type !== 'aac') {\n        this.setupAacPipeline();\n      } else if (!isAac && this.transmuxPipeline_.type !== 'ts') {\n        this.setupTsPipeline();\n      }\n      hasFlushed = false;\n    }\n    this.transmuxPipeline_.headOfPipeline.push(data);\n  };\n\n  // flush any buffered data\n  this.flush = function() {\n    hasFlushed = true;\n    // Start at the top of the pipeline and flush all pending work\n    this.transmuxPipeline_.headOfPipeline.flush();\n  };\n\n  this.endTimeline = function() {\n    this.transmuxPipeline_.headOfPipeline.endTimeline();\n  };\n\n  this.reset = function() {\n    if (this.transmuxPipeline_.headOfPipeline) {\n      this.transmuxPipeline_.headOfPipeline.reset();\n    }\n  };\n\n  // Caption data has to be reset when seeking outside buffered range\n  this.resetCaptions = function() {\n    if (this.transmuxPipeline_.captionStream) {\n      this.transmuxPipeline_.captionStream.reset();\n    }\n  };\n\n};\nTransmuxer.prototype = new Stream();\n\nmodule.exports = {\n  Transmuxer: Transmuxer,\n  VideoSegmentStream: VideoSegmentStream,\n  AudioSegmentStream: AudioSegmentStream,\n  AUDIO_PROPERTIES: AUDIO_PROPERTIES,\n  VIDEO_PROPERTIES: VIDEO_PROPERTIES,\n  // exported for testing\n  generateVideoSegmentTimingInfo: generateVideoSegmentTimingInfo\n};\n",
    "'use strict';\n\nvar Stream = require('../utils/stream.js');\nvar mp4 = require('../mp4/mp4-generator.js');\nvar audioFrameUtils = require('../mp4/audio-frame-utils');\nvar trackInfo = require('../mp4/track-decode-info.js');\nvar ONE_SECOND_IN_TS = require('../utils/clock').ONE_SECOND_IN_TS;\nvar AUDIO_PROPERTIES = require('../constants/audio-properties.js');\n\n/**\n * Constructs a single-track, ISO BMFF media segment from AAC data\n * events. The output of this stream can be fed to a SourceBuffer\n * configured with a suitable initialization segment.\n */\nvar AudioSegmentStream = function(track, options) {\n  var\n    adtsFrames = [],\n    sequenceNumber = 0,\n    earliestAllowedDts = 0,\n    audioAppendStartTs = 0,\n    videoBaseMediaDecodeTime = Infinity,\n    segmentStartPts = null,\n    segmentEndPts = null;\n\n  options = options || {};\n\n  AudioSegmentStream.prototype.init.call(this);\n\n  this.push = function(data) {\n    trackInfo.collectDtsInfo(track, data);\n\n    if (track) {\n      AUDIO_PROPERTIES.forEach(function(prop) {\n        track[prop] = data[prop];\n      });\n    }\n\n    // buffer audio data until end() is called\n    adtsFrames.push(data);\n  };\n\n  this.setEarliestDts = function(earliestDts) {\n    earliestAllowedDts = earliestDts;\n  };\n\n  this.setVideoBaseMediaDecodeTime = function(baseMediaDecodeTime) {\n    videoBaseMediaDecodeTime = baseMediaDecodeTime;\n  };\n\n  this.setAudioAppendStart = function(timestamp) {\n    audioAppendStartTs = timestamp;\n  };\n\n  this.processFrames_ = function() {\n    var\n      frames,\n      moof,\n      mdat,\n      boxes,\n      timingInfo;\n\n    // return early if no audio data has been observed\n    if (adtsFrames.length === 0) {\n      return;\n    }\n\n    frames = audioFrameUtils.trimAdtsFramesByEarliestDts(\n      adtsFrames, track, earliestAllowedDts);\n    if (frames.length === 0) {\n      // return early if the frames are all after the earliest allowed DTS\n      // TODO should we clear the adtsFrames?\n      return;\n    }\n\n    track.baseMediaDecodeTime = trackInfo.calculateTrackBaseMediaDecodeTime(\n      track, options.keepOriginalTimestamps);\n\n    audioFrameUtils.prefixWithSilence(\n      track, frames, audioAppendStartTs, videoBaseMediaDecodeTime);\n\n    // we have to build the index from byte locations to\n    // samples (that is, adts frames) in the audio data\n    track.samples = audioFrameUtils.generateSampleTable(frames);\n\n    // concatenate the audio data to constuct the mdat\n    mdat = mp4.mdat(audioFrameUtils.concatenateFrameData(frames));\n\n    adtsFrames = [];\n\n    moof = mp4.moof(sequenceNumber, [track]);\n\n    // bump the sequence number for next time\n    sequenceNumber++;\n\n    track.initSegment = mp4.initSegment([track]);\n\n    // it would be great to allocate this array up front instead of\n    // throwing away hundreds of media segment fragments\n    boxes = new Uint8Array(moof.byteLength + mdat.byteLength);\n\n    boxes.set(moof);\n    boxes.set(mdat, moof.byteLength);\n\n    trackInfo.clearDtsInfo(track);\n\n    if (segmentStartPts === null) {\n      segmentEndPts = segmentStartPts = frames[0].pts;\n    }\n\n    segmentEndPts += frames.length * (ONE_SECOND_IN_TS * 1024 / track.samplerate);\n\n    timingInfo = { start: segmentStartPts };\n\n    this.trigger('timingInfo', timingInfo);\n    this.trigger('data', {track: track, boxes: boxes});\n  };\n\n  this.flush = function() {\n    this.processFrames_();\n    // trigger final timing info\n    this.trigger('timingInfo', {\n      start: segmentStartPts,\n      end: segmentEndPts\n    });\n    this.resetTiming_();\n    this.trigger('done', 'AudioSegmentStream');\n  };\n\n  this.partialFlush = function() {\n    this.processFrames_();\n    this.trigger('partialdone', 'AudioSegmentStream');\n  };\n\n  this.endTimeline = function() {\n    this.flush();\n    this.trigger('endedtimeline', 'AudioSegmentStream');\n  };\n\n  this.resetTiming_ = function() {\n    trackInfo.clearDtsInfo(track);\n    segmentStartPts = null;\n    segmentEndPts = null;\n  };\n\n  this.reset = function() {\n    this.resetTiming_();\n    adtsFrames = [];\n    this.trigger('reset');\n  };\n};\n\nAudioSegmentStream.prototype = new Stream();\n\nmodule.exports = AudioSegmentStream;\n",
    "module.exports = {\n  Transmuxer: require('./transmuxer')\n};\n",
    "var Stream = require('../utils/stream.js');\nvar m2ts = require('../m2ts/m2ts.js');\nvar codecs = require('../codecs/index.js');\nvar AudioSegmentStream = require('./audio-segment-stream.js');\nvar VideoSegmentStream = require('./video-segment-stream.js');\nvar trackInfo = require('../mp4/track-decode-info.js');\nvar isLikelyAacData = require('../aac/utils').isLikelyAacData;\nvar AdtsStream = require('../codecs/adts');\nvar AacStream = require('../aac/index');\nvar clock = require('../utils/clock');\n\nvar createPipeline = function(object) {\n  object.prototype = new Stream();\n  object.prototype.init.call(object);\n\n  return object;\n};\n\nvar tsPipeline = function(options) {\n  var\n    pipeline = {\n      type: 'ts',\n      tracks: {\n        audio: null,\n        video: null\n      },\n      packet: new m2ts.TransportPacketStream(),\n      parse: new m2ts.TransportParseStream(),\n      elementary: new m2ts.ElementaryStream(),\n      timestampRollover: new m2ts.TimestampRolloverStream(),\n      adts: new codecs.Adts(),\n      h264: new codecs.h264.H264Stream(),\n      captionStream: new m2ts.CaptionStream(),\n      metadataStream: new m2ts.MetadataStream()\n  };\n\n  pipeline.headOfPipeline = pipeline.packet;\n\n  // Transport Stream\n  pipeline.packet\n    .pipe(pipeline.parse)\n    .pipe(pipeline.elementary)\n    .pipe(pipeline.timestampRollover);\n\n  // H264\n  pipeline.timestampRollover\n    .pipe(pipeline.h264);\n\n  // Hook up CEA-608/708 caption stream\n  pipeline.h264\n    .pipe(pipeline.captionStream);\n\n  pipeline.timestampRollover\n    .pipe(pipeline.metadataStream);\n\n  // ADTS\n  pipeline.timestampRollover\n    .pipe(pipeline.adts);\n\n  pipeline.elementary.on('data', function(data) {\n    if (data.type !== 'metadata') {\n      return;\n    }\n\n    for (var i = 0; i < data.tracks.length; i++) {\n      if (!pipeline.tracks[data.tracks[i].type]) {\n        pipeline.tracks[data.tracks[i].type] = data.tracks[i];\n        pipeline.tracks[data.tracks[i].type].timelineStartInfo.baseMediaDecodeTime = options.baseMediaDecodeTime;\n      }\n    }\n\n    if (pipeline.tracks.video && !pipeline.videoSegmentStream) {\n      pipeline.videoSegmentStream = new VideoSegmentStream(pipeline.tracks.video, options);\n\n      pipeline.videoSegmentStream.on('timelineStartInfo', function(timelineStartInfo) {\n        if (pipeline.tracks.audio && !options.keepOriginalTimestamps) {\n          pipeline.audioSegmentStream.setEarliestDts(timelineStartInfo.dts - options.baseMediaDecodeTime);\n        }\n      });\n\n      pipeline.videoSegmentStream.on('timingInfo',\n                                     pipeline.trigger.bind(pipeline, 'videoTimingInfo'));\n\n      pipeline.videoSegmentStream.on('data', function(data) {\n        pipeline.trigger('data', {\n          type: 'video',\n          data: data\n        });\n      });\n\n      pipeline.videoSegmentStream.on('done',\n                                     pipeline.trigger.bind(pipeline, 'done'));\n      pipeline.videoSegmentStream.on('partialdone',\n                                     pipeline.trigger.bind(pipeline, 'partialdone'));\n      pipeline.videoSegmentStream.on('endedtimeline',\n                                     pipeline.trigger.bind(pipeline, 'endedtimeline'));\n\n      pipeline.h264\n        .pipe(pipeline.videoSegmentStream);\n    }\n\n    if (pipeline.tracks.audio && !pipeline.audioSegmentStream) {\n      pipeline.audioSegmentStream = new AudioSegmentStream(pipeline.tracks.audio, options);\n\n      pipeline.audioSegmentStream.on('data', function(data) {\n        pipeline.trigger('data', {\n          type: 'audio',\n          data: data\n        });\n      });\n\n      pipeline.audioSegmentStream.on('done',\n                                     pipeline.trigger.bind(pipeline, 'done'));\n      pipeline.audioSegmentStream.on('partialdone',\n                                     pipeline.trigger.bind(pipeline, 'partialdone'));\n      pipeline.audioSegmentStream.on('endedtimeline',\n                                     pipeline.trigger.bind(pipeline, 'endedtimeline'));\n\n      pipeline.audioSegmentStream.on('timingInfo',\n                                     pipeline.trigger.bind(pipeline, 'audioTimingInfo'));\n\n      pipeline.adts\n        .pipe(pipeline.audioSegmentStream);\n    }\n\n    // emit pmt info\n    pipeline.trigger('trackinfo', {\n      hasAudio: !!pipeline.tracks.audio,\n      hasVideo: !!pipeline.tracks.video\n    });\n  });\n\n  pipeline.captionStream.on('data', function(caption) {\n    var timelineStartPts;\n\n    if (pipeline.tracks.video) {\n      timelineStartPts = pipeline.tracks.video.timelineStartInfo.pts || 0;\n    } else {\n      // This will only happen if we encounter caption packets before\n      // video data in a segment. This is an unusual/unlikely scenario,\n      // so we assume the timeline starts at zero for now.\n      timelineStartPts = 0;\n    }\n\n    // Translate caption PTS times into second offsets into the\n    // video timeline for the segment\n    caption.startTime = clock.metadataTsToSeconds(caption.startPts, timelineStartPts, options.keepOriginalTimestamps);\n    caption.endTime = clock.metadataTsToSeconds(caption.endPts, timelineStartPts, options.keepOriginalTimestamps);\n\n    pipeline.trigger('caption', caption);\n  });\n\n  pipeline = createPipeline(pipeline);\n\n  pipeline.metadataStream.on('data', pipeline.trigger.bind(pipeline, 'id3Frame'));\n\n  return pipeline;\n};\n\nvar aacPipeline = function(options) {\n  var\n    pipeline = {\n    type: 'aac',\n    tracks: {\n      audio: null\n    },\n    metadataStream: new m2ts.MetadataStream(),\n    aacStream: new AacStream(),\n    audioRollover: new m2ts.TimestampRolloverStream('audio'),\n    timedMetadataRollover: new m2ts.TimestampRolloverStream('timed-metadata'),\n    adtsStream: new AdtsStream(true)\n  };\n\n  // set up the parsing pipeline\n  pipeline.headOfPipeline = pipeline.aacStream;\n\n  pipeline.aacStream\n    .pipe(pipeline.audioRollover)\n    .pipe(pipeline.adtsStream);\n  pipeline.aacStream\n    .pipe(pipeline.timedMetadataRollover)\n    .pipe(pipeline.metadataStream);\n\n  pipeline.metadataStream.on('timestamp', function(frame) {\n    pipeline.aacStream.setTimestamp(frame.timeStamp);\n  });\n\n  pipeline.aacStream.on('data', function(data) {\n    if ((data.type !== 'timed-metadata' && data.type !== 'audio') || pipeline.audioSegmentStream) {\n      return;\n    }\n\n    pipeline.tracks.audio = pipeline.tracks.audio || {\n      timelineStartInfo: {\n        baseMediaDecodeTime: options.baseMediaDecodeTime\n      },\n      codec: 'adts',\n      type: 'audio'\n    };\n\n    // hook up the audio segment stream to the first track with aac data\n    pipeline.audioSegmentStream = new AudioSegmentStream(pipeline.tracks.audio, options);\n\n    pipeline.audioSegmentStream.on('data', function(data) {\n      pipeline.trigger('data', {\n        type: 'audio',\n        data: data\n      });\n    });\n\n    pipeline.audioSegmentStream.on('partialdone',\n                                   pipeline.trigger.bind(pipeline, 'partialdone'));\n    pipeline.audioSegmentStream.on('done', pipeline.trigger.bind(pipeline, 'done'));\n    pipeline.audioSegmentStream.on('endedtimeline',\n                                   pipeline.trigger.bind(pipeline, 'endedtimeline'));\n    pipeline.audioSegmentStream.on('timingInfo',\n                                   pipeline.trigger.bind(pipeline, 'audioTimingInfo'));\n\n    // Set up the final part of the audio pipeline\n    pipeline.adtsStream\n      .pipe(pipeline.audioSegmentStream);\n\n    pipeline.trigger('trackinfo', {\n      hasAudio: !!pipeline.tracks.audio,\n      hasVideo: !!pipeline.tracks.video\n    });\n  });\n\n  // set the pipeline up as a stream before binding to get access to the trigger function\n  pipeline = createPipeline(pipeline);\n\n  pipeline.metadataStream.on('data', pipeline.trigger.bind(pipeline, 'id3Frame'));\n\n  return pipeline;\n};\n\nvar setupPipelineListeners = function(pipeline, transmuxer) {\n  pipeline.on('data', transmuxer.trigger.bind(transmuxer, 'data'));\n  pipeline.on('done', transmuxer.trigger.bind(transmuxer, 'done'));\n  pipeline.on('partialdone', transmuxer.trigger.bind(transmuxer, 'partialdone'));\n  pipeline.on('endedtimeline', transmuxer.trigger.bind(transmuxer, 'endedtimeline'));\n  pipeline.on('audioTimingInfo', transmuxer.trigger.bind(transmuxer, 'audioTimingInfo'));\n  pipeline.on('videoTimingInfo', transmuxer.trigger.bind(transmuxer, 'videoTimingInfo'));\n  pipeline.on('trackinfo', transmuxer.trigger.bind(transmuxer, 'trackinfo'));\n  pipeline.on('id3Frame', function(event) {\n    // add this to every single emitted segment even though it's only needed for the first\n    event.dispatchType = pipeline.metadataStream.dispatchType;\n    // keep original time, can be adjusted if needed at a higher level\n    event.cueTime = clock.videoTsToSeconds(event.pts);\n\n    transmuxer.trigger('id3Frame', event);\n  });\n  pipeline.on('caption', function(event) {\n    transmuxer.trigger('caption', event);\n  });\n};\n\nvar Transmuxer = function(options) {\n  var\n    pipeline = null,\n    hasFlushed = true;\n\n  options = options || {};\n\n  Transmuxer.prototype.init.call(this);\n  options.baseMediaDecodeTime = options.baseMediaDecodeTime || 0;\n\n  this.push = function(bytes) {\n    if (hasFlushed) {\n      var isAac = isLikelyAacData(bytes);\n\n      if (isAac && (!pipeline || pipeline.type !== 'aac')) {\n        pipeline = aacPipeline(options);\n        setupPipelineListeners(pipeline, this);\n      } else if (!isAac && (!pipeline || pipeline.type !== 'ts')) {\n        pipeline = tsPipeline(options);\n        setupPipelineListeners(pipeline, this);\n      }\n      hasFlushed = false;\n    }\n\n    pipeline.headOfPipeline.push(bytes);\n  };\n\n  this.flush = function() {\n    if (!pipeline) {\n      return;\n    }\n\n    hasFlushed = true;\n    pipeline.headOfPipeline.flush();\n  };\n\n  this.partialFlush = function() {\n    if (!pipeline) {\n      return;\n    }\n\n    pipeline.headOfPipeline.partialFlush();\n  };\n\n  this.endTimeline = function() {\n    if (!pipeline) {\n      return;\n    }\n\n    pipeline.headOfPipeline.endTimeline();\n  };\n\n  this.reset = function() {\n    if (!pipeline) {\n      return;\n    }\n\n    pipeline.headOfPipeline.reset();\n  };\n\n  this.setBaseMediaDecodeTime = function(baseMediaDecodeTime) {\n    if (!options.keepOriginalTimestamps) {\n      options.baseMediaDecodeTime = baseMediaDecodeTime;\n    }\n\n    if (!pipeline) {\n      return;\n    }\n\n    if (pipeline.tracks.audio) {\n      pipeline.tracks.audio.timelineStartInfo.dts = undefined;\n      pipeline.tracks.audio.timelineStartInfo.pts = undefined;\n      trackInfo.clearDtsInfo(pipeline.tracks.audio);\n      if (pipeline.audioRollover) {\n        pipeline.audioRollover.discontinuity();\n      }\n    }\n    if (pipeline.tracks.video) {\n      if (pipeline.videoSegmentStream) {\n        pipeline.videoSegmentStream.gopCache_ = [];\n      }\n      pipeline.tracks.video.timelineStartInfo.dts = undefined;\n      pipeline.tracks.video.timelineStartInfo.pts = undefined;\n      trackInfo.clearDtsInfo(pipeline.tracks.video);\n      // pipeline.captionStream.reset();\n    }\n\n    if (pipeline.timestampRollover) {\n      pipeline.timestampRollover.discontinuity();\n\n    }\n  };\n\n  this.setRemux = function(val) {\n    options.remux = val;\n\n    if (pipeline && pipeline.coalesceStream) {\n      pipeline.coalesceStream.setRemux(val);\n    }\n  };\n\n\n  this.setAudioAppendStart = function(audioAppendStart) {\n    if (!pipeline || !pipeline.tracks.audio || !pipeline.audioSegmentStream) {\n      return;\n    }\n\n    pipeline.audioSegmentStream.setAudioAppendStart(audioAppendStart);\n  };\n\n  // TODO GOP alignment support\n  // Support may be a bit trickier than with full segment appends, as GOPs may be split\n  // and processed in a more granular fashion\n  this.alignGopsWith = function(gopsToAlignWith) {\n    return;\n  };\n};\n\nTransmuxer.prototype = new Stream();\n\nmodule.exports = Transmuxer;\n",
    "/**\n * Constructs a single-track, ISO BMFF media segment from H264 data\n * events. The output of this stream can be fed to a SourceBuffer\n * configured with a suitable initialization segment.\n * @param track {object} track metadata configuration\n * @param options {object} transmuxer options object\n * @param options.alignGopsAtEnd {boolean} If true, start from the end of the\n *        gopsToAlignWith list when attempting to align gop pts\n */\n'use strict';\n\nvar Stream = require('../utils/stream.js');\nvar mp4 = require('../mp4/mp4-generator.js');\nvar trackInfo = require('../mp4/track-decode-info.js');\nvar frameUtils = require('../mp4/frame-utils');\nvar VIDEO_PROPERTIES = require('../constants/video-properties.js');\n\nvar VideoSegmentStream = function(track, options) {\n  var\n    sequenceNumber = 0,\n    nalUnits = [],\n    frameCache = [],\n    // gopsToAlignWith = [],\n    config,\n    pps,\n    segmentStartPts = null,\n    segmentEndPts = null,\n    gops,\n    ensureNextFrameIsKeyFrame = true;\n\n  options = options || {};\n\n  VideoSegmentStream.prototype.init.call(this);\n\n  this.push = function(nalUnit) {\n    trackInfo.collectDtsInfo(track, nalUnit);\n    if (typeof track.timelineStartInfo.dts === 'undefined') {\n      track.timelineStartInfo.dts = nalUnit.dts;\n    }\n\n    // record the track config\n    if (nalUnit.nalUnitType === 'seq_parameter_set_rbsp' && !config) {\n      config = nalUnit.config;\n      track.sps = [nalUnit.data];\n\n      VIDEO_PROPERTIES.forEach(function(prop) {\n        track[prop] = config[prop];\n      }, this);\n    }\n\n    if (nalUnit.nalUnitType === 'pic_parameter_set_rbsp' &&\n        !pps) {\n      pps = nalUnit.data;\n      track.pps = [nalUnit.data];\n    }\n\n    // buffer video until flush() is called\n    nalUnits.push(nalUnit);\n  };\n\n  this.processNals_ = function(cacheLastFrame) {\n    var i;\n\n    nalUnits = frameCache.concat(nalUnits);\n\n    // Throw away nalUnits at the start of the byte stream until\n    // we find the first AUD\n    while (nalUnits.length) {\n      if (nalUnits[0].nalUnitType === 'access_unit_delimiter_rbsp') {\n        break;\n      }\n      nalUnits.shift();\n    }\n\n    // Return early if no video data has been observed\n    if (nalUnits.length === 0) {\n      return;\n    }\n\n    var frames = frameUtils.groupNalsIntoFrames(nalUnits);\n\n    if (!frames.length) {\n      return;\n    }\n\n    // note that the frame cache may also protect us from cases where we haven't\n    // pushed data for the entire first or last frame yet\n    frameCache = frames[frames.length - 1];\n\n    if (cacheLastFrame) {\n      frames.pop();\n      frames.duration -= frameCache.duration;\n      frames.nalCount -= frameCache.length;\n      frames.byteLength -= frameCache.byteLength;\n    }\n\n    if (!frames.length) {\n      nalUnits = [];\n      return;\n    }\n\n    this.trigger('timelineStartInfo', track.timelineStartInfo);\n\n    if (ensureNextFrameIsKeyFrame) {\n      gops = frameUtils.groupFramesIntoGops(frames);\n\n      if (!gops[0][0].keyFrame) {\n        gops = frameUtils.extendFirstKeyFrame(gops);\n\n        if (!gops[0][0].keyFrame) {\n          // we haven't yet gotten a key frame, so reset nal units to wait for more nal\n          // units\n          nalUnits = ([].concat.apply([], frames)).concat(frameCache);\n          frameCache = [];\n          return;\n        }\n\n        frames = [].concat.apply([], gops);\n        frames.duration = gops.duration;\n      }\n      ensureNextFrameIsKeyFrame = false;\n    }\n\n    if (segmentStartPts === null) {\n      segmentStartPts = frames[0].pts;\n      segmentEndPts = segmentStartPts;\n    }\n\n    segmentEndPts += frames.duration;\n\n    this.trigger('timingInfo', {\n      start: segmentStartPts,\n      end: segmentEndPts\n    });\n\n    for (i = 0; i < frames.length; i++) {\n      var frame = frames[i];\n\n      track.samples = frameUtils.generateSampleTableForFrame(frame);\n\n      var mdat = mp4.mdat(frameUtils.concatenateNalDataForFrame(frame));\n\n      trackInfo.clearDtsInfo(track);\n      trackInfo.collectDtsInfo(track, frame);\n\n      track.baseMediaDecodeTime = trackInfo.calculateTrackBaseMediaDecodeTime(\n        track, options.keepOriginalTimestamps);\n\n      var moof = mp4.moof(sequenceNumber, [track]);\n\n      sequenceNumber++;\n\n      track.initSegment = mp4.initSegment([track]);\n\n      var boxes = new Uint8Array(moof.byteLength + mdat.byteLength);\n\n      boxes.set(moof);\n      boxes.set(mdat, moof.byteLength);\n\n      this.trigger('data', {\n        track: track,\n        boxes: boxes,\n        sequence: sequenceNumber,\n        videoFrameDts: frame.dts,\n        videoFramePts: frame.pts\n      });\n    }\n\n    nalUnits = [];\n  };\n\n  this.resetTimingAndConfig_ = function() {\n    config = undefined;\n    pps = undefined;\n    segmentStartPts = null;\n    segmentEndPts = null;\n  };\n\n  this.partialFlush = function() {\n    this.processNals_(true);\n    this.trigger('partialdone', 'VideoSegmentStream');\n  };\n\n  this.flush = function() {\n    this.processNals_(false);\n    // reset config and pps because they may differ across segments\n    // for instance, when we are rendition switching\n    this.resetTimingAndConfig_();\n    this.trigger('done', 'VideoSegmentStream');\n  };\n\n  this.endTimeline = function() {\n    this.flush();\n    this.trigger('endedtimeline', 'VideoSegmentStream');\n  };\n\n  this.reset = function() {\n    this.resetTimingAndConfig_();\n    frameCache = [];\n    nalUnits = [];\n    ensureNextFrameIsKeyFrame = true;\n    this.trigger('reset');\n  };\n};\n\nVideoSegmentStream.prototype = new Stream();\n\nmodule.exports = VideoSegmentStream;\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * Reads in-band caption information from a video elementary\n * stream. Captions must follow the CEA-708 standard for injection\n * into an MPEG-2 transport streams.\n * @see https://en.wikipedia.org/wiki/CEA-708\n * @see https://www.gpo.gov/fdsys/pkg/CFR-2007-title47-vol1/pdf/CFR-2007-title47-vol1-sec15-119.pdf\n */\n\n'use strict';\n\n// Supplemental enhancement information (SEI) NAL units have a\n// payload type field to indicate how they are to be\n// interpreted. CEAS-708 caption content is always transmitted with\n// payload type 0x04.\nvar USER_DATA_REGISTERED_ITU_T_T35 = 4,\n    RBSP_TRAILING_BITS = 128;\n\n/**\n  * Parse a supplemental enhancement information (SEI) NAL unit.\n  * Stops parsing once a message of type ITU T T35 has been found.\n  *\n  * @param bytes {Uint8Array} the bytes of a SEI NAL unit\n  * @return {object} the parsed SEI payload\n  * @see Rec. ITU-T H.264, 7.3.2.3.1\n  */\nvar parseSei = function(bytes) {\n  var\n    i = 0,\n    result = {\n      payloadType: -1,\n      payloadSize: 0\n    },\n    payloadType = 0,\n    payloadSize = 0;\n\n  // go through the sei_rbsp parsing each each individual sei_message\n  while (i < bytes.byteLength) {\n    // stop once we have hit the end of the sei_rbsp\n    if (bytes[i] === RBSP_TRAILING_BITS) {\n      break;\n    }\n\n    // Parse payload type\n    while (bytes[i] === 0xFF) {\n      payloadType += 255;\n      i++;\n    }\n    payloadType += bytes[i++];\n\n    // Parse payload size\n    while (bytes[i] === 0xFF) {\n      payloadSize += 255;\n      i++;\n    }\n    payloadSize += bytes[i++];\n\n    // this sei_message is a 608/708 caption so save it and break\n    // there can only ever be one caption message in a frame's sei\n    if (!result.payload && payloadType === USER_DATA_REGISTERED_ITU_T_T35) {\n      var userIdentifier = String.fromCharCode(\n        bytes[i + 3],\n        bytes[i + 4],\n        bytes[i + 5],\n        bytes[i + 6]);\n\n      if (userIdentifier === 'GA94') {\n        result.payloadType = payloadType;\n        result.payloadSize = payloadSize;\n        result.payload = bytes.subarray(i, i + payloadSize);\n        break;\n      } else {\n        result.payload = void 0;\n      }\n    }\n\n    // skip the payload and parse the next message\n    i += payloadSize;\n    payloadType = 0;\n    payloadSize = 0;\n  }\n\n  return result;\n};\n\n// see ANSI/SCTE 128-1 (2013), section 8.1\nvar parseUserData = function(sei) {\n  // itu_t_t35_contry_code must be 181 (United States) for\n  // captions\n  if (sei.payload[0] !== 181) {\n    return null;\n  }\n\n  // itu_t_t35_provider_code should be 49 (ATSC) for captions\n  if (((sei.payload[1] << 8) | sei.payload[2]) !== 49) {\n    return null;\n  }\n\n  // the user_identifier should be \"GA94\" to indicate ATSC1 data\n  if (String.fromCharCode(sei.payload[3],\n                          sei.payload[4],\n                          sei.payload[5],\n                          sei.payload[6]) !== 'GA94') {\n    return null;\n  }\n\n  // finally, user_data_type_code should be 0x03 for caption data\n  if (sei.payload[7] !== 0x03) {\n    return null;\n  }\n\n  // return the user_data_type_structure and strip the trailing\n  // marker bits\n  return sei.payload.subarray(8, sei.payload.length - 1);\n};\n\n// see CEA-708-D, section 4.4\nvar parseCaptionPackets = function(pts, userData) {\n  var results = [], i, count, offset, data;\n\n  // if this is just filler, return immediately\n  if (!(userData[0] & 0x40)) {\n    return results;\n  }\n\n  // parse out the cc_data_1 and cc_data_2 fields\n  count = userData[0] & 0x1f;\n  for (i = 0; i < count; i++) {\n    offset = i * 3;\n    data = {\n      type: userData[offset + 2] & 0x03,\n      pts: pts\n    };\n\n    // capture cc data when cc_valid is 1\n    if (userData[offset + 2] & 0x04) {\n      data.ccData = (userData[offset + 3] << 8) | userData[offset + 4];\n      results.push(data);\n    }\n  }\n  return results;\n};\n\nvar discardEmulationPreventionBytes = function(data) {\n    var\n      length = data.byteLength,\n      emulationPreventionBytesPositions = [],\n      i = 1,\n      newLength, newData;\n\n    // Find all `Emulation Prevention Bytes`\n    while (i < length - 2) {\n      if (data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 0x03) {\n        emulationPreventionBytesPositions.push(i + 2);\n        i += 2;\n      } else {\n        i++;\n      }\n    }\n\n    // If no Emulation Prevention Bytes were found just return the original\n    // array\n    if (emulationPreventionBytesPositions.length === 0) {\n      return data;\n    }\n\n    // Create a new array to hold the NAL unit data\n    newLength = length - emulationPreventionBytesPositions.length;\n    newData = new Uint8Array(newLength);\n    var sourceIndex = 0;\n\n    for (i = 0; i < newLength; sourceIndex++, i++) {\n      if (sourceIndex === emulationPreventionBytesPositions[0]) {\n        // Skip this byte\n        sourceIndex++;\n        // Remove this position index\n        emulationPreventionBytesPositions.shift();\n      }\n      newData[i] = data[sourceIndex];\n    }\n\n    return newData;\n};\n\n// exports\nmodule.exports = {\n  parseSei: parseSei,\n  parseUserData: parseUserData,\n  parseCaptionPackets: parseCaptionPackets,\n  discardEmulationPreventionBytes: discardEmulationPreventionBytes,\n  USER_DATA_REGISTERED_ITU_T_T35: USER_DATA_REGISTERED_ITU_T_T35\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\n'use strict';\n\nvar\n  tagTypes = {\n    0x08: 'audio',\n    0x09: 'video',\n    0x12: 'metadata'\n  },\n  hex = function(val) {\n    return '0x' + ('00' + val.toString(16)).slice(-2).toUpperCase();\n  },\n  hexStringList = function(data) {\n    var arr = [], i;\n\n    while (data.byteLength > 0) {\n      i = 0;\n      arr.push(hex(data[i++]));\n      data = data.subarray(i);\n    }\n    return arr.join(' ');\n  },\n  parseAVCTag = function(tag, obj) {\n    var\n      avcPacketTypes = [\n        'AVC Sequence Header',\n        'AVC NALU',\n        'AVC End-of-Sequence'\n      ],\n      compositionTime = (tag[1] & parseInt('01111111', 2) << 16) | (tag[2] << 8) | tag[3];\n\n    obj = obj || {};\n\n    obj.avcPacketType = avcPacketTypes[tag[0]];\n    obj.CompositionTime = (tag[1] & parseInt('10000000', 2)) ? -compositionTime : compositionTime;\n\n    if (tag[0] === 1) {\n      obj.nalUnitTypeRaw = hexStringList(tag.subarray(4, 100));\n    } else {\n      obj.data = hexStringList(tag.subarray(4));\n    }\n\n    return obj;\n  },\n  parseVideoTag = function(tag, obj) {\n    var\n      frameTypes = [\n        'Unknown',\n        'Keyframe (for AVC, a seekable frame)',\n        'Inter frame (for AVC, a nonseekable frame)',\n        'Disposable inter frame (H.263 only)',\n        'Generated keyframe (reserved for server use only)',\n        'Video info/command frame'\n      ],\n      codecID = tag[0] & parseInt('00001111', 2);\n\n    obj = obj || {};\n\n    obj.frameType = frameTypes[(tag[0] & parseInt('11110000', 2)) >>> 4];\n    obj.codecID = codecID;\n\n    if (codecID === 7) {\n      return parseAVCTag(tag.subarray(1), obj);\n    }\n    return obj;\n  },\n  parseAACTag = function(tag, obj) {\n    var packetTypes = [\n      'AAC Sequence Header',\n      'AAC Raw'\n    ];\n\n    obj = obj || {};\n\n    obj.aacPacketType = packetTypes[tag[0]];\n    obj.data = hexStringList(tag.subarray(1));\n\n    return obj;\n  },\n  parseAudioTag = function(tag, obj) {\n    var\n      formatTable = [\n        'Linear PCM, platform endian',\n        'ADPCM',\n        'MP3',\n        'Linear PCM, little endian',\n        'Nellymoser 16-kHz mono',\n        'Nellymoser 8-kHz mono',\n        'Nellymoser',\n        'G.711 A-law logarithmic PCM',\n        'G.711 mu-law logarithmic PCM',\n        'reserved',\n        'AAC',\n        'Speex',\n        'MP3 8-Khz',\n        'Device-specific sound'\n      ],\n      samplingRateTable = [\n        '5.5-kHz',\n        '11-kHz',\n        '22-kHz',\n        '44-kHz'\n      ],\n      soundFormat = (tag[0] & parseInt('11110000', 2)) >>> 4;\n\n    obj = obj || {};\n\n    obj.soundFormat = formatTable[soundFormat];\n    obj.soundRate = samplingRateTable[(tag[0] & parseInt('00001100', 2)) >>> 2];\n    obj.soundSize = ((tag[0] & parseInt('00000010', 2)) >>> 1) ? '16-bit' : '8-bit';\n    obj.soundType = (tag[0] & parseInt('00000001', 2)) ? 'Stereo' : 'Mono';\n\n    if (soundFormat === 10) {\n      return parseAACTag(tag.subarray(1), obj);\n    }\n    return obj;\n  },\n  parseGenericTag = function(tag) {\n    return {\n      tagType: tagTypes[tag[0]],\n      dataSize: (tag[1] << 16) | (tag[2] << 8) | tag[3],\n      timestamp: (tag[7] << 24) | (tag[4] << 16) | (tag[5] << 8) | tag[6],\n      streamID: (tag[8] << 16) | (tag[9] << 8) | tag[10]\n    };\n  },\n  inspectFlvTag = function(tag) {\n    var header = parseGenericTag(tag);\n    switch (tag[0]) {\n      case 0x08:\n        parseAudioTag(tag.subarray(11), header);\n        break;\n      case 0x09:\n        parseVideoTag(tag.subarray(11), header);\n        break;\n      case 0x12:\n    }\n    return header;\n  },\n  inspectFlv = function(bytes) {\n    var i = 9, // header\n        dataSize,\n        parsedResults = [],\n        tag;\n\n    // traverse the tags\n    i += 4; // skip previous tag size\n    while (i < bytes.byteLength) {\n      dataSize = bytes[i + 1] << 16;\n      dataSize |= bytes[i + 2] << 8;\n      dataSize |= bytes[i + 3];\n      dataSize += 11;\n\n      tag = bytes.subarray(i, i + dataSize);\n      parsedResults.push(inspectFlvTag(tag));\n      i += dataSize + 4;\n    }\n    return parsedResults;\n  },\n  textifyFlv = function(flvTagArray) {\n    return JSON.stringify(flvTagArray, null, 2);\n  };\n\nmodule.exports = {\n  inspectTag: inspectFlvTag,\n  inspect: inspectFlv,\n  textify: textifyFlv\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * Parse the internal MP4 structure into an equivalent javascript\n * object.\n */\n'use strict';\n\nvar\n  inspectMp4,\n  textifyMp4,\n  parseMp4Date = function(seconds) {\n    return new Date(seconds * 1000 - 2082844800000);\n  },\n  parseType = require('../mp4/parse-type'),\n  findBox = require('../mp4/find-box'),\n  nalParse = function(avcStream) {\n    var\n      avcView = new DataView(avcStream.buffer, avcStream.byteOffset, avcStream.byteLength),\n      result = [],\n      i,\n      length;\n    for (i = 0; i + 4 < avcStream.length; i += length) {\n      length = avcView.getUint32(i);\n      i += 4;\n\n      // bail if this doesn't appear to be an H264 stream\n      if (length <= 0) {\n        result.push('<span style=\\'color:red;\\'>MALFORMED DATA</span>');\n        continue;\n      }\n\n      switch (avcStream[i] & 0x1F) {\n      case 0x01:\n        result.push('slice_layer_without_partitioning_rbsp');\n        break;\n      case 0x05:\n        result.push('slice_layer_without_partitioning_rbsp_idr');\n        break;\n      case 0x06:\n        result.push('sei_rbsp');\n        break;\n      case 0x07:\n        result.push('seq_parameter_set_rbsp');\n        break;\n      case 0x08:\n        result.push('pic_parameter_set_rbsp');\n        break;\n      case 0x09:\n        result.push('access_unit_delimiter_rbsp');\n        break;\n      default:\n        result.push('UNKNOWN NAL - ' + avcStream[i] & 0x1F);\n        break;\n      }\n    }\n    return result;\n  },\n\n  // registry of handlers for individual mp4 box types\n  parse = {\n    // codingname, not a first-class box type. stsd entries share the\n    // same format as real boxes so the parsing infrastructure can be\n    // shared\n    avc1: function(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength);\n      return {\n        dataReferenceIndex: view.getUint16(6),\n        width: view.getUint16(24),\n        height: view.getUint16(26),\n        horizresolution: view.getUint16(28) + (view.getUint16(30) / 16),\n        vertresolution: view.getUint16(32) + (view.getUint16(34) / 16),\n        frameCount: view.getUint16(40),\n        depth: view.getUint16(74),\n        config: inspectMp4(data.subarray(78, data.byteLength))\n      };\n    },\n    avcC: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        result = {\n          configurationVersion: data[0],\n          avcProfileIndication: data[1],\n          profileCompatibility: data[2],\n          avcLevelIndication: data[3],\n          lengthSizeMinusOne: data[4] & 0x03,\n          sps: [],\n          pps: []\n        },\n        numOfSequenceParameterSets = data[5] & 0x1f,\n        numOfPictureParameterSets,\n        nalSize,\n        offset,\n        i;\n\n      // iterate past any SPSs\n      offset = 6;\n      for (i = 0; i < numOfSequenceParameterSets; i++) {\n        nalSize = view.getUint16(offset);\n        offset += 2;\n        result.sps.push(new Uint8Array(data.subarray(offset, offset + nalSize)));\n        offset += nalSize;\n      }\n      // iterate past any PPSs\n      numOfPictureParameterSets = data[offset];\n      offset++;\n      for (i = 0; i < numOfPictureParameterSets; i++) {\n        nalSize = view.getUint16(offset);\n        offset += 2;\n        result.pps.push(new Uint8Array(data.subarray(offset, offset + nalSize)));\n        offset += nalSize;\n      }\n      return result;\n    },\n    btrt: function(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength);\n      return {\n        bufferSizeDB: view.getUint32(0),\n        maxBitrate: view.getUint32(4),\n        avgBitrate: view.getUint32(8)\n      };\n    },\n    esds: function(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        esId: (data[6] << 8) | data[7],\n        streamPriority: data[8] & 0x1f,\n        decoderConfig: {\n          objectProfileIndication: data[11],\n          streamType: (data[12] >>> 2) & 0x3f,\n          bufferSize: (data[13] << 16) | (data[14] << 8) | data[15],\n          maxBitrate: (data[16] << 24) |\n            (data[17] << 16) |\n            (data[18] <<  8) |\n            data[19],\n          avgBitrate: (data[20] << 24) |\n            (data[21] << 16) |\n            (data[22] <<  8) |\n            data[23],\n          decoderConfigDescriptor: {\n            tag: data[24],\n            length: data[25],\n            audioObjectType: (data[26] >>> 3) & 0x1f,\n            samplingFrequencyIndex: ((data[26] & 0x07) << 1) |\n              ((data[27] >>> 7) & 0x01),\n            channelConfiguration: (data[27] >>> 3) & 0x0f\n          }\n        }\n      };\n    },\n    ftyp: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        result = {\n          majorBrand: parseType(data.subarray(0, 4)),\n          minorVersion: view.getUint32(4),\n          compatibleBrands: []\n        },\n        i = 8;\n      while (i < data.byteLength) {\n        result.compatibleBrands.push(parseType(data.subarray(i, i + 4)));\n        i += 4;\n      }\n      return result;\n    },\n    dinf: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    dref: function(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        dataReferences: inspectMp4(data.subarray(8))\n      };\n    },\n    hdlr: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        result = {\n          version: view.getUint8(0),\n          flags: new Uint8Array(data.subarray(1, 4)),\n          handlerType: parseType(data.subarray(8, 12)),\n          name: ''\n        },\n        i = 8;\n\n      // parse out the name field\n      for (i = 24; i < data.byteLength; i++) {\n        if (data[i] === 0x00) {\n          // the name field is null-terminated\n          i++;\n          break;\n        }\n        result.name += String.fromCharCode(data[i]);\n      }\n      // decode UTF-8 to javascript's internal representation\n      // see http://ecmanaut.blogspot.com/2006/07/encoding-decoding-utf8-in-javascript.html\n      result.name = decodeURIComponent(escape(result.name));\n\n      return result;\n    },\n    mdat: function(data) {\n      return {\n        byteLength: data.byteLength,\n        nals: nalParse(data)\n      };\n    },\n    mdhd: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        i = 4,\n        language,\n        result = {\n          version: view.getUint8(0),\n          flags: new Uint8Array(data.subarray(1, 4)),\n          language: ''\n        };\n      if (result.version === 1) {\n        i += 4;\n        result.creationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n        i += 8;\n        result.modificationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n        i += 4;\n        result.timescale = view.getUint32(i);\n        i += 8;\n        result.duration = view.getUint32(i); // truncating top 4 bytes\n      } else {\n        result.creationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.modificationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.timescale = view.getUint32(i);\n        i += 4;\n        result.duration = view.getUint32(i);\n      }\n      i += 4;\n      // language is stored as an ISO-639-2/T code in an array of three 5-bit fields\n      // each field is the packed difference between its ASCII value and 0x60\n      language = view.getUint16(i);\n      result.language += String.fromCharCode((language >> 10) + 0x60);\n      result.language += String.fromCharCode(((language & 0x03e0) >> 5) + 0x60);\n      result.language += String.fromCharCode((language & 0x1f) + 0x60);\n\n      return result;\n    },\n    mdia: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    mfhd: function(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        sequenceNumber: (data[4] << 24) |\n          (data[5] << 16) |\n          (data[6] << 8) |\n          (data[7])\n      };\n    },\n    minf: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    // codingname, not a first-class box type. stsd entries share the\n    // same format as real boxes so the parsing infrastructure can be\n    // shared\n    mp4a: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        result = {\n          // 6 bytes reserved\n          dataReferenceIndex: view.getUint16(6),\n          // 4 + 4 bytes reserved\n          channelcount: view.getUint16(16),\n          samplesize: view.getUint16(18),\n          // 2 bytes pre_defined\n          // 2 bytes reserved\n          samplerate: view.getUint16(24) + (view.getUint16(26) / 65536)\n        };\n\n      // if there are more bytes to process, assume this is an ISO/IEC\n      // 14496-14 MP4AudioSampleEntry and parse the ESDBox\n      if (data.byteLength > 28) {\n        result.streamDescriptor = inspectMp4(data.subarray(28))[0];\n      }\n      return result;\n    },\n    moof: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    moov: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    mvex: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    mvhd: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        i = 4,\n        result = {\n          version: view.getUint8(0),\n          flags: new Uint8Array(data.subarray(1, 4))\n        };\n\n      if (result.version === 1) {\n        i += 4;\n        result.creationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n        i += 8;\n        result.modificationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n        i += 4;\n        result.timescale = view.getUint32(i);\n        i += 8;\n        result.duration = view.getUint32(i); // truncating top 4 bytes\n      } else {\n        result.creationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.modificationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.timescale = view.getUint32(i);\n        i += 4;\n        result.duration = view.getUint32(i);\n      }\n      i += 4;\n\n      // convert fixed-point, base 16 back to a number\n      result.rate = view.getUint16(i) + (view.getUint16(i + 2) / 16);\n      i += 4;\n      result.volume = view.getUint8(i) + (view.getUint8(i + 1) / 8);\n      i += 2;\n      i += 2;\n      i += 2 * 4;\n      result.matrix = new Uint32Array(data.subarray(i, i + (9 * 4)));\n      i += 9 * 4;\n      i += 6 * 4;\n      result.nextTrackId = view.getUint32(i);\n      return result;\n    },\n    pdin: function(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength);\n      return {\n        version: view.getUint8(0),\n        flags: new Uint8Array(data.subarray(1, 4)),\n        rate: view.getUint32(4),\n        initialDelay: view.getUint32(8)\n      };\n    },\n    sdtp: function(data) {\n      var\n        result = {\n          version: data[0],\n          flags: new Uint8Array(data.subarray(1, 4)),\n          samples: []\n        }, i;\n\n      for (i = 4; i < data.byteLength; i++) {\n        result.samples.push({\n          dependsOn: (data[i] & 0x30) >> 4,\n          isDependedOn: (data[i] & 0x0c) >> 2,\n          hasRedundancy: data[i] & 0x03\n        });\n      }\n      return result;\n    },\n    sidx: require('./parse-sidx.js'),\n    smhd: function(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        balance: data[4] + (data[5] / 256)\n      };\n    },\n    stbl: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    stco: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        result = {\n          version: data[0],\n          flags: new Uint8Array(data.subarray(1, 4)),\n          chunkOffsets: []\n        },\n        entryCount = view.getUint32(4),\n        i;\n      for (i = 8; entryCount; i += 4, entryCount--) {\n        result.chunkOffsets.push(view.getUint32(i));\n      }\n      return result;\n    },\n    stsc: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        entryCount = view.getUint32(4),\n        result = {\n          version: data[0],\n          flags: new Uint8Array(data.subarray(1, 4)),\n          sampleToChunks: []\n        },\n        i;\n      for (i = 8; entryCount; i += 12, entryCount--) {\n        result.sampleToChunks.push({\n          firstChunk: view.getUint32(i),\n          samplesPerChunk: view.getUint32(i + 4),\n          sampleDescriptionIndex: view.getUint32(i + 8)\n        });\n      }\n      return result;\n    },\n    stsd: function(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        sampleDescriptions: inspectMp4(data.subarray(8))\n      };\n    },\n    stsz: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        result = {\n          version: data[0],\n          flags: new Uint8Array(data.subarray(1, 4)),\n          sampleSize: view.getUint32(4),\n          entries: []\n        },\n        i;\n      for (i = 12; i < data.byteLength; i += 4) {\n        result.entries.push(view.getUint32(i));\n      }\n      return result;\n    },\n    stts: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        result = {\n          version: data[0],\n          flags: new Uint8Array(data.subarray(1, 4)),\n          timeToSamples: []\n        },\n        entryCount = view.getUint32(4),\n        i;\n\n      for (i = 8; entryCount; i += 8, entryCount--) {\n        result.timeToSamples.push({\n          sampleCount: view.getUint32(i),\n          sampleDelta: view.getUint32(i + 4)\n        });\n      }\n      return result;\n    },\n    styp: function(data) {\n      return parse.ftyp(data);\n    },\n    tfdt: require('./parse-tfdt.js'),\n    tfhd: require('./parse-tfhd.js'),\n    tkhd: function(data) {\n      var\n        view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n        i = 4,\n        result = {\n          version: view.getUint8(0),\n          flags: new Uint8Array(data.subarray(1, 4))\n        };\n      if (result.version === 1) {\n        i += 4;\n        result.creationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n        i += 8;\n        result.modificationTime = parseMp4Date(view.getUint32(i)); // truncating top 4 bytes\n        i += 4;\n        result.trackId = view.getUint32(i);\n        i += 4;\n        i += 8;\n        result.duration = view.getUint32(i); // truncating top 4 bytes\n      } else {\n        result.creationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.modificationTime = parseMp4Date(view.getUint32(i));\n        i += 4;\n        result.trackId = view.getUint32(i);\n        i += 4;\n        i += 4;\n        result.duration = view.getUint32(i);\n      }\n      i += 4;\n      i += 2 * 4;\n      result.layer = view.getUint16(i);\n      i += 2;\n      result.alternateGroup = view.getUint16(i);\n      i += 2;\n      // convert fixed-point, base 16 back to a number\n      result.volume = view.getUint8(i) + (view.getUint8(i + 1) / 8);\n      i += 2;\n      i += 2;\n      result.matrix = new Uint32Array(data.subarray(i, i + (9 * 4)));\n      i += 9 * 4;\n      result.width = view.getUint16(i) + (view.getUint16(i + 2) / 65536);\n      i += 4;\n      result.height = view.getUint16(i) + (view.getUint16(i + 2) / 65536);\n      return result;\n    },\n    traf: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    trak: function(data) {\n      return {\n        boxes: inspectMp4(data)\n      };\n    },\n    trex: function(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength);\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        trackId: view.getUint32(4),\n        defaultSampleDescriptionIndex: view.getUint32(8),\n        defaultSampleDuration: view.getUint32(12),\n        defaultSampleSize: view.getUint32(16),\n        sampleDependsOn: data[20] & 0x03,\n        sampleIsDependedOn: (data[21] & 0xc0) >> 6,\n        sampleHasRedundancy: (data[21] & 0x30) >> 4,\n        samplePaddingValue: (data[21] & 0x0e) >> 1,\n        sampleIsDifferenceSample: !!(data[21] & 0x01),\n        sampleDegradationPriority: view.getUint16(22)\n      };\n    },\n    trun: require('./parse-trun.js'),\n    'url ': function(data) {\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4))\n      };\n    },\n    vmhd: function(data) {\n      var view = new DataView(data.buffer, data.byteOffset, data.byteLength);\n      return {\n        version: data[0],\n        flags: new Uint8Array(data.subarray(1, 4)),\n        graphicsmode: view.getUint16(4),\n        opcolor: new Uint16Array([view.getUint16(6),\n                                  view.getUint16(8),\n                                  view.getUint16(10)])\n      };\n    }\n  };\n\n\n/**\n * Return a javascript array of box objects parsed from an ISO base\n * media file.\n * @param data {Uint8Array} the binary data of the media to be inspected\n * @return {array} a javascript array of potentially nested box objects\n */\ninspectMp4 = function(data) {\n  var\n    i = 0,\n    result = [],\n    view,\n    size,\n    type,\n    end,\n    box;\n\n  // Convert data from Uint8Array to ArrayBuffer, to follow Dataview API\n  var ab = new ArrayBuffer(data.length);\n  var v = new Uint8Array(ab);\n  for (var z = 0; z < data.length; ++z) {\n      v[z] = data[z];\n  }\n  view = new DataView(ab);\n\n  while (i < data.byteLength) {\n    // parse box data\n    size = view.getUint32(i);\n    type =  parseType(data.subarray(i + 4, i + 8));\n    end = size > 1 ? i + size : data.byteLength;\n\n    // parse type-specific data\n    box = (parse[type] || function(data) {\n      return {\n        data: data\n      };\n    })(data.subarray(i + 8, end));\n    box.size = size;\n    box.type = type;\n\n    // store this box and move to the next\n    result.push(box);\n    i = end;\n  }\n  return result;\n};\n\n/**\n * Returns a textual representation of the javascript represtentation\n * of an MP4 file. You can use it as an alternative to\n * JSON.stringify() to compare inspected MP4s.\n * @param inspectedMp4 {array} the parsed array of boxes in an MP4\n * file\n * @param depth {number} (optional) the number of ancestor boxes of\n * the elements of inspectedMp4. Assumed to be zero if unspecified.\n * @return {string} a text representation of the parsed MP4\n */\ntextifyMp4 = function(inspectedMp4, depth) {\n  var indent;\n  depth = depth || 0;\n  indent = new Array(depth * 2 + 1).join(' ');\n\n  // iterate over all the boxes\n  return inspectedMp4.map(function(box, index) {\n\n    // list the box type first at the current indentation level\n    return indent + box.type + '\\n' +\n\n      // the type is already included and handle child boxes separately\n      Object.keys(box).filter(function(key) {\n        return key !== 'type' && key !== 'boxes';\n\n      // output all the box properties\n      }).map(function(key) {\n        var prefix = indent + '  ' + key + ': ',\n            value = box[key];\n\n        // print out raw bytes as hexademical\n        if (value instanceof Uint8Array || value instanceof Uint32Array) {\n          var bytes = Array.prototype.slice.call(new Uint8Array(value.buffer, value.byteOffset, value.byteLength))\n              .map(function(byte) {\n                return ' ' + ('00' + byte.toString(16)).slice(-2);\n              }).join('').match(/.{1,24}/g);\n          if (!bytes) {\n            return prefix + '<>';\n          }\n          if (bytes.length === 1) {\n            return prefix + '<' + bytes.join('').slice(1) + '>';\n          }\n          return prefix + '<\\n' + bytes.map(function(line) {\n            return indent + '  ' + line;\n          }).join('\\n') + '\\n' + indent + '  >';\n        }\n\n        // stringify generic objects\n        return prefix +\n            JSON.stringify(value, null, 2)\n              .split('\\n').map(function(line, index) {\n                if (index === 0) {\n                  return line;\n                }\n                return indent + '  ' + line;\n              }).join('\\n');\n      }).join('\\n') +\n\n    // recursively textify the child boxes\n    (box.boxes ? '\\n' + textifyMp4(box.boxes, depth + 1) : '');\n  }).join('\\n');\n};\n\nmodule.exports = {\n  inspect: inspectMp4,\n  textify: textifyMp4,\n  parseType: parseType,\n  findBox: findBox,\n  parseTraf: parse.traf,\n  parseTfdt: parse.tfdt,\n  parseHdlr: parse.hdlr,\n  parseTfhd: parse.tfhd,\n  parseTrun: parse.trun,\n  parseSidx: parse.sidx\n};\n",
    "var parseSampleFlags = function(flags) {\n  return {\n    isLeading: (flags[0] & 0x0c) >>> 2,\n    dependsOn: flags[0] & 0x03,\n    isDependedOn: (flags[1] & 0xc0) >>> 6,\n    hasRedundancy: (flags[1] & 0x30) >>> 4,\n    paddingValue: (flags[1] & 0x0e) >>> 1,\n    isNonSyncSample: flags[1] & 0x01,\n    degradationPriority: (flags[2] << 8) | flags[3]\n  };\n};\n\nmodule.exports = parseSampleFlags;\n",
    "var parseSidx = function(data) {\n  var view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n    result = {\n      version: data[0],\n      flags: new Uint8Array(data.subarray(1, 4)),\n      references: [],\n      referenceId: view.getUint32(4),\n      timescale: view.getUint32(8),\n      earliestPresentationTime: view.getUint32(12),\n      firstOffset: view.getUint32(16)\n    },\n    referenceCount = view.getUint16(22),\n    i;\n\n  for (i = 24; referenceCount; i += 12, referenceCount--) {\n    result.references.push({\n      referenceType: (data[i] & 0x80) >>> 7,\n      referencedSize: view.getUint32(i) & 0x7FFFFFFF,\n      subsegmentDuration: view.getUint32(i + 4),\n      startsWithSap: !!(data[i + 8] & 0x80),\n      sapType: (data[i + 8] & 0x70) >>> 4,\n      sapDeltaTime: view.getUint32(i + 8) & 0x0FFFFFFF\n    });\n  }\n\n  return result;\n};\n\nmodule.exports = parseSidx;\n",
    "var toUnsigned = require('../utils/bin').toUnsigned;\n\nvar tfdt = function(data) {\n  var result = {\n    version: data[0],\n    flags: new Uint8Array(data.subarray(1, 4)),\n    baseMediaDecodeTime: toUnsigned(data[4] << 24 | data[5] << 16 | data[6] << 8 | data[7])\n  };\n  if (result.version === 1) {\n    result.baseMediaDecodeTime *= Math.pow(2, 32);\n    result.baseMediaDecodeTime += toUnsigned(data[8] << 24 | data[9] << 16 | data[10] << 8 | data[11]);\n  }\n  return result;\n};\n\nmodule.exports = tfdt;\n\n",
    "var tfhd = function(data) {\n  var\n  view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n    result = {\n      version: data[0],\n      flags: new Uint8Array(data.subarray(1, 4)),\n      trackId: view.getUint32(4)\n    },\n    baseDataOffsetPresent = result.flags[2] & 0x01,\n    sampleDescriptionIndexPresent = result.flags[2] & 0x02,\n    defaultSampleDurationPresent = result.flags[2] & 0x08,\n    defaultSampleSizePresent = result.flags[2] & 0x10,\n    defaultSampleFlagsPresent = result.flags[2] & 0x20,\n    durationIsEmpty = result.flags[0] & 0x010000,\n    defaultBaseIsMoof =  result.flags[0] & 0x020000,\n    i;\n\n  i = 8;\n  if (baseDataOffsetPresent) {\n    i += 4; // truncate top 4 bytes\n    // FIXME: should we read the full 64 bits?\n    result.baseDataOffset = view.getUint32(12);\n    i += 4;\n  }\n  if (sampleDescriptionIndexPresent) {\n    result.sampleDescriptionIndex = view.getUint32(i);\n    i += 4;\n  }\n  if (defaultSampleDurationPresent) {\n    result.defaultSampleDuration = view.getUint32(i);\n    i += 4;\n  }\n  if (defaultSampleSizePresent) {\n    result.defaultSampleSize = view.getUint32(i);\n    i += 4;\n  }\n  if (defaultSampleFlagsPresent) {\n    result.defaultSampleFlags = view.getUint32(i);\n  }\n  if (durationIsEmpty) {\n    result.durationIsEmpty = true;\n  }\n  if (!baseDataOffsetPresent && defaultBaseIsMoof) {\n    result.baseDataOffsetIsMoof = true;\n  }\n  return result;\n};\n\nmodule.exports = tfhd;\n",
    "var parseSampleFlags = require('./parse-sample-flags.js');\n\nvar trun = function(data) {\n  var\n  result = {\n    version: data[0],\n    flags: new Uint8Array(data.subarray(1, 4)),\n    samples: []\n  },\n    view = new DataView(data.buffer, data.byteOffset, data.byteLength),\n    // Flag interpretation\n    dataOffsetPresent = result.flags[2] & 0x01, // compare with 2nd byte of 0x1\n    firstSampleFlagsPresent = result.flags[2] & 0x04, // compare with 2nd byte of 0x4\n    sampleDurationPresent = result.flags[1] & 0x01, // compare with 2nd byte of 0x100\n    sampleSizePresent = result.flags[1] & 0x02, // compare with 2nd byte of 0x200\n    sampleFlagsPresent = result.flags[1] & 0x04, // compare with 2nd byte of 0x400\n    sampleCompositionTimeOffsetPresent = result.flags[1] & 0x08, // compare with 2nd byte of 0x800\n    sampleCount = view.getUint32(4),\n    offset = 8,\n    sample;\n\n  if (dataOffsetPresent) {\n    // 32 bit signed integer\n    result.dataOffset = view.getInt32(offset);\n    offset += 4;\n  }\n\n  // Overrides the flags for the first sample only. The order of\n  // optional values will be: duration, size, compositionTimeOffset\n  if (firstSampleFlagsPresent && sampleCount) {\n    sample = {\n      flags: parseSampleFlags(data.subarray(offset, offset + 4))\n    };\n    offset += 4;\n    if (sampleDurationPresent) {\n      sample.duration = view.getUint32(offset);\n      offset += 4;\n    }\n    if (sampleSizePresent) {\n      sample.size = view.getUint32(offset);\n      offset += 4;\n    }\n    if (sampleCompositionTimeOffsetPresent) {\n      if (result.version === 1) {\n        sample.compositionTimeOffset = view.getInt32(offset);\n      } else {\n        sample.compositionTimeOffset = view.getUint32(offset);\n      }\n      offset += 4;\n    }\n    result.samples.push(sample);\n    sampleCount--;\n  }\n\n  while (sampleCount--) {\n    sample = {};\n    if (sampleDurationPresent) {\n      sample.duration = view.getUint32(offset);\n      offset += 4;\n    }\n    if (sampleSizePresent) {\n      sample.size = view.getUint32(offset);\n      offset += 4;\n    }\n    if (sampleFlagsPresent) {\n      sample.flags = parseSampleFlags(data.subarray(offset, offset + 4));\n      offset += 4;\n    }\n    if (sampleCompositionTimeOffsetPresent) {\n      if (result.version === 1) {\n        sample.compositionTimeOffset = view.getInt32(offset);\n      } else {\n        sample.compositionTimeOffset = view.getUint32(offset);\n      }\n      offset += 4;\n    }\n    result.samples.push(sample);\n  }\n  return result;\n};\n\nmodule.exports = trun;\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * Parse mpeg2 transport stream packets to extract basic timing information\n */\n'use strict';\n\nvar StreamTypes = require('../m2ts/stream-types.js');\nvar handleRollover = require('../m2ts/timestamp-rollover-stream.js').handleRollover;\nvar probe = {};\nprobe.ts = require('../m2ts/probe.js');\nprobe.aac = require('../aac/utils.js');\nvar ONE_SECOND_IN_TS = require('../utils/clock').ONE_SECOND_IN_TS;\n\nvar\n  MP2T_PACKET_LENGTH = 188, // bytes\n  SYNC_BYTE = 0x47;\n\n/**\n * walks through segment data looking for pat and pmt packets to parse out\n * program map table information\n */\nvar parsePsi_ = function(bytes, pmt) {\n  var\n    startIndex = 0,\n    endIndex = MP2T_PACKET_LENGTH,\n    packet, type;\n\n  while (endIndex < bytes.byteLength) {\n    // Look for a pair of start and end sync bytes in the data..\n    if (bytes[startIndex] === SYNC_BYTE && bytes[endIndex] === SYNC_BYTE) {\n      // We found a packet\n      packet = bytes.subarray(startIndex, endIndex);\n      type = probe.ts.parseType(packet, pmt.pid);\n\n      switch (type) {\n        case 'pat':\n          if (!pmt.pid) {\n            pmt.pid = probe.ts.parsePat(packet);\n          }\n          break;\n        case 'pmt':\n          if (!pmt.table) {\n            pmt.table = probe.ts.parsePmt(packet);\n          }\n          break;\n        default:\n          break;\n      }\n\n      // Found the pat and pmt, we can stop walking the segment\n      if (pmt.pid && pmt.table) {\n        return;\n      }\n\n      startIndex += MP2T_PACKET_LENGTH;\n      endIndex += MP2T_PACKET_LENGTH;\n      continue;\n    }\n\n    // If we get here, we have somehow become de-synchronized and we need to step\n    // forward one byte at a time until we find a pair of sync bytes that denote\n    // a packet\n    startIndex++;\n    endIndex++;\n  }\n};\n\n/**\n * walks through the segment data from the start and end to get timing information\n * for the first and last audio pes packets\n */\nvar parseAudioPes_ = function(bytes, pmt, result) {\n  var\n    startIndex = 0,\n    endIndex = MP2T_PACKET_LENGTH,\n    packet, type, pesType, pusi, parsed;\n\n  var endLoop = false;\n\n  // Start walking from start of segment to get first audio packet\n  while (endIndex <= bytes.byteLength) {\n    // Look for a pair of start and end sync bytes in the data..\n    if (bytes[startIndex] === SYNC_BYTE &&\n        (bytes[endIndex] === SYNC_BYTE || endIndex === bytes.byteLength)) {\n      // We found a packet\n      packet = bytes.subarray(startIndex, endIndex);\n      type = probe.ts.parseType(packet, pmt.pid);\n\n      switch (type) {\n        case 'pes':\n          pesType = probe.ts.parsePesType(packet, pmt.table);\n          pusi = probe.ts.parsePayloadUnitStartIndicator(packet);\n          if (pesType === 'audio' && pusi) {\n            parsed = probe.ts.parsePesTime(packet);\n            if (parsed) {\n              parsed.type = 'audio';\n              result.audio.push(parsed);\n              endLoop = true;\n            }\n          }\n          break;\n        default:\n          break;\n      }\n\n      if (endLoop) {\n        break;\n      }\n\n      startIndex += MP2T_PACKET_LENGTH;\n      endIndex += MP2T_PACKET_LENGTH;\n      continue;\n    }\n\n    // If we get here, we have somehow become de-synchronized and we need to step\n    // forward one byte at a time until we find a pair of sync bytes that denote\n    // a packet\n    startIndex++;\n    endIndex++;\n  }\n\n  // Start walking from end of segment to get last audio packet\n  endIndex = bytes.byteLength;\n  startIndex = endIndex - MP2T_PACKET_LENGTH;\n  endLoop = false;\n  while (startIndex >= 0) {\n    // Look for a pair of start and end sync bytes in the data..\n    if (bytes[startIndex] === SYNC_BYTE &&\n        (bytes[endIndex] === SYNC_BYTE || endIndex === bytes.byteLength)) {\n      // We found a packet\n      packet = bytes.subarray(startIndex, endIndex);\n      type = probe.ts.parseType(packet, pmt.pid);\n\n      switch (type) {\n        case 'pes':\n          pesType = probe.ts.parsePesType(packet, pmt.table);\n          pusi = probe.ts.parsePayloadUnitStartIndicator(packet);\n          if (pesType === 'audio' && pusi) {\n            parsed = probe.ts.parsePesTime(packet);\n            if (parsed) {\n              parsed.type = 'audio';\n              result.audio.push(parsed);\n              endLoop = true;\n            }\n          }\n          break;\n        default:\n          break;\n      }\n\n      if (endLoop) {\n        break;\n      }\n\n      startIndex -= MP2T_PACKET_LENGTH;\n      endIndex -= MP2T_PACKET_LENGTH;\n      continue;\n    }\n\n    // If we get here, we have somehow become de-synchronized and we need to step\n    // forward one byte at a time until we find a pair of sync bytes that denote\n    // a packet\n    startIndex--;\n    endIndex--;\n  }\n};\n\n/**\n * walks through the segment data from the start and end to get timing information\n * for the first and last video pes packets as well as timing information for the first\n * key frame.\n */\nvar parseVideoPes_ = function(bytes, pmt, result) {\n  var\n    startIndex = 0,\n    endIndex = MP2T_PACKET_LENGTH,\n    packet, type, pesType, pusi, parsed, frame, i, pes;\n\n  var endLoop = false;\n\n  var currentFrame = {\n    data: [],\n    size: 0\n  };\n\n  // Start walking from start of segment to get first video packet\n  while (endIndex < bytes.byteLength) {\n    // Look for a pair of start and end sync bytes in the data..\n    if (bytes[startIndex] === SYNC_BYTE && bytes[endIndex] === SYNC_BYTE) {\n      // We found a packet\n      packet = bytes.subarray(startIndex, endIndex);\n      type = probe.ts.parseType(packet, pmt.pid);\n\n      switch (type) {\n        case 'pes':\n          pesType = probe.ts.parsePesType(packet, pmt.table);\n          pusi = probe.ts.parsePayloadUnitStartIndicator(packet);\n          if (pesType === 'video') {\n            if (pusi && !endLoop) {\n              parsed = probe.ts.parsePesTime(packet);\n              if (parsed) {\n                parsed.type = 'video';\n                result.video.push(parsed);\n                endLoop = true;\n              }\n            }\n            if (!result.firstKeyFrame) {\n              if (pusi) {\n                if (currentFrame.size !== 0) {\n                  frame = new Uint8Array(currentFrame.size);\n                  i = 0;\n                  while (currentFrame.data.length) {\n                    pes = currentFrame.data.shift();\n                    frame.set(pes, i);\n                    i += pes.byteLength;\n                  }\n                  if (probe.ts.videoPacketContainsKeyFrame(frame)) {\n                    var firstKeyFrame = probe.ts.parsePesTime(frame);\n\n                    // PTS/DTS may not be available. Simply *not* setting\n                    // the keyframe seems to work fine with HLS playback\n                    // and definitely preferable to a crash with TypeError...\n                    if (firstKeyFrame) {\n                      result.firstKeyFrame = firstKeyFrame;\n                      result.firstKeyFrame.type = 'video';\n                    } else {\n                      // eslint-disable-next-line\n                      console.warn(\n                        'Failed to extract PTS/DTS from PES at first keyframe. ' +\n                        'This could be an unusual TS segment, or else mux.js did not ' +\n                        'parse your TS segment correctly. If you know your TS ' +\n                        'segments do contain PTS/DTS on keyframes please file a bug ' +\n                        'report! You can try ffprobe to double check for yourself.'\n                      );\n                    }\n                  }\n                  currentFrame.size = 0;\n                }\n              }\n              currentFrame.data.push(packet);\n              currentFrame.size += packet.byteLength;\n            }\n          }\n          break;\n        default:\n          break;\n      }\n\n      if (endLoop && result.firstKeyFrame) {\n        break;\n      }\n\n      startIndex += MP2T_PACKET_LENGTH;\n      endIndex += MP2T_PACKET_LENGTH;\n      continue;\n    }\n\n    // If we get here, we have somehow become de-synchronized and we need to step\n    // forward one byte at a time until we find a pair of sync bytes that denote\n    // a packet\n    startIndex++;\n    endIndex++;\n  }\n\n  // Start walking from end of segment to get last video packet\n  endIndex = bytes.byteLength;\n  startIndex = endIndex - MP2T_PACKET_LENGTH;\n  endLoop = false;\n  while (startIndex >= 0) {\n    // Look for a pair of start and end sync bytes in the data..\n    if (bytes[startIndex] === SYNC_BYTE && bytes[endIndex] === SYNC_BYTE) {\n      // We found a packet\n      packet = bytes.subarray(startIndex, endIndex);\n      type = probe.ts.parseType(packet, pmt.pid);\n\n      switch (type) {\n        case 'pes':\n          pesType = probe.ts.parsePesType(packet, pmt.table);\n          pusi = probe.ts.parsePayloadUnitStartIndicator(packet);\n          if (pesType === 'video' && pusi) {\n              parsed = probe.ts.parsePesTime(packet);\n              if (parsed) {\n                parsed.type = 'video';\n                result.video.push(parsed);\n                endLoop = true;\n              }\n          }\n          break;\n        default:\n          break;\n      }\n\n      if (endLoop) {\n        break;\n      }\n\n      startIndex -= MP2T_PACKET_LENGTH;\n      endIndex -= MP2T_PACKET_LENGTH;\n      continue;\n    }\n\n    // If we get here, we have somehow become de-synchronized and we need to step\n    // forward one byte at a time until we find a pair of sync bytes that denote\n    // a packet\n    startIndex--;\n    endIndex--;\n  }\n};\n\n/**\n * Adjusts the timestamp information for the segment to account for\n * rollover and convert to seconds based on pes packet timescale (90khz clock)\n */\nvar adjustTimestamp_ = function(segmentInfo, baseTimestamp) {\n  if (segmentInfo.audio && segmentInfo.audio.length) {\n    var audioBaseTimestamp = baseTimestamp;\n    if (typeof audioBaseTimestamp === 'undefined') {\n      audioBaseTimestamp = segmentInfo.audio[0].dts;\n    }\n    segmentInfo.audio.forEach(function(info) {\n      info.dts = handleRollover(info.dts, audioBaseTimestamp);\n      info.pts = handleRollover(info.pts, audioBaseTimestamp);\n      // time in seconds\n      info.dtsTime = info.dts / ONE_SECOND_IN_TS;\n      info.ptsTime = info.pts / ONE_SECOND_IN_TS;\n    });\n  }\n\n  if (segmentInfo.video && segmentInfo.video.length) {\n    var videoBaseTimestamp = baseTimestamp;\n    if (typeof videoBaseTimestamp === 'undefined') {\n      videoBaseTimestamp = segmentInfo.video[0].dts;\n    }\n    segmentInfo.video.forEach(function(info) {\n      info.dts = handleRollover(info.dts, videoBaseTimestamp);\n      info.pts = handleRollover(info.pts, videoBaseTimestamp);\n      // time in seconds\n      info.dtsTime = info.dts / ONE_SECOND_IN_TS;\n      info.ptsTime = info.pts / ONE_SECOND_IN_TS;\n    });\n    if (segmentInfo.firstKeyFrame) {\n      var frame = segmentInfo.firstKeyFrame;\n      frame.dts = handleRollover(frame.dts, videoBaseTimestamp);\n      frame.pts = handleRollover(frame.pts, videoBaseTimestamp);\n      // time in seconds\n      frame.dtsTime = frame.dts / ONE_SECOND_IN_TS;\n      frame.ptsTime = frame.dts / ONE_SECOND_IN_TS;\n    }\n  }\n};\n\n/**\n * inspects the aac data stream for start and end time information\n */\nvar inspectAac_ = function(bytes) {\n  var\n    endLoop = false,\n    audioCount = 0,\n    sampleRate = null,\n    timestamp = null,\n    frameSize = 0,\n    byteIndex = 0,\n    packet;\n\n  while (bytes.length - byteIndex >= 3) {\n    var type = probe.aac.parseType(bytes, byteIndex);\n    switch (type) {\n      case 'timed-metadata':\n        // Exit early because we don't have enough to parse\n        // the ID3 tag header\n        if (bytes.length - byteIndex < 10) {\n          endLoop = true;\n          break;\n        }\n\n        frameSize = probe.aac.parseId3TagSize(bytes, byteIndex);\n\n        // Exit early if we don't have enough in the buffer\n        // to emit a full packet\n        if (frameSize > bytes.length) {\n          endLoop = true;\n          break;\n        }\n        if (timestamp === null) {\n          packet = bytes.subarray(byteIndex, byteIndex + frameSize);\n          timestamp = probe.aac.parseAacTimestamp(packet);\n        }\n        byteIndex += frameSize;\n        break;\n      case 'audio':\n        // Exit early because we don't have enough to parse\n        // the ADTS frame header\n        if (bytes.length - byteIndex < 7) {\n          endLoop = true;\n          break;\n        }\n\n        frameSize = probe.aac.parseAdtsSize(bytes, byteIndex);\n\n        // Exit early if we don't have enough in the buffer\n        // to emit a full packet\n        if (frameSize > bytes.length) {\n          endLoop = true;\n          break;\n        }\n        if (sampleRate === null) {\n          packet = bytes.subarray(byteIndex, byteIndex + frameSize);\n          sampleRate = probe.aac.parseSampleRate(packet);\n        }\n        audioCount++;\n        byteIndex += frameSize;\n        break;\n      default:\n        byteIndex++;\n        break;\n    }\n    if (endLoop) {\n      return null;\n    }\n  }\n  if (sampleRate === null || timestamp === null) {\n    return null;\n  }\n\n  var audioTimescale = ONE_SECOND_IN_TS / sampleRate;\n\n  var result = {\n    audio: [\n      {\n        type: 'audio',\n        dts: timestamp,\n        pts: timestamp\n      },\n      {\n        type: 'audio',\n        dts: timestamp + (audioCount * 1024 * audioTimescale),\n        pts: timestamp + (audioCount * 1024 * audioTimescale)\n      }\n    ]\n  };\n\n  return result;\n};\n\n/**\n * inspects the transport stream segment data for start and end time information\n * of the audio and video tracks (when present) as well as the first key frame's\n * start time.\n */\nvar inspectTs_ = function(bytes) {\n  var pmt = {\n    pid: null,\n    table: null\n  };\n\n  var result = {};\n\n  parsePsi_(bytes, pmt);\n\n  for (var pid in pmt.table) {\n    if (pmt.table.hasOwnProperty(pid)) {\n      var type = pmt.table[pid];\n      switch (type) {\n        case StreamTypes.H264_STREAM_TYPE:\n          result.video = [];\n          parseVideoPes_(bytes, pmt, result);\n          if (result.video.length === 0) {\n            delete result.video;\n          }\n          break;\n        case StreamTypes.ADTS_STREAM_TYPE:\n          result.audio = [];\n          parseAudioPes_(bytes, pmt, result);\n          if (result.audio.length === 0) {\n            delete result.audio;\n          }\n          break;\n        default:\n          break;\n      }\n    }\n  }\n  return result;\n};\n\n/**\n * Inspects segment byte data and returns an object with start and end timing information\n *\n * @param {Uint8Array} bytes The segment byte data\n * @param {Number} baseTimestamp Relative reference timestamp used when adjusting frame\n *  timestamps for rollover. This value must be in 90khz clock.\n * @return {Object} Object containing start and end frame timing info of segment.\n */\nvar inspect = function(bytes, baseTimestamp) {\n  var isAacData = probe.aac.isLikelyAacData(bytes);\n\n  var result;\n\n  if (isAacData) {\n    result = inspectAac_(bytes);\n  } else {\n    result = inspectTs_(bytes);\n  }\n\n  if (!result || (!result.audio && !result.video)) {\n    return null;\n  }\n\n  adjustTimestamp_(result, baseTimestamp);\n\n  return result;\n};\n\nmodule.exports = {\n  inspect: inspect,\n  parseAudioPes_: parseAudioPes_\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\nvar toUnsigned = function(value) {\n  return value >>> 0;\n};\n\nvar toHexString = function(value) {\n  return ('00' + value.toString(16)).slice(-2);\n};\n\nmodule.exports = {\n  toUnsigned: toUnsigned,\n  toHexString: toHexString\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\nvar\n  ONE_SECOND_IN_TS = 90000, // 90kHz clock\n  secondsToVideoTs,\n  secondsToAudioTs,\n  videoTsToSeconds,\n  audioTsToSeconds,\n  audioTsToVideoTs,\n  videoTsToAudioTs,\n  metadataTsToSeconds;\n\nsecondsToVideoTs = function(seconds) {\n  return seconds * ONE_SECOND_IN_TS;\n};\n\nsecondsToAudioTs = function(seconds, sampleRate) {\n  return seconds * sampleRate;\n};\n\nvideoTsToSeconds = function(timestamp) {\n  return timestamp / ONE_SECOND_IN_TS;\n};\n\naudioTsToSeconds = function(timestamp, sampleRate) {\n  return timestamp / sampleRate;\n};\n\naudioTsToVideoTs = function(timestamp, sampleRate) {\n  return secondsToVideoTs(audioTsToSeconds(timestamp, sampleRate));\n};\n\nvideoTsToAudioTs = function(timestamp, sampleRate) {\n  return secondsToAudioTs(videoTsToSeconds(timestamp), sampleRate);\n};\n\n/**\n * Adjust ID3 tag or caption timing information by the timeline pts values\n * (if keepOriginalTimestamps is false) and convert to seconds\n */\nmetadataTsToSeconds = function(timestamp, timelineStartPts, keepOriginalTimestamps) {\n  return videoTsToSeconds(keepOriginalTimestamps ? timestamp : timestamp - timelineStartPts);\n};\n\nmodule.exports = {\n  ONE_SECOND_IN_TS: ONE_SECOND_IN_TS,\n  secondsToVideoTs: secondsToVideoTs,\n  secondsToAudioTs: secondsToAudioTs,\n  videoTsToSeconds: videoTsToSeconds,\n  audioTsToSeconds: audioTsToSeconds,\n  audioTsToVideoTs: audioTsToVideoTs,\n  videoTsToAudioTs: videoTsToAudioTs,\n  metadataTsToSeconds: metadataTsToSeconds\n};\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n */\n'use strict';\n\nvar ExpGolomb;\n\n/**\n * Parser for exponential Golomb codes, a variable-bitwidth number encoding\n * scheme used by h264.\n */\nExpGolomb = function(workingData) {\n  var\n    // the number of bytes left to examine in workingData\n    workingBytesAvailable = workingData.byteLength,\n\n    // the current word being examined\n    workingWord = 0, // :uint\n\n    // the number of bits left to examine in the current word\n    workingBitsAvailable = 0; // :uint;\n\n  // ():uint\n  this.length = function() {\n    return (8 * workingBytesAvailable);\n  };\n\n  // ():uint\n  this.bitsAvailable = function() {\n    return (8 * workingBytesAvailable) + workingBitsAvailable;\n  };\n\n  // ():void\n  this.loadWord = function() {\n    var\n      position = workingData.byteLength - workingBytesAvailable,\n      workingBytes = new Uint8Array(4),\n      availableBytes = Math.min(4, workingBytesAvailable);\n\n    if (availableBytes === 0) {\n      throw new Error('no bytes available');\n    }\n\n    workingBytes.set(workingData.subarray(position,\n                                          position + availableBytes));\n    workingWord = new DataView(workingBytes.buffer).getUint32(0);\n\n    // track the amount of workingData that has been processed\n    workingBitsAvailable = availableBytes * 8;\n    workingBytesAvailable -= availableBytes;\n  };\n\n  // (count:int):void\n  this.skipBits = function(count) {\n    var skipBytes; // :int\n    if (workingBitsAvailable > count) {\n      workingWord          <<= count;\n      workingBitsAvailable -= count;\n    } else {\n      count -= workingBitsAvailable;\n      skipBytes = Math.floor(count / 8);\n\n      count -= (skipBytes * 8);\n      workingBytesAvailable -= skipBytes;\n\n      this.loadWord();\n\n      workingWord <<= count;\n      workingBitsAvailable -= count;\n    }\n  };\n\n  // (size:int):uint\n  this.readBits = function(size) {\n    var\n      bits = Math.min(workingBitsAvailable, size), // :uint\n      valu = workingWord >>> (32 - bits); // :uint\n    // if size > 31, handle error\n    workingBitsAvailable -= bits;\n    if (workingBitsAvailable > 0) {\n      workingWord <<= bits;\n    } else if (workingBytesAvailable > 0) {\n      this.loadWord();\n    }\n\n    bits = size - bits;\n    if (bits > 0) {\n      return valu << bits | this.readBits(bits);\n    }\n    return valu;\n  };\n\n  // ():uint\n  this.skipLeadingZeros = function() {\n    var leadingZeroCount; // :uint\n    for (leadingZeroCount = 0; leadingZeroCount < workingBitsAvailable; ++leadingZeroCount) {\n      if ((workingWord & (0x80000000 >>> leadingZeroCount)) !== 0) {\n        // the first bit of working word is 1\n        workingWord <<= leadingZeroCount;\n        workingBitsAvailable -= leadingZeroCount;\n        return leadingZeroCount;\n      }\n    }\n\n    // we exhausted workingWord and still have not found a 1\n    this.loadWord();\n    return leadingZeroCount + this.skipLeadingZeros();\n  };\n\n  // ():void\n  this.skipUnsignedExpGolomb = function() {\n    this.skipBits(1 + this.skipLeadingZeros());\n  };\n\n  // ():void\n  this.skipExpGolomb = function() {\n    this.skipBits(1 + this.skipLeadingZeros());\n  };\n\n  // ():uint\n  this.readUnsignedExpGolomb = function() {\n    var clz = this.skipLeadingZeros(); // :uint\n    return this.readBits(clz + 1) - 1;\n  };\n\n  // ():int\n  this.readExpGolomb = function() {\n    var valu = this.readUnsignedExpGolomb(); // :int\n    if (0x01 & valu) {\n      // the number is odd if the low order bit is set\n      return (1 + valu) >>> 1; // add 1 to make it even, and divide by 2\n    }\n    return -1 * (valu >>> 1); // divide by two then make it negative\n  };\n\n  // Some convenience functions\n  // :Boolean\n  this.readBoolean = function() {\n    return this.readBits(1) === 1;\n  };\n\n  // ():int\n  this.readUnsignedByte = function() {\n    return this.readBits(8);\n  };\n\n  this.loadWord();\n};\n\nmodule.exports = ExpGolomb;\n",
    "/**\n * mux.js\n *\n * Copyright (c) Brightcove\n * Licensed Apache-2.0 https://github.com/videojs/mux.js/blob/master/LICENSE\n *\n * A lightweight readable stream implemention that handles event dispatching.\n * Objects that inherit from streams should call init in their constructors.\n */\n'use strict';\n\nvar Stream = function() {\n  this.init = function() {\n    var listeners = {};\n    /**\n     * Add a listener for a specified event type.\n     * @param type {string} the event name\n     * @param listener {function} the callback to be invoked when an event of\n     * the specified type occurs\n     */\n    this.on = function(type, listener) {\n      if (!listeners[type]) {\n        listeners[type] = [];\n      }\n      listeners[type] = listeners[type].concat(listener);\n    };\n    /**\n     * Remove a listener for a specified event type.\n     * @param type {string} the event name\n     * @param listener {function} a function previously registered for this\n     * type of event through `on`\n     */\n    this.off = function(type, listener) {\n      var index;\n      if (!listeners[type]) {\n        return false;\n      }\n      index = listeners[type].indexOf(listener);\n      listeners[type] = listeners[type].slice();\n      listeners[type].splice(index, 1);\n      return index > -1;\n    };\n    /**\n     * Trigger an event of the specified type on this stream. Any additional\n     * arguments to this function are passed as parameters to event listeners.\n     * @param type {string} the event name\n     */\n    this.trigger = function(type) {\n      var callbacks, i, length, args;\n      callbacks = listeners[type];\n      if (!callbacks) {\n        return;\n      }\n      // Slicing the arguments on every invocation of this method\n      // can add a significant amount of overhead. Avoid the\n      // intermediate object creation for the common case of a\n      // single callback argument\n      if (arguments.length === 2) {\n        length = callbacks.length;\n        for (i = 0; i < length; ++i) {\n          callbacks[i].call(this, arguments[1]);\n        }\n      } else {\n        args = [];\n        i = arguments.length;\n        for (i = 1; i < arguments.length; ++i) {\n          args.push(arguments[i]);\n        }\n        length = callbacks.length;\n        for (i = 0; i < length; ++i) {\n          callbacks[i].apply(this, args);\n        }\n      }\n    };\n    /**\n     * Destroys the stream and cleans up.\n     */\n    this.dispose = function() {\n      listeners = {};\n    };\n  };\n};\n\n/**\n * Forwards all `data` events on this stream to the destination stream. The\n * destination stream should provide a method `push` to receive the data\n * events as they arrive.\n * @param destination {stream} the stream that will receive all `data` events\n * @param autoFlush {boolean} if false, we will not call `flush` on the destination\n *                            when the current stream emits a 'done' event\n * @see http://nodejs.org/api/stream.html#stream_readable_pipe_destination_options\n */\nStream.prototype.pipe = function(destination) {\n  this.on('data', function(data) {\n    destination.push(data);\n  });\n\n  this.on('done', function(flushSource) {\n    destination.flush(flushSource);\n  });\n\n  this.on('partialdone', function(flushSource) {\n    destination.partialFlush(flushSource);\n  });\n\n  this.on('endedtimeline', function(flushSource) {\n    destination.endTimeline(flushSource);\n  });\n\n  this.on('reset', function(flushSource) {\n    destination.reset(flushSource);\n  });\n\n  return destination;\n};\n\n// Default stream functions that are expected to be overridden to perform\n// actual work. These are provided by the prototype as a sort of no-op\n// implementation so that we don't have to check for their existence in the\n// `pipe` function above.\nStream.prototype.push = function(data) {\n  this.trigger('data', data);\n};\n\nStream.prototype.flush = function(flushSource) {\n  this.trigger('done', flushSource);\n};\n\nStream.prototype.partialFlush = function(flushSource) {\n  this.trigger('partialdone', flushSource);\n};\n\nStream.prototype.endTimeline = function(flushSource) {\n  this.trigger('endedtimeline', flushSource);\n};\n\nStream.prototype.reset = function(flushSource) {\n  this.trigger('reset', flushSource);\n};\n\nmodule.exports = Stream;\n",
    "/*\n * Buffer Controller\n*/\n\nimport Event from '../events';\nimport EventHandler from '../event-handler';\nimport FlowTransmuxer from '../videojs/flow'\n\nclass BufferController extends EventHandler {\n\n  constructor(wfs) {\n    super(wfs,\n      Event.MEDIA_ATTACHING,\n      Event.BUFFER_APPENDING,\n      Event.BUFFER_RESET,\n      Event.H264_DATA_PARSING\n    );\n    \n    this.mediaSource = null;\n    this.media = null;\n    this.pendingTracks = {};\n    this.sourceBuffer = {};\n    this.segments = [];\n \n    this.appended = 0;\n    this._msDuration = null;\n\n    // Source Buffer listeners\n    this.onsbue = this.onSBUpdateEnd.bind(this);\n\n    this.browserType = 0;\n    if (navigator.userAgent.toLowerCase().indexOf('firefox') !== -1){\n      this.browserType = 1;\n    }\n    this.mediaType = 'H264Raw';\n\n    this.websocketName = undefined; \n    this.channelName = undefined;\n  }\n\n  destroy() {\n    if(this.flow)this.flow.dispose();\n    EventHandler.prototype.destroy.call(this);\n  }\n \n  onMediaAttaching(data) {\n    let media = this.media = data.media;\n    this.mediaType = data.mediaType;\n    this.websocketName = data.websocketName;\n    this.channelName = data.channelName;\n    if (media) {\n      // setup the media source\n      var ms = this.mediaSource = new MediaSource();\n      // link video and media Source\n      media.src = URL.createObjectURL(ms);\n\n      //Media Source listeners\n      this.onmso = this.onMediaSourceOpen.bind(this);\n      this.onmse = this.onMediaSourceEnded.bind(this);\n      this.onmsc = this.onMediaSourceClose.bind(this);\n      ms.addEventListener('sourceopen', this.onmso);\n      ms.addEventListener('sourceended', this.onmse);\n      ms.addEventListener('sourceclose', this.onmsc);\n    }\n  }\n\n  onMediaDetaching() {\n \n  }\n   \n  onBufferAppending(data) { \n    if (!this.segments) {\n      this.segments = [ data ];\n    } else {\n      this.segments.push(data); \n    }\n    this.doAppending(); \n  }\n  \n  onMediaSourceClose() {\n    console.log('media source closed');\n  }\n\n  onMediaSourceEnded() {\n    console.log('media source ended');\n  }\n\n  onSBUpdateEnd(event) { \n    // Firefox\n    if (this.browserType === 1){\n      this.mediaSource.endOfStream();\n      this.media.play();  \n    }\n \n    this.appending = false;\n    this.doAppending();\n    this.updateMediaElementDuration();\n \n  }\n \n  updateMediaElementDuration() {\n  \n  }\n\n  onMediaSourceOpen() { \n    let mediaSource = this.mediaSource;\n    if (mediaSource) {\n      // once received, don't listen anymore to sourceopen event\n      mediaSource.removeEventListener('sourceopen', this.onmso);\n    }\n\n    let videoSourceBuffer = mediaSource.addSourceBuffer('video/mp4;codecs=\"avc1.42E01E\"')\n    this.flow = new FlowTransmuxer();\n    this.flow.on('data' , function(segment){\n      if(segment.type == 'audio'){\n        // sudioSourceBuffer.appendBuffer(segment.data.buffer)\n      }else{\n        videoSourceBuffer.appendBuffer(segment.data.buffer)\n      }\n    })\n\n    this.wfs.trigger(Event.MEDIA_ATTACHED, {media:this.media, channelName:this.channelName, mediaType: this.mediaType, websocketName:this.websocketName});\n  }\n\n  onH264DataParsing(event) {\n\t\tvar b = event.data; // Blob: https://developer.mozilla.org/en-US/docs/Web/API/Blob\n    var reader = new FileReader();\n    reader.addEventListener('loadend', ()=>{\n        var bytes = new Uint8Array(reader.result);\n        this.flow.transmux(bytes);\n    });\n    reader.readAsArrayBuffer(b);\n\t}\n}\n\nexport default BufferController;\n",
    "/*\n * Flow Controller\n*/\n \nimport Event from '../events';\nimport EventHandler from '../event-handler'; \n\nclass FlowController extends EventHandler {\n\n  constructor(wfs) {\n    super(wfs,\n      Event.MEDIA_ATTACHED,\n      Event.BUFFER_CREATED,\n      Event.FILE_PARSING_DATA,\n      Event.FILE_HEAD_LOADED,\n      Event.FILE_DATA_LOADED,\n      Event.WEBSOCKET_ATTACHED,\n      Event.FRAG_PARSING_DATA,\n      Event.FRAG_PARSING_INIT_SEGMENT);\n    \n    this.fileStart = 0;\n    this.fileEnd = 0;\n    this.pendingAppending = 0;\n    this.mediaType = undefined; \n    channelName:this.channelName;\n  }\n\n  destroy() {\n     EventHandler.prototype.destroy.call(this);\n  }  \n\n  onMediaAttached(data) {      \n    if (data.websocketName != undefined){\n      var client = new WebSocket( 'ws://' + window.location.host + '/' +  data.websocketName );\n      this.wfs.attachWebsocket(client,data.channelName);\n    }else{\n       console.log('websocketName ERROE!!!');\n    }\n\n  }\n  \n  onBufferCreated(data) {\n    this.mediaType = data.mediaType; \n  }\n\n  onFileHeadLoaded(data) { \n  }\n\n  onFileDataLoaded(data) { \n  }\n\n  onFileParsingData(data) {\n  }\n \n  onWebsocketAttached(data) {\n    this.wfs.trigger(Event.BUFFER_APPENDING, {type: 'video', data: data.payload, parent : 'main'}); \n  }\n  \n  onFragParsingInitSegment(data) {\n  \t var tracks = data.tracks, trackName, track;\n \n      track = tracks.video;\n      if(track) { \n        track.id = data.id;\n      }\n \n      for (trackName in tracks) {\n        track = tracks[trackName];\n        var initSegment = track.initSegment;\n        if (initSegment) {\n          this.pendingAppending++;\n          this.wfs.trigger(Event.BUFFER_APPENDING, {type: trackName, data: initSegment, parent : 'main'});\n        }\n      }\n \n  }\n\n  onFragParsingData(data) {\n \n      if(data.type === 'video') {\n     \n      }\n       \n      [data.data1, data.data2].forEach(buffer => {\n        if (buffer) {\n          this.pendingAppending++;\n          this.wfs.trigger(Event.BUFFER_APPENDING, {type: data.type, data: buffer, parent : 'main'}); \n        }\n      });\n \n  }\n\n}\nexport default FlowController;  ",
    "/*\n*\n* All objects in the event handling chain should inherit from this class\n*\n*/ \nimport Event from './events';\n\nclass EventHandler {\n\n  constructor(wfs, ...events) {\n    this.wfs = wfs;\n    this.onEvent = this.onEvent.bind(this);\n    this.handledEvents = events;\n    this.useGenericHandler = true;\n\n    this.registerListeners();\n  }\n\n  destroy() {\n    this.unregisterListeners();\n  }\n\n  isEventHandler() {\n    return typeof this.handledEvents === 'object' && this.handledEvents.length && typeof this.onEvent === 'function';\n  }\n\n  registerListeners() {\n    if (this.isEventHandler()) {\n      this.handledEvents.forEach(function(event) {\n        if (event === 'wfsEventGeneric') {\n          //throw new Error('Forbidden event name: ' + event);\n        }\n        this.wfs.on(event, this.onEvent);\n      }.bind(this));\n    }\n  }\n\n  unregisterListeners() {\n    if (this.isEventHandler()) {\n      this.handledEvents.forEach(function(event) {\n        this.wfs.off(event, this.onEvent);\n      }.bind(this));\n    }\n  }\n\n  /**\n   * arguments: event (string), data (any)\n   */\n  onEvent(event, data) {\n    this.onEventGeneric(event, data);\n  }\n\n  onEventGeneric(event, data) {\n    var eventToFunction = function(event, data) {\n      var funcName = 'on' + event.replace('wfs', '');\n      if (typeof this[funcName] !== 'function') {\n        //throw new Error(`Event ${event} has no generic handler in this ${this.constructor.name} class (tried ${funcName})`);\n      }\n      return this[funcName].bind(this, data);\n    };\n    try {\n      eventToFunction.call(this, event, data).call();\n    } catch (err) {\n      console.log(`internal error happened while processing ${event}:${err.message}`);\n      // this.hls.trigger(Event.ERROR, {type: ErrorTypes.OTHER_ERROR, details: ErrorDetails.INTERNAL_EXCEPTION, fatal: false, event : event, err : err});\n    }\n  }\n}\n\nexport default EventHandler;\n",
    "module.exports = {\n \n  MEDIA_ATTACHING: 'wfsMediaAttaching',  \n \n  MEDIA_ATTACHED: 'wfsMediaAttached',\n \n  FRAG_LOADING: 'wfsFragLoading',\n\n  BUFFER_CREATED: 'wfsBufferCreated', \n\n  BUFFER_APPENDING: 'wfsBufferAppending',\n\n  BUFFER_RESET: 'wfsBufferReset', \n\n  FRAG_PARSING_DATA: 'wfsFragParsingData',\n \n  FRAG_PARSING_INIT_SEGMENT: 'wfsFragParsingInitSegment',\n//------------------------------------------\n  H264_DATA_PARSING: 'wfsH264DataParsing',\n\n  H264_DATA_PARSED: 'wfsH264DataParsed',\n//------------------------------------------\n  WEBSOCKET_ATTACHED: 'wfsWebsocketAttached',\n\n  WEBSOCKET_ATTACHING: 'wfsWebsocketAttaching',\n\n  WEBSOCKET_DATA_UPLOADING: 'wfsWebsocketDataUploading',\n\n  WEBSOCKET_MESSAGE_SENDING: 'wfsWebsocketMessageSending',   \n\n  WEBSOCKET_DATA_SIZE: 'wfsWebsocketDataSize',   \n\n  WEBSOCKET_CONNECT:'wfsWebsocketConnect',\n\n  WEBSOCKET_RECEIVED_MSG:'wfsWebsocketMsg',\n//------------------------------------------\n  FILE_HEAD_LOADING: 'wfsFileHeadLoading',\n\n  FILE_HEAD_LOADED: 'wfsFileHeadLoaded',\n\n  FILE_DATA_LOADING: 'wfsFileDataLoading',\n\n  FILE_DATA_LOADED: 'wfsFileDataLoaded',\n\n  FILE_PARSING_DATA: 'wfsFileParsingData'\n//------------------------------------------\n\n};\n",
    "// This is mostly for support of the es6 module export\n// syntax with the babel compiler, it looks like it doesnt support\n// function exports like we are used to in node/commonjs\nmodule.exports = require('./player.js').default;\n",
    "/*\n * Websocket Loader\n*/\n\nimport Event from '../events';\nimport EventHandler from '../event-handler';\n// import SlicesReader from '../utils/h264-nal-slicesreader.js';\n\nclass WebsocketLoader extends EventHandler {\n\n  constructor(wfs) {\n    super(wfs, \n    Event.WEBSOCKET_ATTACHING,\n    Event.WEBSOCKET_DATA_UPLOADING,\n    Event.WEBSOCKET_MESSAGE_SENDING)   \n    this.buf = null;\n    // this.slicesReader = new SlicesReader(wfs);\n    this.mediaType = undefined; \n    this.channelName = undefined; \n  }\n \n  destroy() { \n\t!!this.client && this.client.close();\n\t// this.slicesReader.destroy();\n    EventHandler.prototype.destroy.call(this);\n  }\n\n  onWebsocketAttaching(data) {\n  \tthis.mediaType = data.mediaType; \n  \tthis.channelName = data.channelName;  \n    if( data.websocket instanceof WebSocket ) {\n      this.client = data.websocket;\n      this.client.onopen = this.initSocketClient.bind(this);   \n      this.client.onclose = function(e) {\n          console.log('Websocket Disconnected!');\n      }; \n    }    \n  }\n\n  initSocketClient(client){\n    // this.client.binaryType = 'arraybuffer';\n    this.client.onmessage = this.receiveSocketMessage.bind(this);\n    this.wfs.trigger(Event.WEBSOCKET_CONNECT, {});\n    // this.wfs.trigger(Event.WEBSOCKET_MESSAGE_SENDING, {commandType: \"open\", channelName:this.channelName, commandValue:\"NA\" });\n    console.log('Websocket Open!'); \n  }\n \n  receiveSocketMessage( event ){\n    if(document['hidden']) return;\n    if((typeof event.data).toLowerCase() === 'string' ) {\n      console.log(\"Received data string\");\n      this.wfs.trigger(Event.WEBSOCKET_RECEIVED_MSG, event.data);\n      return;\n    }\n    this.wfs.trigger(Event.WEBSOCKET_DATA_SIZE, event.data.size);\n\n    this.wfs.trigger(Event.H264_DATA_PARSING, event);\n\n    // this.buf = new Uint8Array(event.data);\n    // var copy = new Uint8Array(this.buf);   \n    \n    // if (this.mediaType ==='FMp4'){\n    //   this.wfs.trigger(Event.WEBSOCKET_ATTACHED, {payload: copy });\n    // } \n    // if (this.mediaType === 'H264Raw'){\n    //   this.wfs.trigger(Event.H264_DATA_PARSING, {data: copy });\n    // }   \n  }\n\n  onWebsocketDataUploading( event ){\n    this.client.send( event.data );\n  }\n  \n  onWebsocketMessageSending( event ){  \n    this.client.send( JSON.stringify({ t: event.commandType, c:event.channelName, v: event.commandValue  }) );\n  }\n\n}\n\nexport default WebsocketLoader;  \n",
    "\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n    value: true\n});\nexports.default = \"\\n.wfs-p-layout-view {\\n    position: relative;\\n    width: 100%;\\n    height: 100%\\n}\\n\\n.wfs-p-layout-view .maximize {\\n    position: absolute !important;\\n    width: 100% !important;\\n    height: 100% !important;\\n    top: 0 !important;\\n    bottom: 0 !important;\\n    left: 0 !important;\\n    right: 0 !important;\\n    border: 1px solid #e8eaec !important;\\n    z-index: 10 !important\\n}\\n\\n.wfs-p-layout-view .maximize .exit {\\n    content: \\\"X\\\";\\n    position: absolute;\\n    top: 5px;\\n    right: 10px;\\n    color: #fff;\\n    font-size: 20px;\\n    cursor: pointer\\n}\\n\\n.wfs-p-layout-view .single-line {\\n    overflow-x: auto;\\n    width: 100%;\\n    height: 100%;\\n    -webkit-box-align: center;\\n    -ms-flex-align: center;\\n    align-items: center\\n}\\n\\n.wfs-p-layout-view .single-line,\\n.wfs-p-layout-view .single-line>div {\\n    display: -webkit-inline-box;\\n    display: -ms-inline-flexbox;\\n    display: inline-flex;\\n    position: relative\\n}\\n\\n.wfs-p-layout-view .single-line .num {\\n    position: relative;\\n    width: 320px;\\n    height: 240px;\\n    border-top: 1px solid #e8eaec;\\n    border-bottom: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .single-line .num:last-child {\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .single-column {\\n    overflow-y: auto;\\n    width: 100%;\\n    height: 100%;\\n    -webkit-box-align: center;\\n    -ms-flex-align: center;\\n    align-items: center\\n}\\n\\n.wfs-p-layout-view .single-column,\\n.wfs-p-layout-view .single-column>div {\\n    display: -webkit-inline-box;\\n    display: -ms-inline-flexbox;\\n    display: inline-flex;\\n    position: relative;\\n    -webkit-box-orient: vertical;\\n    -webkit-box-direction: normal;\\n    -ms-flex-direction: column;\\n    flex-direction: column\\n}\\n\\n.wfs-p-layout-view .single-column .num {\\n    position: relative;\\n    width: 281px;\\n    height: 180px;\\n    border-top: 1px solid #e8eaec;\\n    border-bottom: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .single-column .num:last-child {\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-1 .num-1 {\\n    position: absolute;\\n    top: 0;\\n    bottom: 0;\\n    left: 0;\\n    right: 0;\\n    border: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-2 .num {\\n    position: absolute;\\n    top: 0;\\n    bottom: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-bottom: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-2 .num-1 {\\n    left: 0;\\n    right: 50%\\n}\\n\\n.wfs-p-layout-view .layout-2 .num-2 {\\n    left: 50%;\\n    right: 0;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-4 .num {\\n    position: absolute\\n}\\n\\n.wfs-p-layout-view .layout-4 .num-1 {\\n    left: 0;\\n    right: 50%\\n}\\n\\n.wfs-p-layout-view .layout-4 .num-1,\\n.wfs-p-layout-view .layout-4 .num-2 {\\n    top: 0;\\n    bottom: 50%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-4 .num-2 {\\n    left: 50%;\\n    right: 0;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-4 .num-3 {\\n    top: 50%;\\n    bottom: 0;\\n    left: 0;\\n    right: 50%;\\n    border-top: 1px solid #e8eaec;\\n    border-bottom: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-4 .num-4 {\\n    top: 50%;\\n    bottom: 0;\\n    left: 50%;\\n    right: 0;\\n    border: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-6 .num {\\n    position: absolute\\n}\\n\\n.wfs-p-layout-view .layout-6 .num-1 {\\n    top: 0;\\n    left: 0;\\n    right: 33.333333%;\\n    bottom: 33.333333%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-6 .num-2 {\\n    top: 0;\\n    bottom: 66.666666%\\n}\\n\\n.wfs-p-layout-view .layout-6 .num-2,\\n.wfs-p-layout-view .layout-6 .num-3 {\\n    left: 66.666666%;\\n    right: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-6 .num-3 {\\n    top: 33.333333%;\\n    bottom: 33.333333%\\n}\\n\\n.wfs-p-layout-view .layout-6 .num-4 {\\n    left: 0;\\n    right: 66.666666%\\n}\\n\\n.wfs-p-layout-view .layout-6 .num-4,\\n.wfs-p-layout-view .layout-6 .num-5 {\\n    top: 66.666666%;\\n    bottom: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-bottom: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-6 .num-5 {\\n    left: 33.333333%;\\n    right: 33.333333%\\n}\\n\\n.wfs-p-layout-view .layout-6 .num-6 {\\n    top: 66.666666%;\\n    bottom: 0;\\n    left: 66.666666%;\\n    right: 0;\\n    border: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-8 .num {\\n    position: absolute\\n}\\n\\n.wfs-p-layout-view .layout-8 .num-1 {\\n    top: 0;\\n    bottom: 25%;\\n    left: 0;\\n    right: 25%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-8 .num-2 {\\n    top: 0;\\n    bottom: 75%\\n}\\n\\n.wfs-p-layout-view .layout-8 .num-2,\\n.wfs-p-layout-view .layout-8 .num-3 {\\n    left: 75%;\\n    right: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-8 .num-3 {\\n    top: 25%;\\n    bottom: 50%\\n}\\n\\n.wfs-p-layout-view .layout-8 .num-4 {\\n    top: 50%;\\n    bottom: 25%;\\n    left: 75%;\\n    right: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-8 .num-5 {\\n    left: 0;\\n    right: 75%\\n}\\n\\n.wfs-p-layout-view .layout-8 .num-5,\\n.wfs-p-layout-view .layout-8 .num-6 {\\n    top: 75%;\\n    bottom: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-bottom: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-8 .num-6 {\\n    left: 25%;\\n    right: 50%\\n}\\n\\n.wfs-p-layout-view .layout-8 .num-7 {\\n    top: 75%;\\n    bottom: 0;\\n    left: 50%;\\n    right: 25%;\\n    border-top: 1px solid #e8eaec;\\n    border-bottom: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-8 .num-8 {\\n    top: 75%;\\n    bottom: 0;\\n    left: 75%;\\n    right: 0;\\n    border: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-9 .num {\\n    position: absolute\\n}\\n\\n.wfs-p-layout-view .layout-9 .num-1 {\\n    left: 0;\\n    right: 66.666666%\\n}\\n\\n.wfs-p-layout-view .layout-9 .num-1,\\n.wfs-p-layout-view .layout-9 .num-2 {\\n    top: 0;\\n    bottom: 66.666666%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-9 .num-2 {\\n    left: 33.333333%;\\n    right: 33.333333%\\n}\\n\\n.wfs-p-layout-view .layout-9 .num-3 {\\n    top: 0;\\n    bottom: 66.666666%;\\n    left: 66.666666%;\\n    right: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-9 .num-4 {\\n    left: 0;\\n    right: 66.666666%\\n}\\n\\n.wfs-p-layout-view .layout-9 .num-4,\\n.wfs-p-layout-view .layout-9 .num-5 {\\n    top: 33.333333%;\\n    bottom: 33.333333%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-9 .num-5 {\\n    left: 33.333333%;\\n    right: 33.333333%\\n}\\n\\n.wfs-p-layout-view .layout-9 .num-6 {\\n    top: 33.333333%;\\n    bottom: 33.333333%;\\n    left: 66.666666%;\\n    right: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-9 .num-7 {\\n    left: 0;\\n    right: 66.666666%\\n}\\n\\n.wfs-p-layout-view .layout-9 .num-7,\\n.wfs-p-layout-view .layout-9 .num-8 {\\n    top: 66.666666%;\\n    bottom: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-bottom: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-9 .num-8 {\\n    left: 33.333333%;\\n    right: 33.333333%\\n}\\n\\n.wfs-p-layout-view .layout-9 .num-9 {\\n    top: 66.666666%;\\n    bottom: 0;\\n    left: 66.666666%;\\n    right: 0;\\n    border: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-12 .num {\\n    position: absolute\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-1 {\\n    left: 0;\\n    right: 75%\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-1,\\n.wfs-p-layout-view .layout-12 .num-2 {\\n    top: 0;\\n    bottom: 66.666666%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-2 {\\n    left: 25%;\\n    right: 50%\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-3 {\\n    left: 50%;\\n    right: 25%\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-3,\\n.wfs-p-layout-view .layout-12 .num-4 {\\n    top: 0;\\n    bottom: 66.666666%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-4 {\\n    left: 75%;\\n    right: 0;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-5 {\\n    left: 0;\\n    right: 75%\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-5,\\n.wfs-p-layout-view .layout-12 .num-6 {\\n    top: 33.333333%;\\n    bottom: 33.333333%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-6 {\\n    left: 25%;\\n    right: 50%\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-7 {\\n    left: 50%;\\n    right: 25%\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-7,\\n.wfs-p-layout-view .layout-12 .num-8 {\\n    top: 33.333333%;\\n    bottom: 33.333333%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-8 {\\n    left: 75%;\\n    right: 0;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-9 {\\n    left: 0;\\n    right: 75%\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-9,\\n.wfs-p-layout-view .layout-12 .num-10 {\\n    top: 66.666666%;\\n    bottom: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-10 {\\n    left: 25%;\\n    right: 50%\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-11 {\\n    top: 66.666666%;\\n    bottom: 0;\\n    left: 50%;\\n    right: 25%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-12 .num-12 {\\n    top: 66.666666%;\\n    bottom: 0;\\n    left: 75%;\\n    right: 0;\\n    border: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-13 .num {\\n    position: absolute\\n}\\n\\n.wfs-p-layout-view .layout-13 .num-1 {\\n    top: 25%;\\n    bottom: 25%;\\n    left: 25%;\\n    right: 25%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-13 .num-2 {\\n    top: 0;\\n    bottom: 75%;\\n    left: 0;\\n    right: 75%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-13 .num-3 {\\n    top: 0;\\n    bottom: 75%;\\n    left: 25%;\\n    right: 50%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-13 .num-4 {\\n    top: 0;\\n    bottom: 75%;\\n    left: 50%;\\n    right: 25%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-13 .num-5 {\\n    top: 0;\\n    bottom: 75%;\\n    left: 75%;\\n    right: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-13 .num-6 {\\n    left: 0;\\n    right: 75%\\n}\\n\\n.wfs-p-layout-view .layout-13 .num-6,\\n.wfs-p-layout-view .layout-13 .num-7 {\\n    top: 25%;\\n    bottom: 50%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-13 .num-7 {\\n    left: 75%;\\n    right: 0;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-13 .num-8 {\\n    left: 0;\\n    right: 75%\\n}\\n\\n.wfs-p-layout-view .layout-13 .num-8,\\n.wfs-p-layout-view .layout-13 .num-9 {\\n    top: 50%;\\n    bottom: 25%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-13 .num-9 {\\n    left: 75%;\\n    right: 0;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-13 .num-10 {\\n    top: 75%;\\n    bottom: 0;\\n    left: 0;\\n    right: 75%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-13 .num-11 {\\n    top: 75%;\\n    bottom: 0;\\n    left: 25%;\\n    right: 50%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-13 .num-12 {\\n    top: 75%;\\n    bottom: 0;\\n    left: 50%;\\n    right: 25%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-13 .num-13 {\\n    top: 75%;\\n    bottom: 0;\\n    left: 75%;\\n    right: 0;\\n    border: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-16 .num {\\n    position: absolute\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-1 {\\n    top: 0;\\n    bottom: 75%;\\n    left: 0;\\n    right: 75%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-2 {\\n    top: 0;\\n    bottom: 75%;\\n    left: 25%;\\n    right: 50%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-3 {\\n    top: 0;\\n    bottom: 75%;\\n    left: 50%;\\n    right: 25%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-4 {\\n    top: 0;\\n    bottom: 75%;\\n    left: 75%;\\n    right: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-5 {\\n    left: 0;\\n    right: 75%\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-5,\\n.wfs-p-layout-view .layout-16 .num-6 {\\n    top: 25%;\\n    bottom: 50%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-6 {\\n    left: 25%;\\n    right: 50%\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-7 {\\n    left: 50%;\\n    right: 25%\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-7,\\n.wfs-p-layout-view .layout-16 .num-8 {\\n    top: 25%;\\n    bottom: 50%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-8 {\\n    left: 75%;\\n    right: 0;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-9 {\\n    left: 0;\\n    right: 75%\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-9,\\n.wfs-p-layout-view .layout-16 .num-10 {\\n    top: 50%;\\n    bottom: 25%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-10 {\\n    left: 25%;\\n    right: 50%\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-11 {\\n    top: 50%;\\n    bottom: 25%;\\n    left: 50%;\\n    right: 25%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-12 {\\n    top: 50%;\\n    bottom: 25%;\\n    left: 75%;\\n    right: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-13 {\\n    top: 75%;\\n    bottom: 0;\\n    left: 0;\\n    right: 75%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-14 {\\n    top: 75%;\\n    bottom: 0;\\n    left: 25%;\\n    right: 50%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-15 {\\n    top: 75%;\\n    bottom: 0;\\n    left: 50%;\\n    right: 25%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-16 .num-16 {\\n    top: 75%;\\n    bottom: 0;\\n    left: 75%;\\n    right: 0;\\n    border: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-17 .num {\\n    position: absolute\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-2 {\\n    top: 0;\\n    bottom: 80%;\\n    left: 0;\\n    right: 80%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-3 {\\n    top: 0;\\n    bottom: 80%;\\n    left: 20%;\\n    right: 60%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-4 {\\n    top: 0;\\n    bottom: 80%;\\n    left: 40%;\\n    right: 40%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-5 {\\n    top: 0;\\n    bottom: 80%;\\n    left: 60%;\\n    right: 20%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-6 {\\n    top: 0;\\n    bottom: 80%;\\n    left: 80%;\\n    right: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-7 {\\n    top: 20%;\\n    bottom: 60%;\\n    left: 0;\\n    right: 80%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-1 {\\n    top: 20%;\\n    bottom: 20%;\\n    left: 20%;\\n    right: 20%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-8 {\\n    top: 20%;\\n    bottom: 60%;\\n    left: 80%;\\n    right: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-9 {\\n    left: 0;\\n    right: 80%\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-9,\\n.wfs-p-layout-view .layout-17 .num-10 {\\n    top: 40%;\\n    bottom: 40%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-10 {\\n    left: 80%;\\n    right: 0;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-11 {\\n    top: 60%;\\n    bottom: 20%;\\n    left: 0;\\n    right: 80%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-12 {\\n    top: 60%;\\n    bottom: 20%;\\n    left: 80%;\\n    right: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-13 {\\n    left: 0;\\n    right: 80%\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-13,\\n.wfs-p-layout-view .layout-17 .num-14 {\\n    top: 80%;\\n    bottom: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-bottom: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-14 {\\n    left: 20%;\\n    right: 60%\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-15 {\\n    left: 40%;\\n    right: 40%\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-15,\\n.wfs-p-layout-view .layout-17 .num-16 {\\n    top: 80%;\\n    bottom: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-bottom: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-16 {\\n    left: 60%;\\n    right: 20%\\n}\\n\\n.wfs-p-layout-view .layout-17 .num-17 {\\n    top: 80%;\\n    bottom: 0;\\n    left: 80%;\\n    right: 0;\\n    border: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num {\\n    position: absolute\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-1 {\\n    top: 0;\\n    bottom: 80%;\\n    left: 0;\\n    right: 80%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-2 {\\n    top: 0;\\n    bottom: 80%;\\n    left: 20%;\\n    right: 60%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-3 {\\n    top: 0;\\n    bottom: 80%;\\n    left: 40%;\\n    right: 40%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-4 {\\n    top: 0;\\n    bottom: 80%;\\n    left: 60%;\\n    right: 20%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-5 {\\n    top: 0;\\n    bottom: 80%;\\n    left: 80%;\\n    right: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-6 {\\n    left: 0;\\n    right: 80%\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-6,\\n.wfs-p-layout-view .layout-25 .num-7 {\\n    top: 20%;\\n    bottom: 60%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-7 {\\n    left: 20%;\\n    right: 60%\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-8 {\\n    left: 40%;\\n    right: 40%\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-8,\\n.wfs-p-layout-view .layout-25 .num-9 {\\n    top: 20%;\\n    bottom: 60%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-9 {\\n    left: 60%;\\n    right: 20%\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-10 {\\n    top: 20%;\\n    bottom: 60%;\\n    left: 80%;\\n    right: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-11 {\\n    top: 40%;\\n    bottom: 40%;\\n    left: 0;\\n    right: 80%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-12 {\\n    top: 40%;\\n    bottom: 40%;\\n    left: 20%;\\n    right: 60%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-13 {\\n    top: 40%;\\n    bottom: 40%;\\n    left: 40%;\\n    right: 40%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-14 {\\n    top: 40%;\\n    bottom: 40%;\\n    left: 60%;\\n    right: 20%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-15 {\\n    top: 40%;\\n    bottom: 40%;\\n    left: 80%;\\n    right: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-16 {\\n    top: 60%;\\n    bottom: 20%;\\n    left: 0;\\n    right: 80%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-17 {\\n    top: 60%;\\n    bottom: 20%;\\n    left: 20%;\\n    right: 60%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-18 {\\n    top: 60%;\\n    bottom: 20%;\\n    left: 40%;\\n    right: 40%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-19 {\\n    top: 60%;\\n    bottom: 20%;\\n    left: 60%;\\n    right: 20%;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-20 {\\n    top: 60%;\\n    bottom: 20%;\\n    left: 80%;\\n    right: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-right: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-21 {\\n    left: 0;\\n    right: 80%\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-21,\\n.wfs-p-layout-view .layout-25 .num-22 {\\n    top: 80%;\\n    bottom: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-bottom: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-22 {\\n    left: 20%;\\n    right: 60%\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-23 {\\n    left: 40%;\\n    right: 40%\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-23,\\n.wfs-p-layout-view .layout-25 .num-24 {\\n    top: 80%;\\n    bottom: 0;\\n    border-top: 1px solid #e8eaec;\\n    border-left: 1px solid #e8eaec;\\n    border-bottom: 1px solid #e8eaec\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-24 {\\n    left: 60%;\\n    right: 20%\\n}\\n\\n.wfs-p-layout-view .layout-25 .num-25 {\\n    top: 80%;\\n    bottom: 0;\\n    left: 80%;\\n    right: 0;\\n    border: 1px solid #e8eaec\\n}\\n\\n.wfsplayer-layout-wrapper {\\n    position: relative;\\n    width: 100%;\\n    height: 100%;\\n    font-size: 12px\\n}\\n\\n.wfsplayer-layout-wrapper .player {\\n    background-color: #516f8a;\\n    z-index: 9\\n}\\n\\n.wfsplayer-layout-wrapper video {\\n    width: 100%;\\n    height: 100%;\\n    -o-object-fit: fill;\\n    object-fit: fill\\n}\\n\\n.wfsplayer-layout-wrapper .plate-text {\\n    width: calc(100% - 5px);\\n    margin-right: 5px;\\n    background: transparent;\\n    text-align: end;\\n    display: block;\\n    padding-right: 5px\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-bar,\\n.wfsplayer-layout-wrapper .plate-text {\\n    border-radius: 1px;\\n    height: 26px;\\n    line-height: 26px;\\n    color: #fff;\\n    font-size: 12px;\\n    position: absolute;\\n    bottom: 0;\\n    -webkit-user-select: none;\\n    -moz-user-select: none;\\n    -ms-user-select: none;\\n    user-select: none;\\n    -webkit-transition: opacity .3s ease 0s;\\n    transition: opacity .3s ease 0s;\\n    opacity: 1\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-bar {\\n    display: -webkit-box;\\n    display: -ms-flexbox;\\n    display: flex;\\n    -webkit-box-pack: end;\\n    -ms-flex-pack: end;\\n    justify-content: flex-end;\\n    -ms-flex-wrap: nowrap;\\n    flex-wrap: nowrap;\\n    -webkit-box-align: center;\\n    -ms-flex-align: center;\\n    align-items: center;\\n    width: calc(100% - 1px);\\n    padding-left: 3px;\\n    background-color: #fafafa;\\n    overflow: hidden\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-block {\\n    margin-right: 2px;\\n    width: 26px;\\n    height: 100%;\\n    background-size: 20px;\\n    background-color: initial;\\n    color: inherit;\\n    -webkit-box-sizing: border-box;\\n    box-sizing: border-box;\\n    background-repeat: no-repeat;\\n    background-position: 50%;\\n    overflow: hidden;\\n    cursor: pointer\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-block:hover {\\n    border: 1px solid #95a5a6\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-plate-text {\\n    -webkit-box-flex: 1;\\n    -ms-flex-positive: 1;\\n    flex-grow: 1;\\n    color: #5a5a5a;\\n    text-overflow: ellipsis;\\n    white-space: nowrap;\\n    overflow: hidden\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-download-speed {\\n    color: #5a5a5a;\\n    width: 65px;\\n    text-align: end\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-codetype {\\n    color: #4885d4\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-stop {\\n    background-image: url(data:image/png;base64,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)\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-snapshot {\\n    background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACUAAAAgCAYAAACVU7GwAAADCUlEQVRYR81XTVITURD+ehIUq6iSGwBLJCngBISFZlypNwg3wKUMFqHM4FI8AXACceVEFyQnIFQGWRJOIFZpiUqmrR6YYWZ885eklOxS81739/p9/fX3CLfwRx4m3TzeUOLTtD3rxWxPvumvuhVo2tLQ53CctvWy3IqLEwBls3KRw8sS4NHW56caO++GBnQdgBnPm+ulbVW8AKhuXV2p4q5USje7LYCGr5KfhNuWUa4kgkqrwH8BVamfTt67czEfB87h/jYBC2ngs35noKNRYdVb/+PX+FGrPnMu/93rE76Q098hosmsQUe9jpnPWSusfFx7sE9XHUUHI0nCOANxD0zTIEwNFNPhZRqeK7wJB62L/kTHK78vM+6BUWFglUD3s4HkNlUb3S+DXBszjhyi2idjrpOWTH99Ms39/j4RYjnrxZBrJN2M0aeETAy8bRoln6RpoG4EWmSH1CIdCDIAqHh9kbiPt06WPqzNtuOAVhu2VOxJ0kFygWLwV9KKC97Y8QK73cvORkQyegBtWsbcbhCASM/dsW+9JI7lAgXQSjSJbto7AGpxJ2fwftMoPwt+T+v4zKCkSk2jHNKxasNeJcKbdE7xpmWUQ2Os2rA7ccTPDAoIc+mqoy4PM3euVpgJXnsStzKDinZcXtcQdQW6Gd+JmUFF+ZQUVHmdjD1rveRzL4lX/wxUtNIjAXVLry9M9Cx6448Ohb6NhOiSwDJKvlP1LE8Wi6yyvrppnwKYVjrPfLPvb71JI7xqTurmcQ1gEV3lLwfRr/b3QYtRZ/DQPF7QmOvumCFMueMI6MBBPfpqyaJvuUGJjW0apcV0FVev0Bv2AQjKB4O3Izco2Sjz7OfviZWoqUsCKo0xPvZdRlLsnPRBVc3ueXZXeJM26KnTqnatScIhJbFD+xlnlMXfJCWVqgFoaVTsBH2U8KzAPH99VanV8eWD8Z7czeDDtNPm+C5P/PSKKAJKgzjQKq7uuOUl2h34BZIDcexSeQkx16RbQ2Io7YrLy4FOORSuYrEXtDUhUEMFHuHmPyfRoJlWO/FbAAAAAElFTkSuQmCC)\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-muted {\\n    background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAACp0lEQVRYR8VXTZLSQBh9X4DSKjZ4goGlTii5gcxCyXI8weAJHJcaLLGG6FI8gXgCdBd0IXOCwYLRpdzAcYHllEw+q1PToUk65Icpp5ekyXv9vq/f90K45kXXjI+tCVhH0+aFYZx9tncneQ6Tm0Cz+6Nys7gYgtAUwB4ZDz89u/MhK4lcBMSpmTAkoooEZMbHUcfc1xFo9WaHHtFYp1JmApYz7QL0IgrEx65d99VQl9WbDUA4YMaTUcfsh5+nJhCWPA0BBfzr+bLcHHdrZxsJWK+/V4mxE97keV4F8Aaq5EkE0oCLdwQKCHC+WJ5sBolvMbUHdOD+b4VC1316e66+ZUXgaNqEQV+ydrHYz4xAYh34g1ff9g32hmCM3Y65d6UEksAlWKs3mxDhLoxCTVVhKwXSggsSlnPaBvgdGO/djtmWxHITSALX1dxyZgxg7tpmbSsCSeBBzcEvXbvelWCWMx0DdO/P3/IteSUzK5AELsB8zygtfgLr5hSYmMd77vP6eP0aprgFacDDTefa5uqQ0kXzEEgCF03m2ruDQO7ebA7CzpUQSAT3/Z6rchbIEoj/jTpmI1DFmfUJeIwsCqQDx4Fab1lrBt6ObPMw3ISqKhubMD2474f+NJSWDgKRUWxI04lTJZZANnCFQDCu6dFaT1waUVgVLYHs4CsC4qSl0u9qOHxYl02ZaMX5wFcEdMNMJCIivAnbcMQHmKgvg0PsSCXRcLqlT0T3ndNGAXzC4F9qT0SsWDqYsMjs4PEKSOnjQmskksUlmfgsKM+iV6Dl332aqA2pzQPiR1krtQ/UzUJOg3ngz/XI0hNICjhrCogOvlFctM+X5YEuQCqGEknGm2L5JhKpU3H4JcJw4C0HYryKZ//1w0Qlc22fZkm1Tfs8dwnSAiTt+wevK7s/Y5o+4AAAAABJRU5ErkJggg==)\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-volume {\\n    background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAACjElEQVRYR+2W0W4SURCGZ5Y2mNSk9Amkl9ol1DeAC2XvhCfo9gnkVhfTTWT1svoE8Ab2clcv5A1qwlYv0SewJjTBCGfMLD317AG2uxZKYuSG5HA4880//5k5CGv+4Jrjw78BUHEHhfzm8IAw9+398wcnWVS9sQKPX32uo5h0ELFAROdBq7RzKwCXWXcQsK4G9B0zU1KZNstAtXbYBKAjzlrPdqUA1usvRZhMOoBQWSSzDmB5ZzYQHYzGW42eu3uu/y+1AklZJ5WAS3Vnc3hCBGWBRvWDs/dJ3T8XwHrZr2Bug3ijEKKAQM2krNN4wGqHXQJ68nN8d1dVIgagOjqLk3WAKOv8qOA/u/9V/c3y+j0C3A4c86FcvwLg+tJkfDrPWFlg2AOciEHiHQAe+s5eV/5/Wo6L7yCo6r8o9Xj9DwCbBaiTJdi8vdKEkfn4PCUY7+dS8LffMm0NoO8C4NGyAPicmhe+QYKy3zKr8lypjgRVFFg+wCPvbD8HdKpeTbk2+rW1w2ZcKUAkuRfSTBmUtZUC6NlGQNzMxGRwKwpYXt8lwnrQMvelB7jHgIEfZzzAnQ4RjpdlQpm9QKOhjujoFiAVfacUtfNYH2BplgEgnU4AbwPHbKp9IL8xHJCRO5RQsU54dXdvQMHScvaIWNQfJ7V2yI+VolqSmVkwNYmoAIii5CCAJgJup+FaNI4jPwA0BRgVdSClmobTx8eFiwBPr4PQAS7b7zEBNQhztq5KKoCYgxG7gHBvEYgOMB3jYAtEWx/FMRNel1nMSAlqrPRFpEKy0QyiLiKU9XGcNpm/UkA/nM0lhxgB/Qic0sw7MQkokwcWHTS9OWMbBPTknE+rwlIA0gabt+8/wNoV+A2EdkkwivO81wAAAABJRU5ErkJggg==)\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-fullscreen {\\n    background-image: url(data:image/png;base64,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)\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-minimize {\\n    background-image: url(data:image/png;base64,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)\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-pause {\\n    background-image: url(data:image/png;base64,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)\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-playing {\\n    background-image: url(data:image/png;base64,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)\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-download {\\n    background-image: url(data:image/png;base64,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)\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-codetype-pane {\\n    position: absolute;\\n    bottom: 26px;\\n    width: 60px;\\n    background-color: rgba(0, 0, 0, .5);\\n    color: #fff;\\n    right: 100px;\\n    cursor: pointer\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-codetype-pane .codetype-item {\\n    padding: 5px 0;\\n    text-align: center\\n}\\n\\n.wfsplayer-layout-wrapper .ctrl-codetype-pane .codetype-item:hover {\\n    background-color: rgba(41, 182, 246, .4)\\n}\\n\\n.wfsplayer-layout-wrapper .log-pane {\\n    border-radius: 1px;\\n    width: 100%;\\n    height: 40%;\\n    line-height: 16px;\\n    color: #fff;\\n    font-size: 12px;\\n    padding-left: 8px;\\n    padding-right: 5px;\\n    background: transparent;\\n    position: absolute;\\n    bottom: 0;\\n    text-align: center;\\n    -webkit-box-align: center;\\n    -ms-flex-align: center;\\n    align-items: center;\\n    -webkit-box-pack: center;\\n    -ms-flex-pack: center;\\n    justify-content: center;\\n    -webkit-user-select: none;\\n    -moz-user-select: none;\\n    -ms-user-select: none;\\n    user-select: none;\\n    -webkit-transition: opacity .3s ease 0s;\\n    transition: opacity .3s ease 0s\\n}\\n\\n.wfsplayer-layout-wrapper .log-pane .log-line {\\n    line-height: 16px;\\n    text-overflow: ellipsis;\\n    white-space: nowrap;\\n    overflow: hidden;\\n    font-size: 13px\\n}\\n\\n.wfsplayer-layout-wrapper .replay-pane {\\n    border-radius: 1px;\\n    width: 100%;\\n    height: 100%;\\n    color: #fff;\\n    background: transparent;\\n    position: absolute;\\n    bottom: 0;\\n    -webkit-box-align: center;\\n    -ms-flex-align: center;\\n    align-items: center;\\n    -webkit-box-pack: center;\\n    -ms-flex-pack: center;\\n    justify-content: center;\\n    -webkit-user-select: none;\\n    -moz-user-select: none;\\n    -ms-user-select: none;\\n    user-select: none;\\n    display: -webkit-box;\\n    display: -ms-flexbox;\\n    display: flex\\n}\\n\\n.wfsplayer-layout-wrapper .replay-pane .replay-img {\\n    width: 44px;\\n    height: 44px;\\n    cursor: pointer;\\n    background-image: url(data:image/png;base64,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);\\n    background-repeat: round\\n}\\n\\n.wfsplayer-layout-wrapper .replay-pane .replay-img:hover {\\n    background-image: url(data:image/png;base64,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)\\n}\\n\";\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJzb3VyY2VzIjpbXSwibmFtZXMiOltdLCJtYXBwaW5ncyI6IiIsImZpbGUiOiJwbGF5ZXIuY3NzLmpzIiwic291cmNlc0NvbnRlbnQiOltdfQ==",
    "/**\n * WFS interface, Jeff Yang 2016.10\n */\n// 'use strict';\n\nimport Event from './events';\nimport EventHandler from './event-handler'; \nimport Wfs from './wfs';\nimport cssStr from './player.css.js';\n\nconst Status = {\n  IDEL:\"idel\",\n  PLAYING: 'playing',\n  PAUSE: 'pause',\n  STOP: 'stop',\n}\n\nclass WfsHandler extends EventHandler{\n    constructor(wfs , player) {\n        super(wfs,\n            Event.MEDIA_ATTACHING,  \n \n            Event.BUFFER_CREATED, \n\n            Event.FRAG_PARSING_INIT_SEGMENT,\n            Event.WEBSOCKET_DATA_SIZE,\n            Event.WEBSOCKET_RECEIVED_MSG,\n            Event.WEBSOCKET_CONNECT\n        );\n        this.lastReceviedTime = new Date()\n\n        this.player = player\n\n        this.size = 0;\n        this.timeid = setInterval(() => {\n            if(this.player.status == Status.PLAYING){\n                if(new Date().getTime() - this.lastReceviedTime.getTime() > this.player.config.timeout * 1000 ){\n                    //长时间未收到视频数据，断开视频\n                    this.player.stop()\n                    this.player.showMsg('视频信号中断，请重新开始！')\n                }\n            }\n            this.player.updateNetworkSpeed((this.size/1024.0).toFixed(2))\n            this.size = 0\n        }, 1000);\n    } \n    destroy() {\n        this.player.updateNetworkSpeed('0.00')\n        clearInterval(this.timeid)\n        EventHandler.prototype.destroy.call(this);\n    }\n\n    onMediaAttaching(){\n        this.player.showMsg('正在请求视频。。。')\n        console.log('wfsMediaAttaching')\n        \n    }\n    onBufferCreated(){\n        //\n        this.player.showMsg('设备响应成功，视频加载中。')\n        console.log('onBufferCreated')\n    }\n    onFragParsingInitSegment(){\n        //第一帧\n        this.player.hideMsg()\n        console.log('onFragParsingInitSegment')\n    }\n\n    onWebsocketDataSize(size){\n        this.size += size\n        this.lastReceviedTime = new Date()\n    }\n    onWebsocketMsg(data){\n        try {\n            let res = JSON.parse(data || '')\n            if(res && res.resultCode){\n                this.player.stop()\n                this.player.showMsg(res.resultMsg||'')\n            }\n        } catch (e) {\n        \n        }\n    }\n\n    onWebsocketConnect(){\n        if( !this.player.config.isReal && this.player.config.recodeData){\n            this.player.client && this.player.client.send(this.player.config.recodeData)\n        }\n        \n        if(this.player.client){\n            this.player.heart()\n        }\n        // if(this.player.client){\n        //     // 发送开始指令\n        //     this.player.client.send(`{\"url\":\"${this.player.config.baseUrl}/iot/jt808-out/cameraVedio\",\n        //     \"token\":\"${this.player.config.token}\",\"temiCode\":\"${this.player.config.temiCode}\",\n        //     \"channelId\":${this.player.config.channel},\"streamType\":1,\"dataType\":1}`\n        //     )\n        // }\n    }\n}\n\nclass WfsPlayer{\n\n    static get DefaultConfig() {\n        if (!WfsPlayer.defaultConfig) {\n            WfsPlayer.defaultConfig = {\n                id:'video-container',\n                deviceName:'测试设备',\n                channel: 1,\n                url:'ws://127.0.0.1:8094/websocket',\n                baseUrl:'http://192.168.1.217:8100',\n                token:'',\n                temiCode:'',\n                poster:'',\n                timeout: 30,\n                isReal:true,//默认是直播\n            };\n        }\n        return WfsPlayer.defaultConfig;\n    }\n    constructor(config = {}) {\n        var defaultConfig = WfsPlayer.DefaultConfig;\n        for (var prop in defaultConfig) {\n            if (prop in config) { continue; }\n            config[prop] = defaultConfig[prop];\n        }\n        this.config = config;  \n\n        this.status = Status.IDEL\n\n        WfsPlayer.createStyle()\n        this.container = document.querySelector(\"#\" + this.config.id);\n        this.container.innerHTML = this.createEl()\n        this.media = this.container.querySelector('#container_video_1');\n        \n        this.initEvent()\n    }\n    play(config) {\n        if(config && config.recodeData){\n            this.config.recodeData = config.recodeData\n            this.config.channel = config.channel\n            this.config.url = config.url\n        }\n        if(!this.config.isReal && !this.config.recodeData){\n            //没有回放数据则不播放\n            return;\n        }\n\n        if(this.status == Status.PLAYING){\n            this.stop()\n        }\n        this.status = Status.PLAYING\n\n        try {\n            this.container.querySelector('.ctrl-stop')['style']=\"\"\n            this.container.querySelector('.ctrl-playing')['style']=\"display:none;\"\n            this.container.querySelector('.replay-pane')['style']=\"display:none;\"\n        } catch (e) {\n        \n        }\n\n        if(!this.client || this.client.readyState == 3){\n            this.wfs = new Wfs()\n            this.wfsHandler = new WfsHandler(this.wfs , this)\n            this.wfs.attachMedia(this.media)\n            this.client = new WebSocket(this.config.url)\n            let self = this\n            this.client.onclose = function(e) {\n                self.stop()\n                self.showMsg('视频信号已中断，请重新开始！')\n            }; \n            this.wfs.attachWebsocket(this.client)\n        }\n\n\n        // if(this.client && this.client.readyState == 1){\n        //     //恢复播放指令\n        //     this.client.send(`{\"url\":\"${this.config.baseUrl}/iot/jt808-out/controllVedio\",\n        //     \"token\":\"${this.config.token}\",\"temiCode\":\"${this.config.temiCode}\",\n        //     \"channelId\":${this.config.channel},\"controllCommand\":3,\"changeStreamType\":1,\"audioOrVedio\":2}`\n        //     )\n        // }\n        \n    }\n\n    stop(){\n        this._heart && clearInterval(this._heart)\n        this._heart = null\n\n        this.status = Status.STOP\n        this.media.src='/'\n        \n        try {\n            this.container.querySelector('.ctrl-stop')['style']=\"display:none;\"\n            this.container.querySelector('.ctrl-playing')['style']=\"\"\n            this.container.querySelector('.replay-pane')['style']=\"\"\n        } catch (e) {\n        \n        }\n        \n        this.hideMsg()\n\n        // if(this.client && this.client.readyState == 1){\n        //     //暂停播放指令\n        //         this.client.send(`{\"url\":\"${this.config.baseUrl}/iot/jt808-out/controllVedio\",\n        //     \"token\":\"${this.config.token}\",\"temiCode\":\"${this.config.temiCode}\",\n        //     \"channelId\":${this.config.channel},\"controllCommand\":2,\"changeStreamType\":1,\"audioOrVedio\":2}`\n        //     )\n        // }\n\n        this.wfsHandler && this.wfsHandler.destroy()\n        this.wfs && this.wfs.destroy()\n        this.client = null;\n    }\n    heart(){\n        this._heart = setInterval(() => {\n            if(this.client && this.client.readyState == 1){\n                //心跳指令\n                this.client.send('heart')\n            }\n        }, 5000);\n    }\n    //进入全屏\n    FullScreen() {\n        let ele = this.container\n        if (ele.requestFullscreen) {\n            ele.requestFullscreen();\n        } else if (ele.mozRequestFullScreen) {\n            ele.mozRequestFullScreen();\n        } else if (ele.webkitRequestFullScreen) {\n            ele.webkitRequestFullScreen();\n        }\n    }\n\n    //退出全屏\n    exitFullscreen() {\n        var de = document;\n        if (de.exitFullscreen) {\n            de.exitFullscreen();\n        } else if (de.mozCancelFullScreen) {\n            de.mozCancelFullScreen();\n        } else if (de.webkitCancelFullScreen) {\n            de.webkitCancelFullScreen();\n        }\n    }\n\n    initEvent(){\n        let self = this\n        this.media.addEventListener('playing',function(){\n            self.hideMsg()\n        },false);\n        this.media.addEventListener('canplay',function(){\n            self.media.play()\n        },false);\n\n        this.container.querySelector('.replay-img').addEventListener('click', function () {\n            self.media.load();\n            self.play()\n        })\n        this.container.querySelector('.ctrl-playing').addEventListener('click',function () {\n            self.media.load();\n            self.play()\n        })\n        this.container.querySelector('.ctrl-stop').onclick = function () {\n            self.stop()\n        }\n        this.container.querySelector('.ctrl-fullscreen').onclick = function () {\n            try {\n                self.container.querySelector('.ctrl-fullscreen')['style']='display: none;'\n                self.container.querySelector('.ctrl-minimize')['style']=''\n            } catch (e) {\n            \n            }\n            \n            self.FullScreen()\n        }\n        this.container.querySelector('.ctrl-minimize').onclick = function () {\n            try {\n                self.container.querySelector('.ctrl-minimize')['style']='display: none;'\n                self.container.querySelector('.ctrl-fullscreen')['style']=''\n            } catch (e) {\n            \n            }\n          \n            self.exitFullscreen()\n        }\n        \n        this.container.querySelector('#container_1').onmouseover = function () {\n            try {\n                self.container.querySelector('.ctrl-bar')['style'] = \"\"\n            } catch (e) {\n            \n            }\n        }\n        this.container.querySelector('#container_1').onmouseout = function () {\n            try {\n                self.container.querySelector('.ctrl-bar')['style'] = \"display: none;\"\n            } catch (e) {\n            \n            }\n        }\n    }\n\n    showMsg(msg) {\n        try {\n            let log = this.container.querySelector('.log-pane')\n            log['style'] = \"display: block;\"\n            log.innerHTML = msg\n        } catch (e) {\n        \n        }\n        \n    }\n\n    hideMsg() {\n        try {\n            this.container.querySelector('.log-pane')['style'] = \"display: none;\"\n        } catch (e) {\n        \n        }\n    }\n\n    updateNetworkSpeed(speed = '0.00'){\n        try {\n            let el = this.container.querySelector('.plate-text')\n            el.innerHTML = `${speed}KB/s ${this.config.deviceName} &amp; ${this.config.channel}`\n    \n            el = this.container.querySelector('.ctrl-download-speed')\n            el.innerHTML = `${speed}KB/s`\n        } catch (e) {\n        \n        }\n        \n    }\n\n    createEl(name, poster) {\n        let content = this.createVideoEl(1, name, poster)\n        return `<div class=\"wfs-p-layout-view wfsplayer-layout-wrapper\"><div class=\"layout-1\"><div>${content}</div></div></div>`\n    }\n\n    createVideoEl(index) {\n        document.createElement('div' )\n        return `<div id=\"container_${index}\" draggable=\"true\" class=\"player num num-${index}\">\n        <video id=\"container_video_${index}\" autoplay=\"autoplay\" preload=\"none\" muted=\"muted\" type=\"video/mp4\" poster=\"/poster.png\">\n            <audio id=\"container_audio_${index}\" muted=\"muted\" autoplay=\"autoplay\" ></audio>\n        </video>\n                <div class=\"log-pane\" style=\"display: none;\"></div>\n                <div class=\"replay-pane\" style=\"\">\n                    <div class=\"replay-img\"></div>\n                </div>\n                <div class=\"plate-text\">0.00KB/s ${this.config.deviceName} &amp; ${this.config.channel}</div>\n                <div class=\"ctrl-bar\" style=\"display: none;\">\n                    <div class=\"ctrl-block ctrl-plate-text\">${this.config.deviceName} &amp; ${this.config.channel}</div>\n                    <div class=\"ctrl-block ctrl-download-speed\">0.00KB/s</div>\n                    <div class=\"ctrl-block ctrl-codetype\" style=\"\">标清</div>\n                    <div title=\"停止\" class=\"ctrl-block ctrl-stop\"></div>\n                    <div class=\"ctrl-block ctrl-playing\" style=\"display: none;\"></div>\n                    <div title=\"截图\" class=\"ctrl-block ctrl-snapshot\" style=\"display: none;\"></div>\n                    <div title=\"开启音频\" class=\"ctrl-block ctrl-muted\" style=\"display: none;\"></div>\n                    <div title=\"全屏\" class=\"ctrl-block ctrl-fullscreen\"></div>\n                    <div title=\"退出全屏\" class=\"ctrl-block ctrl-minimize\" style=\"display: none;\"></div>\n                    <div class=\"ctrl-block ctrl-download\" style=\"display: none;\"></div>\n                </div>\n                <div class=\"ctrl-codetype-pane\" style=\"display: none;\">\n                    <div class=\"codetype-item\">高清</div>\n                    <div class=\"codetype-item\">标清</div>\n                </div>\n            </div>`\n    }\n\n    static createStyle() {\n        if(WfsPlayer.__create_style)return\n        WfsPlayer.__create_style = true\n        let style = document.createElement(\"style\");\n        style.type = \"text/css\";\n        style.innerHTML = cssStr;\n        document.getElementsByTagName(\"HEAD\").item(0).appendChild(style);\n    }\n\n}\n\n\n\nexport default WfsPlayer",
    "/**\n * XHR based logger\n*/\n\n \nclass XhrLoader {\n\n  constructor(config) {\n    if (config && config.xhrSetup) {\n      this.xhrSetup = config.xhrSetup;\n    }\n  }\n\n  destroy() {\n    this.abort();\n    this.loader = null;\n  }\n\n  abort() {\n    var loader = this.loader;\n    if (loader && loader.readyState !== 4) {\n      this.stats.aborted = true;\n      loader.abort();\n    }\n\n    window.clearTimeout(this.requestTimeout);\n    this.requestTimeout = null;\n    window.clearTimeout(this.retryTimeout);\n    this.retryTimeout = null;\n  }\n\n  loadHead(context, config, callbacks) {\n    this.context = context;\n    this.config = config;\n    this.callbacks = callbacks;\n    this.stats = {trequest: performance.now(), retry: 0};\n    this.retryDelay = config.retryDelay;\n    var xhr = new XMLHttpRequest;\n    xhr.open('head', context.url);\n    xhr.onload = function () {\n          callbacks.onSuccess(xhr.getResponseHeader('content-length'));\n    };\n    xhr.send();\n  }\n\n  load(context, config, callbacks) {\n    this.context = context;\n    this.config = config;\n    this.callbacks = callbacks;\n    this.stats = {trequest: performance.now(), retry: 0};\n    this.retryDelay = config.retryDelay;\n    this.loadInternal(); \n  }\n \n  loadInternal() {\n    var xhr, context = this.context;\n    if (typeof XDomainRequest !== 'undefined') {\n       xhr = this.loader = new XDomainRequest();\n    } else {\n       xhr = this.loader = new XMLHttpRequest();\n    }\n    xhr.onloadend = this.loadend.bind(this);\n    xhr.onprogress = this.loadprogress.bind(this);\n    xhr.open('GET', context.url, true);\n    if (context.rangeEnd) {\n      xhr.setRequestHeader('Range','bytes=' + context.rangeStart + '-' + (context.rangeEnd-1));\n    }\n    xhr.responseType = context.responseType;\n    let stats = this.stats;\n    stats.tfirst = 0;\n    stats.loaded = 0;\n    if (this.xhrSetup) {\n      this.xhrSetup(xhr, context.url);\n    }     \n    // setup timeout before we perform request\n    this.requestTimeout = window.setTimeout(this.loadtimeout.bind(this), this.config.timeout);\n    xhr.send();\n  }\n\n  loadend(event) {\n    var xhr = event.currentTarget,\n        status = xhr.status,\n        stats = this.stats,\n        context = this.context,\n        config = this.config;\n    // don't proceed if xhr has been aborted\n    if (stats.aborted) {\n      return;\n    }\n    // in any case clear the current xhrs timeout\n    window.clearTimeout(this.requestTimeout);\n\n    // http status between 200 to 299 are all successful\n    if (status >= 200 && status < 300)  {\n      stats.tload = Math.max(stats.tfirst,performance.now());\n      let data,len;\n      if (context.responseType === 'arraybuffer') {\n        data = xhr.response;\n        len = data.byteLength;\n      } else {\n        data = xhr.responseText;\n        len = data.length;\n      }\n      stats.loaded = stats.total = len;\n      let response = { url : xhr.responseURL, data : data };\n      this.callbacks.onSuccess(response, stats, context);\n    } else {\n      // if max nb of retries reached or if http status between 400 and 499 (such error cannot be recovered, retrying is useless), return error\n      if (stats.retry >= config.maxRetry || (status >= 400 && status < 499)) {\n      //  logger.error(`${status} while loading ${context.url}` );\n        this.callbacks.onError({ code : status, text : xhr.statusText}, context);\n      } else {\n      // retry\n      //  logger.warn(`${status} while loading ${context.url}, retrying in ${this.retryDelay}...`);\n        // aborts and resets internal state\n        this.destroy();\n        // schedule retry\n        this.retryTimeout = window.setTimeout(this.loadInternal.bind(this), this.retryDelay);\n        // set exponential backoff\n        this.retryDelay = Math.min(2 * this.retryDelay, config.maxRetryDelay);\n        stats.retry++;\n      }\n    }\n  }\n\n  loadtimeout() {\n  //  logger.warn(`timeout while loading ${this.context.url}` );\n    this.callbacks.onTimeout(this.stats, this.context);\n  }\n\n  loadprogress(event) {\n    var stats = this.stats;\n    if (stats.tfirst === 0) {\n      stats.tfirst = Math.max(performance.now(), stats.trequest);\n    }\n    stats.loaded = event.loaded;\n    if (event.lengthComputable) {\n      stats.total = event.total;\n    }\n    let onProgress = this.callbacks.onProgress;\n    if (onProgress) {\n      // last args is to provide on progress data\n      onProgress(stats, this.context, null);\n    }\n  }\n}\n\nexport default XhrLoader;\n",
    "import muxjs from 'mux.js'\n\nfunction mp4InitSegment(tracks) {\n    return muxjs.mp4.generator.initSegment(tracks);\n}\n\n/**\n * mux.js\n *\n * Copyright (c) 2014 Brightcove\n * All rights reserved.\n *\n * A lightweight readable stream implemention that handles event dispatching.\n * Objects that inherit from streams should call init in their constructors.\n */\nvar Stream = function() {\n    this.init = function() {\n        var listeners = {};\n        /**\n         * Add a listener for a specified event type.\n         * @param type {string} the event name\n         * @param listener {function} the callback to be invoked when an event of\n         * the specified type occurs\n         */\n        this.on = function(type, listener) {\n            if (!listeners[type]) {\n                listeners[type] = [];\n            }\n            listeners[type].push(listener);\n        };\n        /**\n         * Remove a listener for a specified event type.\n         * @param type {string} the event name\n         * @param listener {function} a function previously registered for this\n         * type of event through `on`\n         */\n        this.off = function(type, listener) {\n            var index;\n            if (!listeners[type]) {\n                return false;\n            }\n            index = listeners[type].indexOf(listener);\n            listeners[type].splice(index, 1);\n            return index > -1;\n        };\n        /**\n         * Trigger an event of the specified type on this stream. Any additional\n         * arguments to this function are passed as parameters to event listeners.\n         * @param type {string} the event name\n         */\n        this.trigger = function(type) {\n            var callbacks, i, length, args;\n            callbacks = listeners[type];\n            if (!callbacks) {\n                return;\n            }\n            // Slicing the arguments on every invocation of this method\n            // can add a significant amount of overhead. Avoid the\n            // intermediate object creation for the common case of a\n            // single callback argument\n            if (arguments.length === 2) {\n                length = callbacks.length;\n                for (i = 0; i < length; ++i) {\n                    callbacks[i].call(this, arguments[1]);\n                }\n            } else {\n                args = [];\n                i = arguments.length;\n                for (i = 1; i < arguments.length; ++i) {\n                    args.push(arguments[i]);\n                }\n                length = callbacks.length;\n                for (i = 0; i < length; ++i) {\n                    callbacks[i].apply(this, args);\n                }\n            }\n        };\n        /**\n         * Destroys the stream and cleans up.\n         */\n        this.dispose = function() {\n            listeners = {};\n        };\n    };\n};\n\n/**\n * Forwards all `data` events on this stream to the destination stream. The\n * destination stream should provide a method `push` to receive the data\n * events as they arrive.\n * @param destination {stream} the stream that will receive all `data` events\n * @param autoFlush {boolean} if false, we will not call `flush` on the destination\n *                            when the current stream emits a 'done' event\n * @see http://nodejs.org/api/stream.html#stream_readable_pipe_destination_options\n */\nStream.prototype.pipe = function(destination) {\n    this.on('data', function(data) {\n        destination.push(data);\n    });\n\n    this.on('done', function(flushSource) {\n        destination.flush(flushSource);\n    });\n\n    return destination;\n};\n\n// Default stream functions that are expected to be overridden to perform\n// actual work. These are provided by the prototype as a sort of no-op\n// implementation so that we don't have to check for their existence in the\n// `pipe` function above.\nStream.prototype.push = function(data) {\n    this.trigger('data', data);\n};\n\nStream.prototype.flush = function(flushSource) {\n    this.trigger('done', flushSource);\n};\n\n/**\n * A Stream that can combine multiple streams (ie. audio & video)\n * into a single output segment for MSE. Also supports audio-only\n * and video-only streams.\n */\nvar CoalesceStream = function(options, metadataStream) {\n    // Number of Tracks per output segment\n    // If greater than 1, we combine multiple\n    // tracks into a single segment\n    this.numberOfTracks = 0;\n    this.metadataStream = metadataStream;\n\n    if (typeof options.remux !== 'undefined') {\n        this.remuxTracks = !!options.remux;\n    } else {\n        this.remuxTracks = true;\n    }\n\n    this.pendingTracks = [];\n    this.videoTrack = null;\n    this.pendingBoxes = [];\n    this.pendingCaptions = [];\n    this.pendingMetadata = [];\n    this.pendingBytes = 0;\n    this.emittedTracks = 0;\n\n    CoalesceStream.prototype.init.call(this);\n\n    // Take output from multiple\n    this.push = function(output) {\n        // buffer incoming captions until the associated video segment\n        // finishes\n        if (output.text) {\n            return this.pendingCaptions.push(output);\n        }\n        // buffer incoming id3 tags until the final flush\n        if (output.frames) {\n            return this.pendingMetadata.push(output);\n        }\n\n        // Add this track to the list of pending tracks and store\n        // important information required for the construction of\n        // the final segment\n        this.pendingTracks.push(output.track);\n        this.pendingBoxes.push(output.boxes);\n        this.pendingBytes += output.boxes.byteLength;\n\n        if (output.track.type === 'video') {\n            this.videoTrack = output.track;\n        }\n        if (output.track.type === 'audio') {\n            this.audioTrack = output.track;\n        }\n    };\n};\n\n// constants\nvar AUDIO_PROPERTIES = [\n    'audioobjecttype',\n    'channelcount',\n    'samplerate',\n    'samplingfrequencyindex',\n    'samplesize'\n];\n\nvar VIDEO_PROPERTIES = [\n    'width',\n    'height',\n    'profileIdc',\n    'levelIdc',\n    'profileCompatibility'\n];\n\nCoalesceStream.prototype = new Stream();\nCoalesceStream.prototype.flush = function(flushSource) {\n    var\n        offset = 0,\n        event = {\n            captions: [],\n            metadata: [],\n            info: {}\n        },\n        caption,\n        id3,\n        initSegment,\n        timelineStartPts = 0,\n        i;\n\n    if (this.pendingTracks.length < this.numberOfTracks) {\n        if (flushSource !== 'VideoSegmentStream' &&\n            flushSource !== 'AudioSegmentStream') {\n            // Return because we haven't received a flush from a data-generating\n            // portion of the segment (meaning that we have only recieved meta-data\n            // or captions.)\n            return;\n        } else if (this.remuxTracks) {\n            // Return until we have enough tracks from the pipeline to remux (if we\n            // are remuxing audio and video into a single MP4)\n            return;\n        } else if (this.pendingTracks.length === 0) {\n            // In the case where we receive a flush without any data having been\n            // received we consider it an emitted track for the purposes of coalescing\n            // `done` events.\n            // We do this for the case where there is an audio and video track in the\n            // segment but no audio data. (seen in several playlists with alternate\n            // audio tracks and no audio present in the main TS segments.)\n            this.emittedTracks++;\n\n            if (this.emittedTracks >= this.numberOfTracks) {\n                this.trigger('done');\n                this.emittedTracks = 0;\n            }\n            return;\n        }\n    }\n\n    if (this.videoTrack) {\n        timelineStartPts = this.videoTrack.timelineStartInfo.pts;\n        VIDEO_PROPERTIES.forEach(function(prop) {\n            event.info[prop] = this.videoTrack[prop];\n        }, this);\n    } else if (this.audioTrack) {\n        timelineStartPts = this.audioTrack.timelineStartInfo.pts;\n        AUDIO_PROPERTIES.forEach(function(prop) {\n            event.info[prop] = this.audioTrack[prop];\n        }, this);\n    }\n\n    if (this.pendingTracks.length === 1) {\n        event.type = this.pendingTracks[0].type;\n    } else {\n        event.type = 'combined';\n    }\n\n    this.emittedTracks += this.pendingTracks.length;\n\n    initSegment = mp4InitSegment(this.pendingTracks);\n\n    // Create a new typed array large enough to hold the init\n    // segment and all tracks\n    event.data = new Uint8Array(initSegment.byteLength +\n        this.pendingBytes);\n\n    // Create an init segment containing a moov\n    // and track definitions\n    event.data.set(initSegment);\n    offset += initSegment.byteLength;\n\n    // Append each moof+mdat (one per track) after the init segment\n    for (i = 0; i < this.pendingBoxes.length; i++) {\n        event.data.set(this.pendingBoxes[i], offset);\n        offset += this.pendingBoxes[i].byteLength;\n    }\n\n    // Translate caption PTS times into second offsets into the\n    // video timeline for the segment\n    for (i = 0; i < this.pendingCaptions.length; i++) {\n        caption = this.pendingCaptions[i];\n        caption.startTime = (caption.startPts - timelineStartPts);\n        caption.startTime /= 90e3;\n        caption.endTime = (caption.endPts - timelineStartPts);\n        caption.endTime /= 90e3;\n        event.captions.push(caption);\n    }\n\n    // Translate ID3 frame PTS times into second offsets into the\n    // video timeline for the segment\n    for (i = 0; i < this.pendingMetadata.length; i++) {\n        id3 = this.pendingMetadata[i];\n        id3.cueTime = (id3.pts - timelineStartPts);\n        id3.cueTime /= 90e3;\n        event.metadata.push(id3);\n    }\n    // We add this to every single emitted segment even though we only need\n    // it for the first\n    event.metadata.dispatchType = this.metadataStream.dispatchType;\n\n    // Reset stream state\n    this.pendingTracks.length = 0;\n    this.videoTrack = null;\n    this.pendingBoxes.length = 0;\n    this.pendingCaptions.length = 0;\n    this.pendingBytes = 0;\n    this.pendingMetadata.length = 0;\n\n    // Emit the built segment\n    this.trigger('data', event);\n\n    // Only emit `done` if all tracks have been flushed and emitted\n    if (this.emittedTracks >= this.numberOfTracks) {\n        this.trigger('done');\n        this.emittedTracks = 0;\n    }\n};\n\n\nmodule.exports = {\n    Stream ,\n    CoalesceStream \n};",
    "// The flow(flv live over websocket) objects.\n// @see http://download.macromedia.com/f4v/video_file_format_spec_v10_1.pdf\n// @see https://github.com/winlinvip/videojs-flow\nimport muxjs from 'mux.js'\nimport {\n    Stream,\n    CoalesceStream\n} from './flow-mux'\n\nvar FlowReader, FlowTag, FlowCodec, FlowGop, FlowTransmuxer;\n\n// manage a gop of tags.\nFlowGop = function() {\n    var self = this;\n    self.tags = [];\n    self.nbKeyframes = 0;\n\t\tself.numFrames = 0;\n\t\t\n    self.push = function(tag) {\n        if (tag.isKeyframe()) {\n            self.nbKeyframes++;\n            console.log(\"keyframe \" + self.nbKeyframes);\n        }\n        self.tags.push(tag);\n        self.numFrames++;\n        // console.log(\"frame \" + self.numFrames);\n    };\n\n    self.pop = function() {\n        if (self.nbKeyframes < 2) {\n            return null;\n        }\n\n        var nbKeyframes = 0;\n        var tags = [];\n        while (self.tags.length > 0) {\n            var tag = self.tags[0];\n\n            if (tag.isKeyframe()) {\n                // return one gop.\n                if (nbKeyframes > 0) {\n                    break;\n                }\n\n                self.nbKeyframes--;\n                nbKeyframes++;\n            }\n\n            tags.push(self.tags.shift());\n            self.numFrames--;\n        }\n\t\t\t\t\n        console.log(\"after frame \" + self.numFrames);\n        return tags;\n    };\n};\n\n// convert flv to adts for aac or annexb for avc.\nFlowCodec = function() {\n    // set to the zero to reserved, for array map.\n    var SrsCodecVideoAVCFrameReserved = 0,\n        SrsCodecVideoAVCFrameReserved1 = 6,\n        SrsCodecVideoAVCFrameKeyFrame = 1,\n        SrsCodecVideoAVCFrameInterFrame= 2,\n        SrsCodecVideoAVCFrameDisposableInterFrame = 3,\n        SrsCodecVideoAVCFrameGeneratedKeyFrame = 4,\n        SrsCodecVideoAVCFrameVideoInfoFrame = 5;\n\n    // Table 1.1 - Audio Object Type definition\n    // @see @see aac-mp4a-format-ISO_IEC_14496-3+2001.pdf, page 23\n    var SrsAacObjectTypeReserved = 0,\n        SrsAacObjectTypeAacMain = 1,\n        SrsAacObjectTypeAacLC = 2,\n        SrsAacObjectTypeAacSSR = 3,\n        SrsAacObjectTypeAacHE = 5, // AAC HE = LC+SBR\n        SrsAacObjectTypeAacHEV2 = 29; // AAC HEv2 = LC+SBR+PS\n\n    /**\n     * the avc payload format, must be ibmf or annexb format.\n     * we guess by annexb first, then ibmf for the first time,\n     * and we always use the guessed format for the next time.\n     */\n    var SrsAvcPayloadFormatGuess = 0,\n        SrsAvcPayloadFormatAnnexb = 1,\n        SrsAvcPayloadFormatIbmf = 2;\n\n    /**\n     * Table 7-1 - NAL unit type codes, syntax element categories, and NAL unit type classes\n     * H.264-AVC-ISO_IEC_14496-10-2012.pdf, page 83.\n     */\n    var SrsAvcNaluTypeReserved = 0,\n        SrsAvcNaluTypeNonIDR = 1,\n        SrsAvcNaluTypeDataPartitionA = 2,\n        SrsAvcNaluTypeDataPartitionB = 3,\n        SrsAvcNaluTypeDataPartitionC = 4,\n        SrsAvcNaluTypeIDR = 5,\n        SrsAvcNaluTypeSEI = 6,\n        SrsAvcNaluTypeSPS = 7,\n        SrsAvcNaluTypePPS = 8,\n        SrsAvcNaluTypeAccessUnitDelimiter = 9,\n        SrsAvcNaluTypeEOSequence = 10,\n        SrsAvcNaluTypeEOStream = 11,\n        SrsAvcNaluTypeFilterData = 12,\n        SrsAvcNaluTypeSPSExt = 13,\n        SrsAvcNaluTypePrefixNALU = 14,\n        SrsAvcNaluTypeSubsetSPS = 15,\n        SrsAvcNaluTypeLayerWithoutPartition = 19,\n        SrsAvcNaluTypeCodedSliceExt = 20;\n\n    // @see 7.1 Profiles, aac-iso-13818-7.pdf, page 40\n    var SrsAacProfileMain = 0,\n        SrsAacProfileLC = 1,\n        SrsAacProfileSSR = 2,\n        SrsAacProfileReserved = 3;\n\n    var self = this;\n    self.aac = {\n        ok: false,\n        object: 0, // SrsAacObjectType\n        sampleRate: 0,\n        channels: 0,\n    };\n    self.avc = {\n        ok: false,        \n        naluSize: 0,\n        sps: null,\n        pps: null,\n        payload_format: SrsAvcPayloadFormatGuess,\n    };\n\n    // @see srs_codec_aac_rtmp2ts\n    self.aac_rtmp2ts = function(object_type) {\n        switch (object_type) {\n            case SrsAacObjectTypeAacMain: return SrsAacProfileMain;\n            case SrsAacObjectTypeAacHE:\n            case SrsAacObjectTypeAacHEV2:\n            case SrsAacObjectTypeAacLC: return SrsAacProfileLC;\n            case SrsAacObjectTypeAacSSR: return SrsAacProfileSSR;\n            default: return SrsAacProfileReserved;\n        }\n    };\n\n    // aac audio to adts format for AdtsStream:\n    //      toAdts(tag FlvTag) (frame Uint8Array)\n    // @return null if not got adts frame.\n    // @see SrsAacEncoder::write_audio\n    self.toAdts = function(tag) {\n        // for audio, pts equals to dts.\n        tag.pts = tag.dts;\n\n        var buf = tag.tag;\n        if (buf.byteLength < 2) {\n            throw new Error(\"audio tag invalid, size=\" + buf.byteLength);\n        }\n\n        // @see: E.4.2 Audio Tags, video_file_format_spec_v10_1.pdf, page 76\n        var sound_format = buf[0];\n        // @see: SrsAvcAacCodec::audio_aac_demux\n        //int8_t sound_type = sound_format & 0x01;\n        //int8_t sound_size = (sound_format >> 1) & 0x01;\n        //int8_t sound_rate = (sound_format >> 2) & 0x03;\n        sound_format = (sound_format >> 4) & 0x0f;\n        //     10 = AAC\n        if (sound_format != 10) {\n            throw new Error(\"audio is not aac, format=\" + sound_format);\n        }\n\n        var aac_packet_type = buf[1];\n        buf = buf.subarray(2);\n        if (aac_packet_type == 0) {\n            // AudioSpecificConfig\n            // 1.6.2.1 AudioSpecificConfig, in aac-mp4a-format-ISO_IEC_14496-3+2001.pdf, page 33.\n            //\n            // only need to decode the first 2bytes:\n            // audioObjectType, 5bits.\n            // samplingFrequencyIndex, aac_sample_rate, 4bits.\n            // channelConfiguration, aac_channels, 4bits\n            if (buf.byteLength < 2) {\n                throw new Error(\"aac sequence header invalid, size=\" + buf.byteLength);\n            }\n\n            var audioObjectType = buf[0];\n            self.aac.sampleRate = buf[1];\n\n            self.aac.channels = (self.aac.sampleRate >> 3) & 0x0f;\n            self.aac.sampleRate = ((audioObjectType << 1) & 0x0e) | ((self.aac.sampleRate >> 7) & 0x01);\n\n            self.aac.object = (audioObjectType >> 3) & 0x1f;\n            self.aac.ok = true;\n            return null;\n        }\n\n        if (!self.aac.ok) {\n            throw new Error(\"no aac sequence header\");\n        }\n\n        // the left is the aac raw frame data.\n        var aac_raw_length = buf.byteLength;\n\n        // write the ADTS header.\n        // @see aac-mp4a-format-ISO_IEC_14496-3+2001.pdf, page 75,\n        //      1.A.2.2 Audio_Data_Transport_Stream frame, ADTS\n        // @see https://github.com/ossrs/srs/issues/212#issuecomment-64145885\n        // byte_alignment()\n\n        // adts_fixed_header:\n        //      12bits syncword,\n        //      16bits left.\n        // adts_variable_header:\n        //      28bits\n        //      12+16+28=56bits\n        // adts_error_check:\n        //      16bits if protection_absent\n        //      56+16=72bits\n        // if protection_absent:\n        //      require(7bytes)=56bits\n        // else\n        //      require(9bytes)=72bits\n        var aac_fixed_header = new Uint8Array(7);\n        var aac_frame_length = aac_raw_length + 7;\n\n        // Syncword 12 bslbf\n        aac_fixed_header[0] = 0xff;\n        // 4bits left.\n        // adts_fixed_header(), 1.A.2.2.1 Fixed Header of ADTS\n        // ID 1 bslbf\n        // Layer 2 uimsbf\n        // protection_absent 1 bslbf\n        aac_fixed_header[1] = 0xf1;\n\n        // profile 2 uimsbf\n        // sampling_frequency_index 4 uimsbf\n        // private_bit 1 bslbf\n        // channel_configuration 3 uimsbf\n        // original/copy 1 bslbf\n        // home 1 bslbf\n        var aac_profile = self.aac_rtmp2ts(self.aac.object);\n        aac_fixed_header[2] = ((aac_profile << 6) & 0xc0) | ((self.aac.sampleRate << 2) & 0x3c) | ((self.aac.channels >> 2) & 0x01);\n        // 4bits left.\n        // adts_variable_header(), 1.A.2.2.2 Variable Header of ADTS\n        // copyright_identification_bit 1 bslbf\n        // copyright_identification_start 1 bslbf\n        aac_fixed_header[3] = ((self.aac.channels << 6) & 0xc0) | ((aac_frame_length >> 11) & 0x03);\n\n        // aac_frame_length 13 bslbf: Length of the frame including headers and error_check in bytes.\n        // use the left 2bits as the 13 and 12 bit,\n        // the aac_frame_length is 13bits, so we move 13-2=11.\n        aac_fixed_header[4] = aac_frame_length >> 3;\n        // adts_buffer_fullness 11 bslbf\n        aac_fixed_header[5] = (aac_frame_length << 5) & 0xe0;\n\n        // no_raw_data_blocks_in_frame 2 uimsbf\n        aac_fixed_header[6] = 0xfc;\n\n        var adts = new Uint8Array(aac_frame_length);\n        adts.set(aac_fixed_header);\n        adts.set(buf, 7);\n        return adts;\n    };\n\n    // avc video to annexb format for NalByteStream:\n    //      toAdts(tag FlvTag) (frame Uint8Array)\n    self.toAnnexb = function(tag) {\n        var buf = tag.tag;\n        \n        // video sample, contains all NALUs in frame.\n        var sample = {ok:false, size:tag.tag.byteLength,\n            dts:tag.dts, cts:0, pts:0, avc_packet_type:0, nalus:[], has_idr:false,\n            addNalu: function(nalu) {\n                var nal_unit_type = (nalu[0] & 0x1f);\n                if (nal_unit_type == SrsAvcNaluTypeIDR) {\n                    this.has_idr = true;\n                }\n                //console.log(\"got nalu \" + nalu.byteLength);\n                this.nalus.push(nalu);\n            },\n        };\n                \n        // pts = dts + cts.\n        sample.cts = 0;\n        sample.pts = sample.dts + sample.cts;\n        // update tag pts.\n        tag.pts = sample.pts;\n\n\t\t\t\tself.avc_demux_sps_pps(buf);\n\t\t\t\t\n\n        self.avc_demux_sample(buf, sample);\n        if (!sample.ok) {\n        \treturn null;\n        }\n        \n        if (null == self.avc.pps || null == self.avc.sps)\n        {\n\t        for (var i in sample.nalus) {\n\t            var nalu = sample.nalus[i];\n\n\t            // 5bits, 7.3.1 NAL unit syntax,\n\t            // H.264-AVC-ISO_IEC_14496-10-2012.pdf, page 83.\n\t            var nal_unit_type = nalu[0]&0x1f;\n\n\t            // ignore SPS/PPS/AUD\n\t            switch (nal_unit_type) {\n\t                case SrsAvcNaluTypeSPS:\n\t                \t\t self.avc.sps = nalu;\n\t                     break;\n\t                case SrsAvcNaluTypePPS:\n\t                     self.avc.pps = nalu;\n\t                     break;\n\t                default:\n\t                    break;\n\t            }\n\t        }\n\t        if(self.avc.sps && self.avc.pps)\n\t        {\n\t        \tself.avc.ok = true;\n\t        }\n        }\n      \n      if(false == self.avc.ok)\n      {\n      \treturn null;\n      }\n      return self.avc_transmux_sample(sample);        \n        \n    };\n    self.avc_demux_sps_pps = function(buf) {\n        \n        // parse the NALU size.\n        self.avc.naluSize = 3;\n        //self.avc.sps = buf.subarray(0, sequenceParameterSetLength);\n        //self.avc.pps = buf.subarray(0, pictureParameterSetLength);\n        //self.avc.ok = false;\n    };\n    self.avc_demux_sample = function(buf, sample) {        \n\n        // guess for the first time.\n        if (self.avc.payload_format == SrsAvcPayloadFormatGuess) {\n            // One or more NALUs (Full frames are required)\n            // try  \"AnnexB\" from H.264-AVC-ISO_IEC_14496-10.pdf, page 211.\n            if (!self.avc_demux_annexb_format(buf, sample)) {\n                // try \"ISO Base Media File Format\" from H.264-AVC-ISO_IEC_14496-15.pdf, page 20\n                if (!self.avc_demux_ibmf_format(buf, sample)) {\n                    throw new Error(\"invalid format, not annexb or ibmf\");\n                } else {\n                    self.avc.payload_format = SrsAvcPayloadFormatIbmf;\n                }\n            } else {\n                self.avc.payload_format = SrsAvcPayloadFormatAnnexb;\n            }\n        } else if (self.avc.payload_format == SrsAvcPayloadFormatIbmf) {\n            // try \"ISO Base Media File Format\" from H.264-AVC-ISO_IEC_14496-15.pdf, page 20\n            if (!self.avc_demux_ibmf_format(buf, sample)) {\n                throw new Error(\"invalid ibmf format.\");\n            }\n        } else {\n            // One or more NALUs (Full frames are required)\n            // try  \"AnnexB\" from H.264-AVC-ISO_IEC_14496-10.pdf, page 211.\n            if (!self.avc_demux_annexb_format(buf, sample)) {\n                // try \"ISO Base Media File Format\" from H.264-AVC-ISO_IEC_14496-15.pdf, page 20\n                if (!self.avc_demux_ibmf_format(buf, sample)) {\n                    throw new Error(\"invalid format, not annexb or ibmf\");\n                } else {\n                    self.avc.payload_format = SrsAvcPayloadFormatIbmf;\n                }\n            }\n        }\n    };\n    self.avc_demux_annexb_format = function(buf, sample) {\n        var srs_avc_startswith_annexb = function(buf) {\n            var p = buf.subarray(0);\n            for (;;) {\n                if (p.byteLength < 3) {\n                    return null;\n                }\n\n                // not match\n                if (p[0] != 0x00 || p[1] != 0x00) {\n                \t\tp = p.subarray(1);\n                    continue;\n                }\n\n                // match N[00] 00 00 01, where N>=0\n                if (p[2] == 0x01) {\n                    return p;\n                }\n                p = p.subarray(1);\n            }\n\n            return null;\n        }\n\n        buf = srs_avc_startswith_annexb(buf);\n        // not annexb, try others\n        if (!buf) {\n            return false;\n        }\n\n        // AnnexB\n        // B.1.1 Byte stream NAL unit syntax,\n        // H.264-AVC-ISO_IEC_14496-10.pdf, page 211.\n        while (buf && buf.byteLength > 0) {\n            var next = srs_avc_startswith_annexb(buf.subarray(1));\n            var nalu = buf.subarray(3, buf.byteLength - (next? next.byteLength:0) - (next? 1:0));\n            sample.addNalu(nalu);\n            buf = next;\n        }\n\n        sample.ok = true;\n        return true;\n    };\n    self.avc_demux_ibmf_format = function(buf, sample) {\n        while (buf && buf.byteLength > 0) {\n            if (buf.byteLength < (self.avc.naluSize + 1)) {\n                throw new Error(\"invalid nalu length, require=\" + (self.avc.naluSize+1) + \", size=\" + buf.byteLength);\n            }\n            var NALUnitLength = 0;\n            if (self.avc.naluSize == 3) {\n                NALUnitLength = (buf[0]<<24)|(buf[1]<<16)|(buf[2]<<8)|(buf[3]);\n            } else if (self.avc.naluSize == 1) {\n                NALUnitLength = (buf[0]<<8)|(buf[1]);\n            } else {\n                NALUnitLength = buf[0];\n            }\n            buf = buf.subarray(self.avc.naluSize + 1);\n\n            // maybe stream is invalid format.\n            // see: https://github.com/ossrs/srs/issues/183\n            if (NALUnitLength < 0) {\n                return false;\n            }\n\n            // NALUnit\n            if (buf.byteLength < NALUnitLength) {\n                throw new Error(\"invalid nalu, require=\" + NALUnitLength + \", size=\" + buf.byteLength);\n            }\n            // 7.3.1 NAL unit syntax, H.264-AVC-ISO_IEC_14496-10.pdf, page 44.\n            var nalu = buf.subarray(0, NALUnitLength);\n            sample.addNalu(nalu);\n            buf = buf.subarray(NALUnitLength);\n        }\t\t\t\t\t\t\t\t\n\n        sample.ok = true;\n        return true;\n    };\n    self.avc_transmux_sample = function(sample) {\n        /*console.log(\"avc(profile=\" + self.avc.profile + \", level=\" + self.avc.level\n         + \", naluSize=\" + self.avc.naluSize + \", sps=\" + self.avc.sps.byteLength\n         + \", pps=\" + self.avc.pps.byteLength + \") frame type=\" + sample.frame_type\n         + \", size=\" + sample.size + \", dts=\" + sample.dts + \", pts=\" + sample.pts\n         + \", nalus=\" + sample.nalus.length + \", idr=\" + sample.has_idr);*/\n\n        // mux the samples in annexb format,\n        // H.264-AVC-ISO_IEC_14496-10-2012.pdf, page 324.\n        /**\n         * 00 00 00 01 // header\n         *       xxxxxxx // data bytes\n         * 00 00 01 // continue header\n         *       xxxxxxx // data bytes.\n         *\n         * nal_unit_type specifies the type of RBSP data structure contained in the NAL unit as specified in Table 7-1.\n         * Table 7-1 - NAL unit type codes, syntax element categories, and NAL unit type classes\n         * H.264-AVC-ISO_IEC_14496-10-2012.pdf, page 83.\n         *      1, Coded slice of a non-IDR picture slice_layer_without_partitioning_rbsp( )\n         *      2, Coded slice data partition A slice_data_partition_a_layer_rbsp( )\n         *      3, Coded slice data partition B slice_data_partition_b_layer_rbsp( )\n         *      4, Coded slice data partition C slice_data_partition_c_layer_rbsp( )\n         *      5, Coded slice of an IDR picture slice_layer_without_partitioning_rbsp( )\n         *      6, Supplemental enhancement information (SEI) sei_rbsp( )\n         *      7, Sequence parameter set seq_parameter_set_rbsp( )\n         *      8, Picture parameter set pic_parameter_set_rbsp( )\n         *      9, Access unit delimiter access_unit_delimiter_rbsp( )\n         *      10, End of sequence end_of_seq_rbsp( )\n         *      11, End of stream end_of_stream_rbsp( )\n         *      12, Filler data filler_data_rbsp( )\n         *      13, Sequence parameter set extension seq_parameter_set_extension_rbsp( )\n         *      14, Prefix NAL unit prefix_nal_unit_rbsp( )\n         *      15, Subset sequence parameter set subset_seq_parameter_set_rbsp( )\n         *      19, Coded slice of an auxiliary coded picture without partitioning slice_layer_without_partitioning_rbsp( )\n         *      20, Coded slice extension slice_layer_extension_rbsp( )\n         * the first ts message of apple sample:\n         *      annexb 4B header, 2B aud(nal_unit_type:6)(0x09 0xf0)\n         *      annexb 4B header, 19B sps(nal_unit_type:7)\n         *      annexb 3B header, 4B pps(nal_unit_type:8)\n         *      annexb 3B header, 12B nalu(nal_unit_type:6)\n         *      annexb 3B header, 21B nalu(nal_unit_type:6)\n         *      annexb 3B header, 2762B nalu(nal_unit_type:5)\n         *      annexb 3B header, 3535B nalu(nal_unit_type:5)\n         * the second ts message of apple ts sample:\n         *      annexb 4B header, 2B aud(nal_unit_type:6)(0x09 0xf0)\n         *      annexb 3B header, 21B nalu(nal_unit_type:6)\n         *      annexb 3B header, 379B nalu(nal_unit_type:1)\n         *      annexb 3B header, 406B nalu(nal_unit_type:1)\n         */\n        var fresh_nalu_header = new Uint8Array([0x00, 0x00, 0x00, 0x01]);\n        var cont_nalu_header = new Uint8Array([0x00, 0x00, 0x01]);\n\n        // the aud(access unit delimiter) before each frame.\n        // 7.3.2.4 Access unit delimiter RBSP syntax\n        // H.264-AVC-ISO_IEC_14496-10-2012.pdf, page 66.\n        //\n        // primary_pic_type u(3), the first 3bits, primary_pic_type indicates that the slice_type values\n        //      for all slices of the primary coded picture are members of the set listed in Table 7-5 for\n        //      the given value of primary_pic_type.\n        //      0, slice_type 2, 7\n        //      1, slice_type 0, 2, 5, 7\n        //      2, slice_type 0, 1, 2, 5, 6, 7\n        //      3, slice_type 4, 9\n        //      4, slice_type 3, 4, 8, 9\n        //      5, slice_type 2, 4, 7, 9\n        //      6, slice_type 0, 2, 3, 4, 5, 7, 8, 9\n        //      7, slice_type 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n        // 7.4.2.4 Access unit delimiter RBSP semantics\n        // H.264-AVC-ISO_IEC_14496-10-2012.pdf, page 102.\n        //\n        // slice_type specifies the coding type of the slice according to Table 7-6.\n        //      0, P (P slice)\n        //      1, B (B slice)\n        //      2, I (I slice)\n        //      3, SP (SP slice)\n        //      4, SI (SI slice)\n        //      5, P (P slice)\n        //      6, B (B slice)\n        //      7, I (I slice)\n        //      8, SP (SP slice)\n        //      9, SI (SI slice)\n        // H.264-AVC-ISO_IEC_14496-10-2012.pdf, page 105.\n        var aud_nalu_7 = new Uint8Array([0x09, 0xf0]);\n\n        // always append a aud nalu for each frame.\n        var frameSize = 4+2+ 4+self.avc.sps.byteLength+ 3+self.avc.pps.byteLength;\n        for (var i in sample.nalus) {\n            var nalu = sample.nalus[i];\n            frameSize += 3+nalu.byteLength;\n        }\n        var frame = new Uint8Array(frameSize);\n        frameSize = 0;\n\n        // aud.\n        frame.set(fresh_nalu_header, frameSize); frameSize += 4;\n        frame.set(aud_nalu_7, frameSize); frameSize += 2;\n\n        // when ts message(samples) contains IDR, insert sps+pps.\n        if (sample.has_idr) {\n            // fresh nalu header before sps.\n            if (self.avc.sps.byteLength > 0) {\n                // AnnexB prefix, for sps always 4 bytes header\n                frame.set(fresh_nalu_header, frameSize); frameSize += 4;\n                // sps\n                frame.set(self.avc.sps, frameSize); frameSize += self.avc.sps.byteLength;\n            }\n            // cont nalu header before pps.\n            if (self.avc.pps.byteLength > 0) {\n                // AnnexB prefix, for pps always 3 bytes header\n                frame.set(cont_nalu_header, frameSize); frameSize += 3;\n                // pps\n                frame.set(self.avc.pps, frameSize); frameSize += self.avc.pps.byteLength;\n            }\n        }\n\n        // all sample use cont nalu header, except the sps-pps before IDR frame.\n        for (var i in sample.nalus) {\n            var nalu = sample.nalus[i];\n\n            // 5bits, 7.3.1 NAL unit syntax,\n            // H.264-AVC-ISO_IEC_14496-10-2012.pdf, page 83.\n            var nal_unit_type = nalu[0]&0x1f;\n\n            // ignore SPS/PPS/AUD\n            switch (nal_unit_type) {\n                case SrsAvcNaluTypeSPS:\n                case SrsAvcNaluTypePPS:\n                case SrsAvcNaluTypeAccessUnitDelimiter:\n                    continue;\n                default:\n                    break;\n            }\n\n            // insert cont nalu header before frame.\n            frame.set(cont_nalu_header, frameSize); frameSize += 3;\n            // sample data\n            frame.set(nalu, frameSize); frameSize += nalu.byteLength;\n        }\n\n        //console.log(frame.byteLength + \", \" + frameSize);\n        var annexb = frame.subarray(0, frameSize);\n        return annexb;\n    };\n};\n\n// the flv tag data.\nFlowTag = function() {\n    var self = this;\n    self.type = self.dts = self.pts = 0; // uint\n    self.tag = null; // Uint8Array.\n\n    self.isAudio = function() {\n        return false;\n    }\n    self.isVideo = function () {\n    \t  // should get frome frame header info\n        return true;\n    };\n    self.isKeyframe = function() {\n        if (!self.isVideo()) {\n            return false;\n        }\n\n        if (self.tag.byteLength < 5) {\n            throw new Error(\"invalid keyframe, size=\" + self.tag.byteLength);\n        }\n        // should get from frame header info\n        var bRet = false;\n        if((self.tag[4] & 0x1F) == 7 || \n        \t (self.tag[4] & 0x1F) == 8 ||\n        \t (self.tag[4] & 0x1F) == 5 )\n        {        \t\n        \tbRet = true;\n        }\n        return bRet;\n    };\n    self.isAac = function() {\n        return false;\n    };\n    self.isAvc = function() {\n        return true;\n    };\n    self.isSequenceHeader = function() {\n        return false;\n    };\n    self.isScriptData = function() {\n        return false;\n    };\n    self.toString = function() {\n        var t = self.isAudio()? \"Audio\":self.isVideo()? \"Video\": self.isScriptData()? \"Data\":\"Other\";\n        return t + ', ' + Number(Number(self.dts)/1000).toFixed(2) + 's, ' + self.tag.byteLength + ' bytes';\n    };\n};\n\n// read FlvTag from Uint8Array.\nFlowReader = function() {\n    var self = this;\n    self.header = {\n        ok: false,\n        version: 0, // File version (for example, 0x01 for FLV version 1)\n        hasAudio: false, // 1 = Audio tags are present\n        hasVideo: false, // 1 = Video tags are present\n    };\n    self.sequenceHeader = null;\n    self.cache = null;\n    self.dts = 0;\n\n    // append bytes to reader:\n    //      append(ibytes Uint8Array) void\n    self.append = function(ibytes) {\n        var everything;\n        if (self.cache && self.cache.byteLength > 0) {\n            everything = new Uint8Array(self.cache.byteLength + ibytes.byteLength);\n            everything.set(self.cache);\n            everything.set(ibytes, self.cache.byteLength);\n        } else {\n            everything = ibytes;\n        }\n\n        self.cache = everything;\n    };\n\n    // read FlvTag instance from reader.\n    //      read() (tag FlvTag)\n    // @return null if eof, user should append bytes then parse.\n    self.read = function(){\n        var everything = self.cache;\n        if (!everything) {\n            return null;\n        }\n\n        while(true) {\n        \t            \n            // parse flv header id: FLV.\n            if (!self.header.ok) {\n                \n                self.header.ok = true;\n                self.header.hasAudio = false;\n                self.header.hasVideo = true;                \n            }\n\t\t\t\t\t\n            // parse a tag from bytes.\n            var obj = new FlowTag();\n            obj.tag = everything;\n            obj.type = 0;\n            obj.dts = self.dts;\n            obj.pts = obj.dts;\n            self.cache = null;\n            self.dts += 40;\n            return obj;\n        }\n\n        return null;\n    };\n};\n\n/**\n * A Stream that expects MP2T binary data as input and produces\n * corresponding media segments, suitable for use with Media Source\n * Extension (MSE) implementations that support the ISO BMFF byte\n * stream format, like Chrome.\n */\nFlowTransmuxer = function() {\n    var self = this;\n    self.flv = new FlowReader();\n    self.codec = new FlowCodec();\n    self.gop = new FlowGop();\n    self.ws = null; // WebSocket\n\n    var videoTrack = {type:'video',codec:'avc',timelineStartInfo:{baseMediaDecodeTime:0}};\n    var audioTrack = {type:'audio',codec:'adts',timelineStartInfo:{baseMediaDecodeTime:0}};\n\n    var pipeline = {};\n    pipeline.type = 'flow'; // FLOW(flv live over websocet), annexb to mp4.\n    pipeline.h264Stream = new muxjs.codecs.h264.H264Stream();\n    pipeline.adtsStream = muxjs.codecs.Adts.AdtsStream; // new AdtsStream()\n    pipeline.videoSegmentStream = new muxjs.mp4.VideoSegmentStream(videoTrack);\n    pipeline.audioSegmentStream = new muxjs.mp4.AudioSegmentStream(audioTrack);\n    pipeline.coalesceStream = new CoalesceStream({}, {dispatchType:muxjs.mp2t.METADATA_STREAM_TYPE});\n    pipeline.h264Stream\n        .pipe(pipeline.videoSegmentStream)\n        .pipe(pipeline.coalesceStream);\n    /*pipeline.adtsStream\n        .pipe(pipeline.audioSegmentStream)\n        .pipe(pipeline.coalesceStream);*/\n\n    FlowTransmuxer.prototype.init.call(this);\n\n    // append mp4 segment to mse.\n    pipeline.coalesceStream.on('data', function(segment){\n        // console.log('append mp4 ' + segment.type + \" \" + segment.data.buffer.byteLength + \" bytes\");\n        self.trigger('data', segment);\n    });\n\n    self.src = function(url) {\n        self.ws = new WebSocket(url);\n        self.ws.onmessage = function(evt) {\n            var b = evt.data; // Blob: https://developer.mozilla.org/en-US/docs/Web/API/Blob\n            var reader = new FileReader();\n            reader.addEventListener('loadend', function(){\n                var bytes = new Uint8Array(reader.result);\n                self.transmux(bytes);\n            });\n            reader.readAsArrayBuffer(b);\n        };\n    };\n\n    // flv => tag => annexb/adts => mp4 => mse.\n    self.transmux = function(bytes) {\n        self.flv.append(bytes);\n\n        while (true) {\n            var tag = self.flv.read();\n            if (!tag) {\n                break;\n            }\n\n            if (tag.isSequenceHeader()) {\n                if (tag.isAudio()) {\n                    self.codec.toAdts(tag);\n                    //console.log(\"parse audio sequence header\");\n                } else {\n                    self.codec.toAnnexb(tag);\n                    //console.log(\"parse video sequence header\");\n                }\n                continue;\n            }\n\n            // append to the gop and conusme it.\n            self.gop.push(tag);\n            while (self.consumeGop()) {\n            }\n        }\n    };\n    // parse a gop of tags to mp4.\n    self.consumeGop = function() {\n        // when got one complete gop, transmux it.\n        var tags = self.gop.pop();\n        if (!tags) {\n            return false;\n        }\n        var first = tags[0];\n        var last = tags[tags.length - 1];\n        /*console.log(\"parse gop \" + tags.length + \" tags, dts[\" + first.dts\n         + \",\" + last.dts + \"], duration=\" + (last.dts - first.dts));*/\n\n        // parse all tags.\n        for (var i in tags) {\n            var tag = tags[i];\n\n            if (tag.isAudio()) {\n                var frame = self.codec.toAdts(tag);\n                if (!frame) {\n                    continue;\n                }\n                //console.log(\"adts \" + frame.byteLength + \" bytes\");\n\n                // @remark we must use ts tbn(*90 for flv).\n                pipeline.adtsStream.push({type:'audio', trackId:100, dts:tag.dts*180, pts:tag.pts*180, data:frame,});\n            } else if(tag.isVideo()) {\n                var frame = self.codec.toAnnexb(tag);\n                if (!frame) {\n                    continue;\n                }\n                //console.log(\"annexb \" + frame.byteLength + \" bytes\");\n\n                // @remark we must use ts tbn(*90 for flv).\n                // console.log(\"h264stream \" + (tag.dts*90) + \" pts \" + (tag.pts*90) + \" framesize\" + frame.byteLength);\n                pipeline.h264Stream.push({type:'video', trackId:101, dts:tag.dts*180, pts:tag.pts*180, data:frame,});\n            }\n        }\n\n        pipeline.h264Stream.flush();\n        //pipeline.adtsStream.flush();\n\n        return true;\n    };\n};\n\nFlowTransmuxer.prototype = new Stream();\n\n\nexport default FlowTransmuxer",
    "/**\n * WFS interface, Jeff Yang 2016.10\n */\n'use strict';\n\nimport Event from './events';\nimport FlowController from  './controller/flow-controller'; \nimport BufferController from  './controller/buffer-controller';\nimport EventEmitter from 'events';\nimport XhrLoader from './utils/xhr-loader';\nimport WebsocketLoader from './loader/websocket-loader';\n\n\nclass Wfs {\n\n  static get version() {\n    // replaced with browserify-versionify transform\n    return ''+'v.0.0.0.1';\n  }\n\n  static isSupported() {\n    return (window.MediaSource &&\n            typeof window.MediaSource.isTypeSupported === 'function' &&\n            window.MediaSource.isTypeSupported('video/mp4; codecs=\"avc1.42c01f,mp4a.40.2\"'));\n  }\n  \n  static get Events() {\n    return Event;\n  }\n \n  static get DefaultConfig() {\n    if(!Wfs.defaultConfig) {\n       Wfs.defaultConfig = {\n        autoStartLoad: true,\n        startPosition: -1,\n        debug: false, \n        fLoader: undefined,\n        loader: XhrLoader,\n        //loader: FetchLoader,\n        fmp4FileUrl: 'xxxx.mp4',\n        fragLoadingTimeOut: 20000,\n        fragLoadingMaxRetry: 6,\n        fragLoadingRetryDelay: 1000,\n        fragLoadingMaxRetryTimeout: 64000,\n        fragLoadingLoopThreshold: 3,\n        forceKeyFrameOnDiscontinuity: true,\n        appendErrorMaxRetry: 3\n      };\n    }\n    return Wfs.defaultConfig;\n  }\n\n  static set DefaultConfig(defaultConfig) {\n    Wfs.defaultConfig = defaultConfig;\n  }\n\n  constructor(config = {}) {\n\n    var defaultConfig = Wfs.DefaultConfig;\n    for (var prop in defaultConfig) {\n        if (prop in config) { continue; }\n        config[prop] = defaultConfig[prop];\n    }\n    this.config = config;  \n    // observer setup\n    var observer = this.observer = new EventEmitter();\n    observer.trigger = function trigger (event, ...data) {\n      observer.emit(event, event, ...data);\n    };\n\n    observer.off = function off (event, ...data) {\n      observer.removeListener(event, ...data);\n    };\n    this.on = observer.on.bind(observer);\n    this.off = observer.off.bind(observer);\n    this.trigger = observer.trigger.bind(observer);\n\n    this.flowController = new FlowController(this);\n    this.bufferController = new BufferController(this);\n  //  this.fileLoader = new FileLoader(this);\n    this.websocketLoader = new WebsocketLoader(this);\n    this.mediaType = undefined;     \n  }\n\n  destroy() {\n    this.flowController.destroy();\n    this.bufferController.destroy();\n //   this.fileLoader.destroy();\n    this.websocketLoader.destroy();\n  }\n\n  attachMedia(media, channelName='chX',mediaType='H264Raw', websocketName) { // 'H264Raw' 'FMp4'    \n    this.mediaType = mediaType; \n    this.media = media;\n    this.trigger(Event.MEDIA_ATTACHING, {media:media, channelName:channelName, mediaType:mediaType, websocketName:websocketName });\n  }\n  \n  attachWebsocket(websocket,channelName) { \n    this.trigger(Event.WEBSOCKET_ATTACHING, {websocket: websocket, mediaType:this.mediaType, channelName:channelName });\n  }\n\n}\n\nexport default Wfs;\n"
  ]
}